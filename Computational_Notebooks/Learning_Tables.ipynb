{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "388df6e4-4407-4617-9d61-211cfc40124f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "using Turing\n",
    "using LinearAlgebra\n",
    "using Distributions\n",
    "using MultivariateStats\n",
    "import MultivariateStats: reconstruct\n",
    "using GaussianProcesses\n",
    "using StatsBase\n",
    "using Statistics\n",
    "using Suppressor\n",
    "using JLD2\n",
    "using CSV\n",
    "using DataFrames, DataFramesMeta\n",
    "using SplitApplyCombine\n",
    "using KernelFunctions\n",
    "using MCMCChains\n",
    "using PyCall\n",
    "using PyPlot\n",
    "using Printf\n",
    "import PyCall.pyfunction\n",
    "using Missings\n",
    "\n",
    "os = pyimport(\"os\")\n",
    "pyimport(\"scienceplots\")\n",
    "np = pyimport(\"numpy\")\n",
    "\n",
    "\n",
    "PyCall.pygui(:tk)\n",
    "\n",
    "FONTSIZE=20.5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f1a91c-26b3-4068-89fe-9547faa350b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5aa5ac-0334-444f-a7c8-fdf2581842c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1325dfc8-0d6c-41c4-811f-6caaf14853bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################################################\n",
    "#####################################################################################################################\n",
    "#####################################################################################################################\n",
    "###############################                Parameter Learning Tables             ###########################\n",
    "#####################################################################################################################\n",
    "#####################################################################################################################\n",
    "#####################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fdae3ae1-b84e-4a31-94d9-59584d00c36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>21×7 DataFrame</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">Latest_calibration_year</th><th style = \"text-align: left;\">vmThresh</th><th style = \"text-align: left;\">fricExp</th><th style = \"text-align: left;\">mu_scale</th><th style = \"text-align: left;\">stiff_scale</th><th style = \"text-align: left;\">gamma0</th><th style = \"text-align: left;\">melt_flux</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"Any\" style = \"text-align: left;\">Any</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: left;\">2015</td><td style = \"text-align: left;\">34089.3</td><td style = \"text-align: left;\">0.172232</td><td style = \"text-align: left;\">0.232868</td><td style = \"text-align: left;\">0.205653</td><td style = \"text-align: left;\">2.53179</td><td style = \"text-align: left;\">30.4802</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: left;\">2030</td><td style = \"text-align: left;\">33780.8</td><td style = \"text-align: left;\">0.167235</td><td style = \"text-align: left;\">0.21296</td><td style = \"text-align: left;\">0.195873</td><td style = \"text-align: left;\">2.46702</td><td style = \"text-align: left;\">30.3705</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: left;\">2045</td><td style = \"text-align: left;\">33765.3</td><td style = \"text-align: left;\">0.15895</td><td style = \"text-align: left;\">0.208421</td><td style = \"text-align: left;\">0.190561</td><td style = \"text-align: left;\">2.25623</td><td style = \"text-align: left;\">30.1791</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4</td><td style = \"text-align: left;\">2060</td><td style = \"text-align: left;\">33642.9</td><td style = \"text-align: left;\">0.157167</td><td style = \"text-align: left;\">0.206643</td><td style = \"text-align: left;\">0.186847</td><td style = \"text-align: left;\">1.8003</td><td style = \"text-align: left;\">29.8141</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5</td><td style = \"text-align: left;\">2075</td><td style = \"text-align: left;\">33475.8</td><td style = \"text-align: left;\">0.153437</td><td style = \"text-align: left;\">0.203493</td><td style = \"text-align: left;\">0.181547</td><td style = \"text-align: left;\">1.24637</td><td style = \"text-align: left;\">28.1198</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">6</td><td style = \"text-align: left;\">2090</td><td style = \"text-align: left;\">33153.9</td><td style = \"text-align: left;\">0.151732</td><td style = \"text-align: left;\">0.198547</td><td style = \"text-align: left;\">0.175937</td><td style = \"text-align: left;\">1.2052</td><td style = \"text-align: left;\">26.9038</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">7</td><td style = \"text-align: left;\">2105</td><td style = \"text-align: left;\">32615.3</td><td style = \"text-align: left;\">0.145927</td><td style = \"text-align: left;\">0.181701</td><td style = \"text-align: left;\">0.164678</td><td style = \"text-align: left;\">1.13852</td><td style = \"text-align: left;\">26.5008</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">8</td><td style = \"text-align: left;\">2120</td><td style = \"text-align: left;\">32367.7</td><td style = \"text-align: left;\">0.139435</td><td style = \"text-align: left;\">0.175612</td><td style = \"text-align: left;\">0.161105</td><td style = \"text-align: left;\">1.02016</td><td style = \"text-align: left;\">26.2051</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">9</td><td style = \"text-align: left;\">2135</td><td style = \"text-align: left;\">31971.1</td><td style = \"text-align: left;\">0.135851</td><td style = \"text-align: left;\">0.172647</td><td style = \"text-align: left;\">0.154908</td><td style = \"text-align: left;\">0.898344</td><td style = \"text-align: left;\">24.2433</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">10</td><td style = \"text-align: left;\">2150</td><td style = \"text-align: left;\">31677.4</td><td style = \"text-align: left;\">0.131824</td><td style = \"text-align: left;\">0.169747</td><td style = \"text-align: left;\">0.150047</td><td style = \"text-align: left;\">0.778619</td><td style = \"text-align: left;\">23.4985</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">11</td><td style = \"text-align: left;\">2165</td><td style = \"text-align: left;\">30712.9</td><td style = \"text-align: left;\">0.125209</td><td style = \"text-align: left;\">0.160811</td><td style = \"text-align: left;\">0.138078</td><td style = \"text-align: left;\">0.697806</td><td style = \"text-align: left;\">21.6572</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">12</td><td style = \"text-align: left;\">2180</td><td style = \"text-align: left;\">29026.5</td><td style = \"text-align: left;\">0.110262</td><td style = \"text-align: left;\">0.14406</td><td style = \"text-align: left;\">0.126137</td><td style = \"text-align: left;\">0.572841</td><td style = \"text-align: left;\">21.3725</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">13</td><td style = \"text-align: left;\">2195</td><td style = \"text-align: left;\">28307.6</td><td style = \"text-align: left;\">0.0908863</td><td style = \"text-align: left;\">0.121924</td><td style = \"text-align: left;\">0.113836</td><td style = \"text-align: left;\">0.410084</td><td style = \"text-align: left;\">20.8598</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">14</td><td style = \"text-align: left;\">2210</td><td style = \"text-align: left;\">27691.4</td><td style = \"text-align: left;\">0.0664433</td><td style = \"text-align: left;\">0.105814</td><td style = \"text-align: left;\">0.105182</td><td style = \"text-align: left;\">0.368331</td><td style = \"text-align: left;\">20.225</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">15</td><td style = \"text-align: left;\">2225</td><td style = \"text-align: left;\">26619.7</td><td style = \"text-align: left;\">0.0420735</td><td style = \"text-align: left;\">0.0989751</td><td style = \"text-align: left;\">0.0990011</td><td style = \"text-align: left;\">0.315574</td><td style = \"text-align: left;\">19.9732</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">16</td><td style = \"text-align: left;\">2240</td><td style = \"text-align: left;\">26423.7</td><td style = \"text-align: left;\">0.0323021</td><td style = \"text-align: left;\">0.0980142</td><td style = \"text-align: left;\">0.0985742</td><td style = \"text-align: left;\">0.295967</td><td style = \"text-align: left;\">19.68</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">17</td><td style = \"text-align: left;\">2255</td><td style = \"text-align: left;\">26190.7</td><td style = \"text-align: left;\">0.0267554</td><td style = \"text-align: left;\">0.0945938</td><td style = \"text-align: left;\">0.0948924</td><td style = \"text-align: left;\">0.278976</td><td style = \"text-align: left;\">19.407</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">18</td><td style = \"text-align: left;\">2270</td><td style = \"text-align: left;\">25982.6</td><td style = \"text-align: left;\">0.023722</td><td style = \"text-align: left;\">0.0920389</td><td style = \"text-align: left;\">0.0931356</td><td style = \"text-align: left;\">0.266886</td><td style = \"text-align: left;\">19.128</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">19</td><td style = \"text-align: left;\">2285</td><td style = \"text-align: left;\">25805.7</td><td style = \"text-align: left;\">0.0219315</td><td style = \"text-align: left;\">0.0912153</td><td style = \"text-align: left;\">0.0914018</td><td style = \"text-align: left;\">0.256166</td><td style = \"text-align: left;\">18.9689</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">20</td><td style = \"text-align: left;\">2300</td><td style = \"text-align: left;\">25731.7</td><td style = \"text-align: left;\">0.0211176</td><td style = \"text-align: left;\">0.090532</td><td style = \"text-align: left;\">0.0900101</td><td style = \"text-align: left;\">0.250342</td><td style = \"text-align: left;\">18.7506</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">21</td><td style = \"text-align: left;\">total_%_decrease</td><td style = \"text-align: left;\">24.5168</td><td style = \"text-align: left;\">87.7389</td><td style = \"text-align: left;\">61.1231</td><td style = \"text-align: left;\">56.2322</td><td style = \"text-align: left;\">90.1121</td><td style = \"text-align: left;\">38.4827</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccc}\n",
       "\t& Latest\\_calibration\\_year & vmThresh & fricExp & mu\\_scale & stiff\\_scale & gamma0 & \\\\\n",
       "\t\\hline\n",
       "\t& Any & Any & Any & Any & Any & Any & \\\\\n",
       "\t\\hline\n",
       "\t1 & 2015 & 34089.3 & 0.172232 & 0.232868 & 0.205653 & 2.53179 & $\\dots$ \\\\\n",
       "\t2 & 2030 & 33780.8 & 0.167235 & 0.21296 & 0.195873 & 2.46702 & $\\dots$ \\\\\n",
       "\t3 & 2045 & 33765.3 & 0.15895 & 0.208421 & 0.190561 & 2.25623 & $\\dots$ \\\\\n",
       "\t4 & 2060 & 33642.9 & 0.157167 & 0.206643 & 0.186847 & 1.8003 & $\\dots$ \\\\\n",
       "\t5 & 2075 & 33475.8 & 0.153437 & 0.203493 & 0.181547 & 1.24637 & $\\dots$ \\\\\n",
       "\t6 & 2090 & 33153.9 & 0.151732 & 0.198547 & 0.175937 & 1.2052 & $\\dots$ \\\\\n",
       "\t7 & 2105 & 32615.3 & 0.145927 & 0.181701 & 0.164678 & 1.13852 & $\\dots$ \\\\\n",
       "\t8 & 2120 & 32367.7 & 0.139435 & 0.175612 & 0.161105 & 1.02016 & $\\dots$ \\\\\n",
       "\t9 & 2135 & 31971.1 & 0.135851 & 0.172647 & 0.154908 & 0.898344 & $\\dots$ \\\\\n",
       "\t10 & 2150 & 31677.4 & 0.131824 & 0.169747 & 0.150047 & 0.778619 & $\\dots$ \\\\\n",
       "\t11 & 2165 & 30712.9 & 0.125209 & 0.160811 & 0.138078 & 0.697806 & $\\dots$ \\\\\n",
       "\t12 & 2180 & 29026.5 & 0.110262 & 0.14406 & 0.126137 & 0.572841 & $\\dots$ \\\\\n",
       "\t13 & 2195 & 28307.6 & 0.0908863 & 0.121924 & 0.113836 & 0.410084 & $\\dots$ \\\\\n",
       "\t14 & 2210 & 27691.4 & 0.0664433 & 0.105814 & 0.105182 & 0.368331 & $\\dots$ \\\\\n",
       "\t15 & 2225 & 26619.7 & 0.0420735 & 0.0989751 & 0.0990011 & 0.315574 & $\\dots$ \\\\\n",
       "\t16 & 2240 & 26423.7 & 0.0323021 & 0.0980142 & 0.0985742 & 0.295967 & $\\dots$ \\\\\n",
       "\t17 & 2255 & 26190.7 & 0.0267554 & 0.0945938 & 0.0948924 & 0.278976 & $\\dots$ \\\\\n",
       "\t18 & 2270 & 25982.6 & 0.023722 & 0.0920389 & 0.0931356 & 0.266886 & $\\dots$ \\\\\n",
       "\t19 & 2285 & 25805.7 & 0.0219315 & 0.0912153 & 0.0914018 & 0.256166 & $\\dots$ \\\\\n",
       "\t20 & 2300 & 25731.7 & 0.0211176 & 0.090532 & 0.0900101 & 0.250342 & $\\dots$ \\\\\n",
       "\t21 & total\\_\\%\\_decrease & 24.5168 & 87.7389 & 61.1231 & 56.2322 & 90.1121 & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m21×7 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m Latest_calibration_year \u001b[0m\u001b[1m vmThresh \u001b[0m\u001b[1m fricExp   \u001b[0m\u001b[1m mu_scale  \u001b[0m\u001b[1m stiff_scale \u001b[0m\u001b[1m g\u001b[0m ⋯\n",
       "     │\u001b[90m Any                     \u001b[0m\u001b[90m Any      \u001b[0m\u001b[90m Any       \u001b[0m\u001b[90m Any       \u001b[0m\u001b[90m Any         \u001b[0m\u001b[90m A\u001b[0m ⋯\n",
       "─────┼──────────────────────────────────────────────────────────────────────────\n",
       "   1 │ 2015                     34089.3   0.172232   0.232868   0.205653     2 ⋯\n",
       "   2 │ 2030                     33780.8   0.167235   0.21296    0.195873     2\n",
       "   3 │ 2045                     33765.3   0.15895    0.208421   0.190561     2\n",
       "   4 │ 2060                     33642.9   0.157167   0.206643   0.186847     1\n",
       "   5 │ 2075                     33475.8   0.153437   0.203493   0.181547     1 ⋯\n",
       "   6 │ 2090                     33153.9   0.151732   0.198547   0.175937     1\n",
       "   7 │ 2105                     32615.3   0.145927   0.181701   0.164678     1\n",
       "   8 │ 2120                     32367.7   0.139435   0.175612   0.161105     1\n",
       "   9 │ 2135                     31971.1   0.135851   0.172647   0.154908     0 ⋯\n",
       "  10 │ 2150                     31677.4   0.131824   0.169747   0.150047     0\n",
       "  11 │ 2165                     30712.9   0.125209   0.160811   0.138078     0\n",
       "  12 │ 2180                     29026.5   0.110262   0.14406    0.126137     0\n",
       "  13 │ 2195                     28307.6   0.0908863  0.121924   0.113836     0 ⋯\n",
       "  14 │ 2210                     27691.4   0.0664433  0.105814   0.105182     0\n",
       "  15 │ 2225                     26619.7   0.0420735  0.0989751  0.0990011    0\n",
       "  16 │ 2240                     26423.7   0.0323021  0.0980142  0.0985742    0\n",
       "  17 │ 2255                     26190.7   0.0267554  0.0945938  0.0948924    0 ⋯\n",
       "  18 │ 2270                     25982.6   0.023722   0.0920389  0.0931356    0\n",
       "  19 │ 2285                     25805.7   0.0219315  0.0912153  0.0914018    0\n",
       "  20 │ 2300                     25731.7   0.0211176  0.090532   0.0900101    0\n",
       "  21 │ total_%_decrease         24.5168   87.7389    61.1231    56.2322      9 ⋯\n",
       "\u001b[36m                                                               2 columns omitted\u001b[0m"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function get_up_low(post_dict, upper_quant, lower_quant, γ0_is_log)\n",
    "    p = [upper_quant,lower_quant]\n",
    "    quantiles = zeros(19, 6, 2)\n",
    "    sorted_keys = sort(collect(keys(post_dict)))\n",
    "    # Adjust for when gamma_0 is considered on the log scale\n",
    "\n",
    "        for i in 1:19\n",
    "            mat = post_dict[ sorted_keys[i] ]\n",
    "            quantiles[i, 1,:] = quantile( mat[:,1], p )\n",
    "            quantiles[i, 2,:] = quantile( mat[:,2], p )\n",
    "            quantiles[i, 3,:] = quantile( mat[:,3], p )\n",
    "            quantiles[i, 4,:] = quantile( mat[:,4], p )\n",
    "            quantiles[i, 5,:] = (γ0_is_log) ? quantile( np.log(mat[:,5]), p ) : quantile( mat[:,5], p )\n",
    "            quantiles[i, 6,:] = quantile( mat[:,6], p )\n",
    "        end\n",
    "\n",
    "    return quantiles\n",
    "end\n",
    "\n",
    "Realizations = [string(i) for i in 1:100];\n",
    "cal_years = collect(range(2015,step=15,length=20));\n",
    "\n",
    "# Load the present day posteriors \n",
    "gamma_0_is_log = true\n",
    "present_posterior = np.load(\"../Data/Training_Data/posterior_samples_All_Combined.npy\");\n",
    "\n",
    "# Compute upper and lower quantile bounds for present day posteriors\n",
    "present_bounds = []\n",
    "present_widths = []\n",
    "for i in 1:6\n",
    "    lower = (i == 5 && gamma_0_is_log) ? quantile(np.log(present_posterior[:,i]), 0.05) : quantile(present_posterior[:,i], 0.05)\n",
    "    upper = (i == 5 && gamma_0_is_log) ? quantile(np.log(present_posterior[:,i]), 0.95) : quantile(present_posterior[:,i], 0.95)\n",
    "    push!(present_bounds, (lower,upper))\n",
    "    push!(present_widths, upper - lower)\n",
    "end\n",
    "present_bounds = reshape(present_bounds, 1, :)\n",
    "present_widths = reshape(present_widths, 1, :);\n",
    "\n",
    "\n",
    "# Change to wherever your posterior dictionaries are located\n",
    "path_to_posteriors = \"../Data/Posterior_Data\"\n",
    "\n",
    "# Initialize empty vectors to hold interval bounds and widths \n",
    "all_widths = zeros(length(Realizations),19,6)\n",
    "all_bounds = zeros(length(Realizations), 19, 6, 2)\n",
    "\n",
    "\n",
    "# Loop to calculate quantiles and credible interval widths\n",
    "    for (iter, r) in enumerate(Realizations)\n",
    "        post = JLD2.load(\"$(path_to_posteriors)/R_$(r)_Posterior_Dict.jld2\", \"post_data\")\n",
    "        cred_int_90_up_low = get_up_low(post, 0.95, 0.05,gamma_0_is_log)\n",
    "        all_bounds[iter, :, :, :] = cred_int_90_up_low\n",
    "        all_widths[iter,:,:] = cred_int_90_up_low[:,:,1] .- cred_int_90_up_low[:,:,2]\n",
    "    end\n",
    "# The average 5th percentile and and 95th percentiles of the six MALI parameters across all trajectories over the 19 years of calibration\n",
    "avg_bounds = mean(all_bounds,dims=1)\n",
    "avg_bounds = dropdims(avg_bounds, dims=1)\n",
    "\n",
    "# The average 90% credible interval widths of the six MALI parameters across all trajectories for each of the 19 years of calibration\n",
    "avg_widths = mean(all_widths,dims=1)\n",
    "avg_widths = dropdims(avg_widths, dims=1)\n",
    "println(size(avg_widths))\n",
    "# The 17% and 83% quantiles of the 90% cred int widths of the six MALI parameters across all trajectories for each of the 19 years of calibration\n",
    "width_variation_interval = np.quantile(all_widths, 0.83,axis=0) .- np.quantile(all_widths, 0.17,axis=0)\n",
    "\n",
    "\n",
    "# Store the bounds as tuples in one matrix\n",
    "bounds_as_tuples = fill((0.0,0.0),(19,6))\n",
    "for i in 1:19\n",
    "    for j in 1:6\n",
    "        bounds_as_tuples[i,j] = (avg_bounds[i,j,2], avg_bounds[i,j,1])\n",
    "    end\n",
    "end\n",
    "# Add the 2015 90% credible interval bounds\n",
    "bounds_w_present = vcat(present_bounds, bounds_as_tuples);\n",
    "\n",
    "# Add the 2015 90% credible widths\n",
    "widths_w_present = vcat(present_widths, avg_widths);\n",
    "\n",
    "\n",
    "# Add the years of calibration as another column\n",
    "bounds_w_years = hcat(cal_years, bounds_w_present)\n",
    "widths_w_years = hcat(cal_years, widths_w_present)\n",
    "width_var_w_years = hcat(cal_years[2:end], width_variation_interval)\n",
    "\n",
    "# Dataframe column names\n",
    "names = [\"Latest_calibration_year\",\"vmThresh\",\"fricExp\",\"mu_scale\",\"stiff_scale\",\"gamma0\",\"melt_flux\"]\n",
    "\n",
    "# Covnert to datframe before saving to disc\n",
    "params_df_bounds = DataFrame(bounds_w_years, names)\n",
    "params_df_widths = DataFrame(widths_w_years, names)\n",
    "params_df_width_var = DataFrame(width_var_w_years, names)\n",
    "\n",
    "#Calculate total percent decrease of 90% cred interval width\n",
    "pct_change = ((collect(params_df_widths[1,2:end]) .- collect(params_df_widths[20,2:end])) ./ collect(params_df_widths[1,2:end])) .* 100\n",
    "# Make a 1×7 row: first element is label, then pct_change values\n",
    "new_row = hcat(\"total_%_decrease\", pct_change...)\n",
    "# Convert to DataFrame with the same column names\n",
    "new_df = DataFrame(new_row, names)\n",
    "# Append to params_df_widths\n",
    "append!(params_df_widths, new_df)\n",
    "\n",
    "\n",
    "# CSV.write(\"../Data/Parameter_Learning_Tables/param_90_CI_bounds_log_gamma0_$(gamma_0_is_log).csv\",params_df_bounds)\n",
    "# CSV.write(\"../Data/Parameter_Learning_Tables/param_90_CI_widths_log_gamma0_$(gamma_0_is_log).csv\",params_df_widths)\n",
    "# CSV.write(\"../Data/Parameter_Learning_Tables/param_90_CI_variation_log_gamma0_$(gamma_0_is_log).csv\",   params_df_width_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "69f30841-4e55-47df-a0a5-03609ccc5678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>20×13 DataFrame</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">LearningPeriod</th><th style = \"text-align: left;\">ΔvmThresh</th><th style = \"text-align: left;\">Δ_%_vmThresh</th><th style = \"text-align: left;\">Δ_fricExp</th><th style = \"text-align: left;\">Δ_%_fricExp</th><th style = \"text-align: left;\">Δ_mu_scale</th><th style = \"text-align: left;\">Δ_%_mu_scale</th><th style = \"text-align: left;\">Δ_stiff_scale</th><th style = \"text-align: left;\">Δ_%_stiff_scale</th><th style = \"text-align: left;\">Δ_gamma0</th><th style = \"text-align: left;\">Δ_%_gamma0</th><th style = \"text-align: left;\">Δ_melt_flux</th><th style = \"text-align: left;\">Δ_%_melt_flux</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"Any\" style = \"text-align: left;\">Any</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: left;\">2015 - 2030</td><td style = \"text-align: left;\">-308.545</td><td style = \"text-align: left;\">3.69178</td><td style = \"text-align: left;\">-0.00499717</td><td style = \"text-align: left;\">3.30688</td><td style = \"text-align: left;\">-0.0199084</td><td style = \"text-align: left;\">13.9869</td><td style = \"text-align: left;\">-0.00978005</td><td style = \"text-align: left;\">8.45708</td><td style = \"text-align: left;\">-0.0647679</td><td style = \"text-align: left;\">2.83889</td><td style = \"text-align: left;\">-0.109738</td><td style = \"text-align: left;\">0.935563</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: left;\">2030 - 2045</td><td style = \"text-align: left;\">-15.5338</td><td style = \"text-align: left;\">0.185864</td><td style = \"text-align: left;\">-0.00828424</td><td style = \"text-align: left;\">5.4821</td><td style = \"text-align: left;\">-0.00453845</td><td style = \"text-align: left;\">3.18854</td><td style = \"text-align: left;\">-0.00531249</td><td style = \"text-align: left;\">4.59386</td><td style = \"text-align: left;\">-0.210791</td><td style = \"text-align: left;\">9.23934</td><td style = \"text-align: left;\">-0.191358</td><td style = \"text-align: left;\">1.63141</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: left;\">2045 - 2060</td><td style = \"text-align: left;\">-122.379</td><td style = \"text-align: left;\">1.46428</td><td style = \"text-align: left;\">-0.00178388</td><td style = \"text-align: left;\">1.18048</td><td style = \"text-align: left;\">-0.00177861</td><td style = \"text-align: left;\">1.24958</td><td style = \"text-align: left;\">-0.00371431</td><td style = \"text-align: left;\">3.21187</td><td style = \"text-align: left;\">-0.455934</td><td style = \"text-align: left;\">19.9844</td><td style = \"text-align: left;\">-0.364953</td><td style = \"text-align: left;\">3.11139</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4</td><td style = \"text-align: left;\">2060 - 2075</td><td style = \"text-align: left;\">-167.098</td><td style = \"text-align: left;\">1.99935</td><td style = \"text-align: left;\">-0.00372934</td><td style = \"text-align: left;\">2.46789</td><td style = \"text-align: left;\">-0.00314946</td><td style = \"text-align: left;\">2.21269</td><td style = \"text-align: left;\">-0.00529938</td><td style = \"text-align: left;\">4.58252</td><td style = \"text-align: left;\">-0.55393</td><td style = \"text-align: left;\">24.2797</td><td style = \"text-align: left;\">-1.69436</td><td style = \"text-align: left;\">14.4451</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5</td><td style = \"text-align: left;\">2075 - 2090</td><td style = \"text-align: left;\">-321.917</td><td style = \"text-align: left;\">3.85177</td><td style = \"text-align: left;\">-0.00170556</td><td style = \"text-align: left;\">1.12866</td><td style = \"text-align: left;\">-0.00494637</td><td style = \"text-align: left;\">3.47513</td><td style = \"text-align: left;\">-0.00561054</td><td style = \"text-align: left;\">4.85159</td><td style = \"text-align: left;\">-0.0411684</td><td style = \"text-align: left;\">1.80448</td><td style = \"text-align: left;\">-1.21598</td><td style = \"text-align: left;\">10.3668</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">6</td><td style = \"text-align: left;\">2090 - 2105</td><td style = \"text-align: left;\">-538.596</td><td style = \"text-align: left;\">6.44437</td><td style = \"text-align: left;\">-0.0058047</td><td style = \"text-align: left;\">3.84127</td><td style = \"text-align: left;\">-0.0168463</td><td style = \"text-align: left;\">11.8356</td><td style = \"text-align: left;\">-0.0112585</td><td style = \"text-align: left;\">9.73551</td><td style = \"text-align: left;\">-0.0666812</td><td style = \"text-align: left;\">2.92275</td><td style = \"text-align: left;\">-0.40298</td><td style = \"text-align: left;\">3.43558</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">7</td><td style = \"text-align: left;\">2105 - 2120</td><td style = \"text-align: left;\">-247.567</td><td style = \"text-align: left;\">2.96217</td><td style = \"text-align: left;\">-0.00649159</td><td style = \"text-align: left;\">4.29581</td><td style = \"text-align: left;\">-0.00608864</td><td style = \"text-align: left;\">4.27765</td><td style = \"text-align: left;\">-0.00357312</td><td style = \"text-align: left;\">3.08977</td><td style = \"text-align: left;\">-0.118359</td><td style = \"text-align: left;\">5.18788</td><td style = \"text-align: left;\">-0.295708</td><td style = \"text-align: left;\">2.52104</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">8</td><td style = \"text-align: left;\">2120 - 2135</td><td style = \"text-align: left;\">-396.591</td><td style = \"text-align: left;\">4.74526</td><td style = \"text-align: left;\">-0.00358477</td><td style = \"text-align: left;\">2.37222</td><td style = \"text-align: left;\">-0.00296495</td><td style = \"text-align: left;\">2.08306</td><td style = \"text-align: left;\">-0.00619757</td><td style = \"text-align: left;\">5.35921</td><td style = \"text-align: left;\">-0.121818</td><td style = \"text-align: left;\">5.33949</td><td style = \"text-align: left;\">-1.96177</td><td style = \"text-align: left;\">16.725</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">9</td><td style = \"text-align: left;\">2135 - 2150</td><td style = \"text-align: left;\">-293.688</td><td style = \"text-align: left;\">3.51401</td><td style = \"text-align: left;\">-0.0040266</td><td style = \"text-align: left;\">2.6646</td><td style = \"text-align: left;\">-0.00290024</td><td style = \"text-align: left;\">2.0376</td><td style = \"text-align: left;\">-0.00486038</td><td style = \"text-align: left;\">4.2029</td><td style = \"text-align: left;\">-0.119725</td><td style = \"text-align: left;\">5.24774</td><td style = \"text-align: left;\">-0.744808</td><td style = \"text-align: left;\">6.34982</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">10</td><td style = \"text-align: left;\">2150 - 2165</td><td style = \"text-align: left;\">-964.573</td><td style = \"text-align: left;\">11.5412</td><td style = \"text-align: left;\">-0.00661458</td><td style = \"text-align: left;\">4.37721</td><td style = \"text-align: left;\">-0.00893586</td><td style = \"text-align: left;\">6.278</td><td style = \"text-align: left;\">-0.0119692</td><td style = \"text-align: left;\">10.3501</td><td style = \"text-align: left;\">-0.0808131</td><td style = \"text-align: left;\">3.54218</td><td style = \"text-align: left;\">-1.84135</td><td style = \"text-align: left;\">15.6983</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">11</td><td style = \"text-align: left;\">2165 - 2180</td><td style = \"text-align: left;\">-1686.36</td><td style = \"text-align: left;\">20.1775</td><td style = \"text-align: left;\">-0.0149479</td><td style = \"text-align: left;\">9.89181</td><td style = \"text-align: left;\">-0.016751</td><td style = \"text-align: left;\">11.7686</td><td style = \"text-align: left;\">-0.0119412</td><td style = \"text-align: left;\">10.3259</td><td style = \"text-align: left;\">-0.124965</td><td style = \"text-align: left;\">5.47744</td><td style = \"text-align: left;\">-0.284675</td><td style = \"text-align: left;\">2.42698</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">12</td><td style = \"text-align: left;\">2180 - 2195</td><td style = \"text-align: left;\">-718.861</td><td style = \"text-align: left;\">8.60126</td><td style = \"text-align: left;\">-0.0193752</td><td style = \"text-align: left;\">12.8216</td><td style = \"text-align: left;\">-0.0221357</td><td style = \"text-align: left;\">15.5517</td><td style = \"text-align: left;\">-0.0123007</td><td style = \"text-align: left;\">10.6367</td><td style = \"text-align: left;\">-0.162757</td><td style = \"text-align: left;\">7.13391</td><td style = \"text-align: left;\">-0.512709</td><td style = \"text-align: left;\">4.37107</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">13</td><td style = \"text-align: left;\">2195 - 2210</td><td style = \"text-align: left;\">-616.187</td><td style = \"text-align: left;\">7.37275</td><td style = \"text-align: left;\">-0.024443</td><td style = \"text-align: left;\">16.1752</td><td style = \"text-align: left;\">-0.0161101</td><td style = \"text-align: left;\">11.3183</td><td style = \"text-align: left;\">-0.00865414</td><td style = \"text-align: left;\">7.48347</td><td style = \"text-align: left;\">-0.0417534</td><td style = \"text-align: left;\">1.83013</td><td style = \"text-align: left;\">-0.634782</td><td style = \"text-align: left;\">5.4118</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">14</td><td style = \"text-align: left;\">2210 - 2225</td><td style = \"text-align: left;\">-1071.7</td><td style = \"text-align: left;\">12.823</td><td style = \"text-align: left;\">-0.0243698</td><td style = \"text-align: left;\">16.1267</td><td style = \"text-align: left;\">-0.0068389</td><td style = \"text-align: left;\">4.80475</td><td style = \"text-align: left;\">-0.00618077</td><td style = \"text-align: left;\">5.34469</td><td style = \"text-align: left;\">-0.0527569</td><td style = \"text-align: left;\">2.31243</td><td style = \"text-align: left;\">-0.251814</td><td style = \"text-align: left;\">2.14683</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">15</td><td style = \"text-align: left;\">2225 - 2240</td><td style = \"text-align: left;\">-196.089</td><td style = \"text-align: left;\">2.34623</td><td style = \"text-align: left;\">-0.00977141</td><td style = \"text-align: left;\">6.46624</td><td style = \"text-align: left;\">-0.00096097</td><td style = \"text-align: left;\">0.675141</td><td style = \"text-align: left;\">-0.000426912</td><td style = \"text-align: left;\">0.369163</td><td style = \"text-align: left;\">-0.0196073</td><td style = \"text-align: left;\">0.859424</td><td style = \"text-align: left;\">-0.293243</td><td style = \"text-align: left;\">2.50003</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">16</td><td style = \"text-align: left;\">2240 - 2255</td><td style = \"text-align: left;\">-232.935</td><td style = \"text-align: left;\">2.78709</td><td style = \"text-align: left;\">-0.00554666</td><td style = \"text-align: left;\">3.67051</td><td style = \"text-align: left;\">-0.00342037</td><td style = \"text-align: left;\">2.40303</td><td style = \"text-align: left;\">-0.00368177</td><td style = \"text-align: left;\">3.18373</td><td style = \"text-align: left;\">-0.0169904</td><td style = \"text-align: left;\">0.744721</td><td style = \"text-align: left;\">-0.272976</td><td style = \"text-align: left;\">2.32724</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">17</td><td style = \"text-align: left;\">2255 - 2270</td><td style = \"text-align: left;\">-208.125</td><td style = \"text-align: left;\">2.49024</td><td style = \"text-align: left;\">-0.00303334</td><td style = \"text-align: left;\">2.00732</td><td style = \"text-align: left;\">-0.00255489</td><td style = \"text-align: left;\">1.79497</td><td style = \"text-align: left;\">-0.00175677</td><td style = \"text-align: left;\">1.51913</td><td style = \"text-align: left;\">-0.0120906</td><td style = \"text-align: left;\">0.529954</td><td style = \"text-align: left;\">-0.278997</td><td style = \"text-align: left;\">2.37857</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">18</td><td style = \"text-align: left;\">2270 - 2285</td><td style = \"text-align: left;\">-176.922</td><td style = \"text-align: left;\">2.11689</td><td style = \"text-align: left;\">-0.00179055</td><td style = \"text-align: left;\">1.1849</td><td style = \"text-align: left;\">-0.000823553</td><td style = \"text-align: left;\">0.578597</td><td style = \"text-align: left;\">-0.00173379</td><td style = \"text-align: left;\">1.49926</td><td style = \"text-align: left;\">-0.0107193</td><td style = \"text-align: left;\">0.469845</td><td style = \"text-align: left;\">-0.159063</td><td style = \"text-align: left;\">1.35608</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">19</td><td style = \"text-align: left;\">2285 - 2300</td><td style = \"text-align: left;\">-73.9552</td><td style = \"text-align: left;\">0.884883</td><td style = \"text-align: left;\">-0.000813894</td><td style = \"text-align: left;\">0.538595</td><td style = \"text-align: left;\">-0.000683377</td><td style = \"text-align: left;\">0.480115</td><td style = \"text-align: left;\">-0.00139174</td><td style = \"text-align: left;\">1.20347</td><td style = \"text-align: left;\">-0.00582455</td><td style = \"text-align: left;\">0.2553</td><td style = \"text-align: left;\">-0.218327</td><td style = \"text-align: left;\">1.86134</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">20</td><td style = \"text-align: left;\">2015 - 2300</td><td style = \"text-align: left;\">-8357.62</td><td style = \"text-align: left;\">100.0</td><td style = \"text-align: left;\">-0.151114</td><td style = \"text-align: left;\">100.0</td><td style = \"text-align: left;\">-0.142336</td><td style = \"text-align: left;\">100.0</td><td style = \"text-align: left;\">-0.115643</td><td style = \"text-align: left;\">100.0</td><td style = \"text-align: left;\">-2.28145</td><td style = \"text-align: left;\">100.0</td><td style = \"text-align: left;\">-11.7296</td><td style = \"text-align: left;\">100.0</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccc}\n",
       "\t& LearningPeriod & ΔvmThresh & Δ\\_\\%\\_vmThresh & Δ\\_fricExp & Δ\\_\\%\\_fricExp & Δ\\_mu\\_scale & \\\\\n",
       "\t\\hline\n",
       "\t& Any & Any & Any & Any & Any & Any & \\\\\n",
       "\t\\hline\n",
       "\t1 & 2015 - 2030 & -308.545 & 3.69178 & -0.00499717 & 3.30688 & -0.0199084 & $\\dots$ \\\\\n",
       "\t2 & 2030 - 2045 & -15.5338 & 0.185864 & -0.00828424 & 5.4821 & -0.00453845 & $\\dots$ \\\\\n",
       "\t3 & 2045 - 2060 & -122.379 & 1.46428 & -0.00178388 & 1.18048 & -0.00177861 & $\\dots$ \\\\\n",
       "\t4 & 2060 - 2075 & -167.098 & 1.99935 & -0.00372934 & 2.46789 & -0.00314946 & $\\dots$ \\\\\n",
       "\t5 & 2075 - 2090 & -321.917 & 3.85177 & -0.00170556 & 1.12866 & -0.00494637 & $\\dots$ \\\\\n",
       "\t6 & 2090 - 2105 & -538.596 & 6.44437 & -0.0058047 & 3.84127 & -0.0168463 & $\\dots$ \\\\\n",
       "\t7 & 2105 - 2120 & -247.567 & 2.96217 & -0.00649159 & 4.29581 & -0.00608864 & $\\dots$ \\\\\n",
       "\t8 & 2120 - 2135 & -396.591 & 4.74526 & -0.00358477 & 2.37222 & -0.00296495 & $\\dots$ \\\\\n",
       "\t9 & 2135 - 2150 & -293.688 & 3.51401 & -0.0040266 & 2.6646 & -0.00290024 & $\\dots$ \\\\\n",
       "\t10 & 2150 - 2165 & -964.573 & 11.5412 & -0.00661458 & 4.37721 & -0.00893586 & $\\dots$ \\\\\n",
       "\t11 & 2165 - 2180 & -1686.36 & 20.1775 & -0.0149479 & 9.89181 & -0.016751 & $\\dots$ \\\\\n",
       "\t12 & 2180 - 2195 & -718.861 & 8.60126 & -0.0193752 & 12.8216 & -0.0221357 & $\\dots$ \\\\\n",
       "\t13 & 2195 - 2210 & -616.187 & 7.37275 & -0.024443 & 16.1752 & -0.0161101 & $\\dots$ \\\\\n",
       "\t14 & 2210 - 2225 & -1071.7 & 12.823 & -0.0243698 & 16.1267 & -0.0068389 & $\\dots$ \\\\\n",
       "\t15 & 2225 - 2240 & -196.089 & 2.34623 & -0.00977141 & 6.46624 & -0.00096097 & $\\dots$ \\\\\n",
       "\t16 & 2240 - 2255 & -232.935 & 2.78709 & -0.00554666 & 3.67051 & -0.00342037 & $\\dots$ \\\\\n",
       "\t17 & 2255 - 2270 & -208.125 & 2.49024 & -0.00303334 & 2.00732 & -0.00255489 & $\\dots$ \\\\\n",
       "\t18 & 2270 - 2285 & -176.922 & 2.11689 & -0.00179055 & 1.1849 & -0.000823553 & $\\dots$ \\\\\n",
       "\t19 & 2285 - 2300 & -73.9552 & 0.884883 & -0.000813894 & 0.538595 & -0.000683377 & $\\dots$ \\\\\n",
       "\t20 & 2015 - 2300 & -8357.62 & 100.0 & -0.151114 & 100.0 & -0.142336 & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m20×13 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m LearningPeriod \u001b[0m\u001b[1m ΔvmThresh \u001b[0m\u001b[1m Δ_%_vmThresh \u001b[0m\u001b[1m Δ_fricExp    \u001b[0m\u001b[1m Δ_%_fricExp \u001b[0m\u001b[1m Δ_m\u001b[0m ⋯\n",
       "     │\u001b[90m Any            \u001b[0m\u001b[90m Any       \u001b[0m\u001b[90m Any          \u001b[0m\u001b[90m Any          \u001b[0m\u001b[90m Any         \u001b[0m\u001b[90m Any\u001b[0m ⋯\n",
       "─────┼──────────────────────────────────────────────────────────────────────────\n",
       "   1 │ 2015 - 2030     -308.545   3.69178       -0.00499717   3.30688      -0. ⋯\n",
       "   2 │ 2030 - 2045     -15.5338   0.185864      -0.00828424   5.4821       -0.\n",
       "   3 │ 2045 - 2060     -122.379   1.46428       -0.00178388   1.18048      -0.\n",
       "   4 │ 2060 - 2075     -167.098   1.99935       -0.00372934   2.46789      -0.\n",
       "   5 │ 2075 - 2090     -321.917   3.85177       -0.00170556   1.12866      -0. ⋯\n",
       "   6 │ 2090 - 2105     -538.596   6.44437       -0.0058047    3.84127      -0.\n",
       "   7 │ 2105 - 2120     -247.567   2.96217       -0.00649159   4.29581      -0.\n",
       "   8 │ 2120 - 2135     -396.591   4.74526       -0.00358477   2.37222      -0.\n",
       "   9 │ 2135 - 2150     -293.688   3.51401       -0.0040266    2.6646       -0. ⋯\n",
       "  10 │ 2150 - 2165     -964.573   11.5412       -0.00661458   4.37721      -0.\n",
       "  11 │ 2165 - 2180     -1686.36   20.1775       -0.0149479    9.89181      -0.\n",
       "  12 │ 2180 - 2195     -718.861   8.60126       -0.0193752    12.8216      -0.\n",
       "  13 │ 2195 - 2210     -616.187   7.37275       -0.024443     16.1752      -0. ⋯\n",
       "  14 │ 2210 - 2225     -1071.7    12.823        -0.0243698    16.1267      -0.\n",
       "  15 │ 2225 - 2240     -196.089   2.34623       -0.00977141   6.46624      -0.\n",
       "  16 │ 2240 - 2255     -232.935   2.78709       -0.00554666   3.67051      -0.\n",
       "  17 │ 2255 - 2270     -208.125   2.49024       -0.00303334   2.00732      -0. ⋯\n",
       "  18 │ 2270 - 2285     -176.922   2.11689       -0.00179055   1.1849       -0.\n",
       "  19 │ 2285 - 2300     -73.9552   0.884883      -0.000813894  0.538595     -0.\n",
       "  20 │ 2015 - 2300     -8357.62   100.0         -0.151114     100.0        -0.\n",
       "\u001b[36m                                                               8 columns omitted\u001b[0m"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##CALCULATING THE YEAR BY YEAR CHANGE IN UNCERTAINTY RANGES FOR EACH PARAMETER, AS WELL AS PERCENT CONTRIBUTION TO TOTAL LEARNING\n",
    "##\n",
    "cal_years = collect(range(2015,step=15,length=20))\n",
    "\n",
    "Δ_param_width = zeros(20, 6)\n",
    "Δ_param_width_pct = zeros(20, 6)\n",
    "\n",
    "#Total learning from 2015 - 2300\n",
    "\n",
    "# find row indices\n",
    "total_idx1 = only(findall(x -> x == 2015, cal_years))\n",
    "total_idx2 = only(findall(x -> x == 2300, cal_years))\n",
    "\n",
    "# extract vectors (dropping year column)\n",
    "present = collect(params_df_widths[total_idx1, :])[2:end]\n",
    "final = collect(params_df_widths[total_idx2, :])[2:end]\n",
    "\n",
    "# compute differences\n",
    "total_diff = final .- present\n",
    "Δ_param_width[20, :] = total_diff\n",
    "Δ_param_width_pct[20,:] .= 100.0\n",
    "\n",
    "learn_periods = []\n",
    "\n",
    "for i in 1:(length(cal_years)-1)\n",
    "    yr1 = cal_years[i]\n",
    "    yr2 = cal_years[i+1]\n",
    "\n",
    "    # find row indices\n",
    "    row_idx1 = only(findall(x -> x == yr1, cal_years))\n",
    "    row_idx2 = only(findall(x -> x == yr2, cal_years))\n",
    "\n",
    "    # extract vectors (dropping year column)\n",
    "    row1 = collect(params_df_widths[row_idx1, :])[2:end]\n",
    "    row2 = collect(params_df_widths[row_idx2, :])[2:end]\n",
    "\n",
    "    # compute differences\n",
    "    diff = row2 .- row1\n",
    "    Δ_param_width[i, :] = diff\n",
    "    Δ_param_width_pct[i, :] = (diff ./ total_diff) .* 100\n",
    "    # Collect this learning period as string for datframe labels\n",
    "    push!(learn_periods, \"$(yr1) - $(yr2)\")\n",
    "end\n",
    "\n",
    "# Add the total learning period\n",
    "push!(learn_periods, \"2015 - 2300\")\n",
    "width_change_mat = zeros(20,12)\n",
    "\n",
    "# Put the parameter width changes and percent changes together param by param columnwise\n",
    "for i in 1:6\n",
    "    width_change_mat[:,(2*i)-1] = Δ_param_width[:,i]\n",
    "    width_change_mat[:,(2*i)] = Δ_param_width_pct[:,i]\n",
    "end\n",
    "\n",
    "\n",
    "names = [\"LearningPeriod\",\"ΔvmThresh\",\"Δ_%_vmThresh\",\"Δ_fricExp\",\"Δ_%_fricExp\",\"Δ_mu_scale\",\"Δ_%_mu_scale\",\"Δ_stiff_scale\",\"Δ_%_stiff_scale\",\"Δ_gamma0\",\"Δ_%_gamma0\",\"Δ_melt_flux\",\"Δ_%_melt_flux\"]\n",
    "width_change_w_years = hcat(learn_periods, width_change_mat)\n",
    "df_bounds_yr_to_yr = DataFrame(width_change_w_years, names)\n",
    "# CSV.write(\"../Data/Parameter_Learning_Tables/yr_to_yr_change_in_widths_log_gamma0_$(gamma_0_is_log).csv\", df_bounds_yr_to_yr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8b4034d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.00000000000001\n"
     ]
    }
   ],
   "source": [
    "println(sum(df_bounds_yr_to_yr[1:5, 11]) + sum(df_bounds_yr_to_yr[6:13, 11]) + sum(df_bounds_yr_to_yr[14:19, 11]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e662d9ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Δ_%_vmThresh decrease from 2015 to 2090: \n",
      "11.193044442419605\n",
      "Δ_%_fricExp decrease from 2015 to 2090: \n",
      "13.56602081348913\n",
      "Δ_%_mu_scale decrease from 2015 to 2090: \n",
      "24.11285593408966\n",
      "Δ_%_stiff_scale decrease from 2015 to 2090: \n",
      "25.69691638711342\n",
      "Δ_%_gamma0 decrease from 2015 to 2090: \n",
      "58.146813524449946\n",
      "Δ_%_melt_flux decrease from 2015 to 2090: \n",
      "30.490298144376688\n"
     ]
    }
   ],
   "source": [
    "cols = [3,5,7,9,11,13]\n",
    "for (i,col) in enumerate(cols)\n",
    "    println(\"$(names[2i+1]) decrease from 2015 to 2090: \")\n",
    "    println(sum(df_bounds_yr_to_yr[1:5, col]))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "46313e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Δ_%_vmThresh decrease from 2090 to 2210: \n",
      "65.35858638372444\n",
      "Δ_%_fricExp decrease from 2090 to 2210: \n",
      "56.43968759374293\n",
      "Δ_%_mu_scale decrease from 2090 to 2210: \n",
      "65.15053906260987\n",
      "Δ_%_stiff_scale decrease from 2090 to 2210: \n",
      "61.183643628975034\n",
      "Δ_%_gamma0 decrease from 2090 to 2210: \n",
      "36.681516511449466\n",
      "Δ_%_melt_flux decrease from 2090 to 2210: \n",
      "56.939614177713494\n"
     ]
    }
   ],
   "source": [
    "cols = [3,5,7,9,11,13]\n",
    "for (i,col) in enumerate(cols)\n",
    "    println(\"$(names[2i+1]) decrease from 2090 to 2210: \")\n",
    "    println(sum(df_bounds_yr_to_yr[6:13, col]))\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ec208a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Δ_%_vmThresh decrease from 2210 to 2300: \n",
      "23.448369173855948\n",
      "Δ_%_fricExp decrease from 2210 to 2300: \n",
      "29.99429159276793\n",
      "Δ_%_mu_scale decrease from 2210 to 2300: \n",
      "10.736605003300483\n",
      "Δ_%_stiff_scale decrease from 2210 to 2300: \n",
      "13.119439983911551\n",
      "Δ_%_gamma0 decrease from 2210 to 2300: \n",
      "5.171669964100604\n",
      "Δ_%_melt_flux decrease from 2210 to 2300: \n",
      "12.570087677909815\n"
     ]
    }
   ],
   "source": [
    "cols = [3,5,7,9,11,13]\n",
    "for (i,col) in enumerate(cols)\n",
    "    println(\"$(names[2i+1]) decrease from 2210 to 2300: \")\n",
    "    println(sum(df_bounds_yr_to_yr[14:19, col]))\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9f9e18f4-875e-46a2-bc3e-318afd6d173a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>19×13 DataFrame</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">LearningPeriod</th><th style = \"text-align: left;\">ΔvmThresh</th><th style = \"text-align: left;\">Δ_%_vmThresh</th><th style = \"text-align: left;\">Δ_fricExp</th><th style = \"text-align: left;\">Δ_%_fricExp</th><th style = \"text-align: left;\">Δ_mu_scale</th><th style = \"text-align: left;\">Δ_%_mu_scale</th><th style = \"text-align: left;\">Δ_stiff_scale</th><th style = \"text-align: left;\">Δ_%_stiff_scale</th><th style = \"text-align: left;\">Δ_gamma0</th><th style = \"text-align: left;\">Δ_%_gamma0</th><th style = \"text-align: left;\">Δ_melt_flux</th><th style = \"text-align: left;\">Δ_%_melt_flux</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"Any\" style = \"text-align: left;\">Any</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: left;\">2030 - 2045</td><td style = \"text-align: left;\">2950.94</td><td style = \"text-align: left;\">69.4426</td><td style = \"text-align: left;\">0.0109701</td><td style = \"text-align: left;\">-935.296</td><td style = \"text-align: left;\">0.044943</td><td style = \"text-align: left;\">98.3006</td><td style = \"text-align: left;\">0.0399945</td><td style = \"text-align: left;\">117.005</td><td style = \"text-align: left;\">0.364371</td><td style = \"text-align: left;\">-1085.09</td><td style = \"text-align: left;\">0.529161</td><td style = \"text-align: left;\">14.3511</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: left;\">2045 - 2060</td><td style = \"text-align: left;\">49.035</td><td style = \"text-align: left;\">1.15391</td><td style = \"text-align: left;\">0.000996436</td><td style = \"text-align: left;\">-84.9549</td><td style = \"text-align: left;\">0.0113058</td><td style = \"text-align: left;\">24.7283</td><td style = \"text-align: left;\">0.00455269</td><td style = \"text-align: left;\">13.319</td><td style = \"text-align: left;\">-0.101516</td><td style = \"text-align: left;\">302.313</td><td style = \"text-align: left;\">0.778981</td><td style = \"text-align: left;\">21.1263</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: left;\">2060 - 2075</td><td style = \"text-align: left;\">857.073</td><td style = \"text-align: left;\">20.169</td><td style = \"text-align: left;\">0.00453659</td><td style = \"text-align: left;\">-386.784</td><td style = \"text-align: left;\">0.0132468</td><td style = \"text-align: left;\">28.9738</td><td style = \"text-align: left;\">0.00461352</td><td style = \"text-align: left;\">13.4969</td><td style = \"text-align: left;\">-0.188508</td><td style = \"text-align: left;\">561.372</td><td style = \"text-align: left;\">1.47982</td><td style = \"text-align: left;\">40.1333</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4</td><td style = \"text-align: left;\">2075 - 2090</td><td style = \"text-align: left;\">346.907</td><td style = \"text-align: left;\">8.16355</td><td style = \"text-align: left;\">0.00717519</td><td style = \"text-align: left;\">-611.748</td><td style = \"text-align: left;\">-0.00394326</td><td style = \"text-align: left;\">-8.62479</td><td style = \"text-align: left;\">0.00473843</td><td style = \"text-align: left;\">13.8624</td><td style = \"text-align: left;\">-0.00993051</td><td style = \"text-align: left;\">29.5728</td><td style = \"text-align: left;\">1.29808</td><td style = \"text-align: left;\">35.2046</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5</td><td style = \"text-align: left;\">2090 - 2105</td><td style = \"text-align: left;\">173.415</td><td style = \"text-align: left;\">4.08086</td><td style = \"text-align: left;\">0.0113467</td><td style = \"text-align: left;\">-967.404</td><td style = \"text-align: left;\">0.0291168</td><td style = \"text-align: left;\">63.685</td><td style = \"text-align: left;\">-3.90227e-6</td><td style = \"text-align: left;\">-0.0114162</td><td style = \"text-align: left;\">0.138624</td><td style = \"text-align: left;\">-412.819</td><td style = \"text-align: left;\">0.987398</td><td style = \"text-align: left;\">26.7787</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">6</td><td style = \"text-align: left;\">2105 - 2120</td><td style = \"text-align: left;\">-222.925</td><td style = \"text-align: left;\">-5.24596</td><td style = \"text-align: left;\">0.00481601</td><td style = \"text-align: left;\">-410.606</td><td style = \"text-align: left;\">0.00548521</td><td style = \"text-align: left;\">11.9974</td><td style = \"text-align: left;\">0.00696103</td><td style = \"text-align: left;\">20.3646</td><td style = \"text-align: left;\">-0.083712</td><td style = \"text-align: left;\">249.292</td><td style = \"text-align: left;\">-0.215089</td><td style = \"text-align: left;\">-5.8333</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">7</td><td style = \"text-align: left;\">2120 - 2135</td><td style = \"text-align: left;\">-813.782</td><td style = \"text-align: left;\">-19.1502</td><td style = \"text-align: left;\">0.00622987</td><td style = \"text-align: left;\">-531.15</td><td style = \"text-align: left;\">0.00188271</td><td style = \"text-align: left;\">4.11792</td><td style = \"text-align: left;\">-0.00312091</td><td style = \"text-align: left;\">-9.13028</td><td style = \"text-align: left;\">-0.00883196</td><td style = \"text-align: left;\">26.3014</td><td style = \"text-align: left;\">-0.526114</td><td style = \"text-align: left;\">-14.2684</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">8</td><td style = \"text-align: left;\">2135 - 2150</td><td style = \"text-align: left;\">466.664</td><td style = \"text-align: left;\">10.9817</td><td style = \"text-align: left;\">-0.00203925</td><td style = \"text-align: left;\">173.864</td><td style = \"text-align: left;\">0.00532965</td><td style = \"text-align: left;\">11.6572</td><td style = \"text-align: left;\">0.00929686</td><td style = \"text-align: left;\">27.1981</td><td style = \"text-align: left;\">-0.0113802</td><td style = \"text-align: left;\">33.89</td><td style = \"text-align: left;\">-0.0742345</td><td style = \"text-align: left;\">-2.01327</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">9</td><td style = \"text-align: left;\">2150 - 2165</td><td style = \"text-align: left;\">1206.95</td><td style = \"text-align: left;\">28.4023</td><td style = \"text-align: left;\">0.00202943</td><td style = \"text-align: left;\">-173.027</td><td style = \"text-align: left;\">-0.00801462</td><td style = \"text-align: left;\">-17.5298</td><td style = \"text-align: left;\">-0.00559898</td><td style = \"text-align: left;\">-16.3799</td><td style = \"text-align: left;\">0.156246</td><td style = \"text-align: left;\">-465.296</td><td style = \"text-align: left;\">-0.665101</td><td style = \"text-align: left;\">-18.0378</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">10</td><td style = \"text-align: left;\">2165 - 2180</td><td style = \"text-align: left;\">-1376.14</td><td style = \"text-align: left;\">-32.3839</td><td style = \"text-align: left;\">0.0126357</td><td style = \"text-align: left;\">-1077.3</td><td style = \"text-align: left;\">-0.00801932</td><td style = \"text-align: left;\">-17.5401</td><td style = \"text-align: left;\">-0.00701544</td><td style = \"text-align: left;\">-20.5238</td><td style = \"text-align: left;\">-0.00325509</td><td style = \"text-align: left;\">9.69358</td><td style = \"text-align: left;\">-0.167603</td><td style = \"text-align: left;\">-4.54548</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">11</td><td style = \"text-align: left;\">2180 - 2195</td><td style = \"text-align: left;\">-124.64</td><td style = \"text-align: left;\">-2.93307</td><td style = \"text-align: left;\">-0.00697696</td><td style = \"text-align: left;\">594.847</td><td style = \"text-align: left;\">-0.0129844</td><td style = \"text-align: left;\">-28.3997</td><td style = \"text-align: left;\">-0.00845712</td><td style = \"text-align: left;\">-24.7414</td><td style = \"text-align: left;\">-0.202409</td><td style = \"text-align: left;\">602.77</td><td style = \"text-align: left;\">-0.0283229</td><td style = \"text-align: left;\">-0.768129</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">12</td><td style = \"text-align: left;\">2195 - 2210</td><td style = \"text-align: left;\">94.4463</td><td style = \"text-align: left;\">2.22255</td><td style = \"text-align: left;\">-0.00998107</td><td style = \"text-align: left;\">850.974</td><td style = \"text-align: left;\">-0.0255264</td><td style = \"text-align: left;\">-55.8321</td><td style = \"text-align: left;\">0.00454936</td><td style = \"text-align: left;\">13.3092</td><td style = \"text-align: left;\">-0.00825645</td><td style = \"text-align: left;\">24.5875</td><td style = \"text-align: left;\">0.758158</td><td style = \"text-align: left;\">20.5616</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">13</td><td style = \"text-align: left;\">2210 - 2225</td><td style = \"text-align: left;\">689.765</td><td style = \"text-align: left;\">16.2318</td><td style = \"text-align: left;\">-0.0300118</td><td style = \"text-align: left;\">2558.77</td><td style = \"text-align: left;\">-0.00570419</td><td style = \"text-align: left;\">-12.4764</td><td style = \"text-align: left;\">-0.00105471</td><td style = \"text-align: left;\">-3.08557</td><td style = \"text-align: left;\">-0.0490562</td><td style = \"text-align: left;\">146.088</td><td style = \"text-align: left;\">0.347847</td><td style = \"text-align: left;\">9.43376</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">14</td><td style = \"text-align: left;\">2225 - 2240</td><td style = \"text-align: left;\">81.0382</td><td style = \"text-align: left;\">1.90702</td><td style = \"text-align: left;\">-0.00855245</td><td style = \"text-align: left;\">729.171</td><td style = \"text-align: left;\">0.00679735</td><td style = \"text-align: left;\">14.8673</td><td style = \"text-align: left;\">0.00236253</td><td style = \"text-align: left;\">6.91163</td><td style = \"text-align: left;\">-0.0172701</td><td style = \"text-align: left;\">51.4298</td><td style = \"text-align: left;\">-0.297147</td><td style = \"text-align: left;\">-8.05875</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">15</td><td style = \"text-align: left;\">2240 - 2255</td><td style = \"text-align: left;\">-261.504</td><td style = \"text-align: left;\">-6.1538</td><td style = \"text-align: left;\">-0.00214106</td><td style = \"text-align: left;\">182.544</td><td style = \"text-align: left;\">-0.00264107</td><td style = \"text-align: left;\">-5.77662</td><td style = \"text-align: left;\">-0.00613826</td><td style = \"text-align: left;\">-17.9576</td><td style = \"text-align: left;\">-0.00590999</td><td style = \"text-align: left;\">17.5998</td><td style = \"text-align: left;\">-0.109555</td><td style = \"text-align: left;\">-2.97117</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">16</td><td style = \"text-align: left;\">2255 - 2270</td><td style = \"text-align: left;\">-308.262</td><td style = \"text-align: left;\">-7.25413</td><td style = \"text-align: left;\">-0.00215216</td><td style = \"text-align: left;\">183.491</td><td style = \"text-align: left;\">-0.00262758</td><td style = \"text-align: left;\">-5.74711</td><td style = \"text-align: left;\">-0.000809913</td><td style = \"text-align: left;\">-2.36941</td><td style = \"text-align: left;\">0.0123863</td><td style = \"text-align: left;\">-36.8861</td><td style = \"text-align: left;\">-0.303816</td><td style = \"text-align: left;\">-8.23963</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">17</td><td style = \"text-align: left;\">2270 - 2285</td><td style = \"text-align: left;\">498.216</td><td style = \"text-align: left;\">11.7242</td><td style = \"text-align: left;\">0.000709491</td><td style = \"text-align: left;\">-60.4903</td><td style = \"text-align: left;\">-0.00129089</td><td style = \"text-align: left;\">-2.82346</td><td style = \"text-align: left;\">-0.00287291</td><td style = \"text-align: left;\">-8.40476</td><td style = \"text-align: left;\">-0.00699449</td><td style = \"text-align: left;\">20.8294</td><td style = \"text-align: left;\">-0.00847936</td><td style = \"text-align: left;\">-0.229964</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">18</td><td style = \"text-align: left;\">2285 - 2300</td><td style = \"text-align: left;\">-57.7269</td><td style = \"text-align: left;\">-1.35845</td><td style = \"text-align: left;\">-0.000763606</td><td style = \"text-align: left;\">65.104</td><td style = \"text-align: left;\">-0.00163568</td><td style = \"text-align: left;\">-3.5776</td><td style = \"text-align: left;\">-0.00781482</td><td style = \"text-align: left;\">-22.8624</td><td style = \"text-align: left;\">-0.00817648</td><td style = \"text-align: left;\">24.3494</td><td style = \"text-align: left;\">-0.0967243</td><td style = \"text-align: left;\">-2.62321</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">19</td><td style = \"text-align: left;\">2030 - 2300</td><td style = \"text-align: left;\">4249.47</td><td style = \"text-align: left;\">100.0</td><td style = \"text-align: left;\">-0.0011729</td><td style = \"text-align: left;\">100.0</td><td style = \"text-align: left;\">0.04572</td><td style = \"text-align: left;\">100.0</td><td style = \"text-align: left;\">0.034182</td><td style = \"text-align: left;\">100.0</td><td style = \"text-align: left;\">-0.0335799</td><td style = \"text-align: left;\">100.0</td><td style = \"text-align: left;\">3.68726</td><td style = \"text-align: left;\">100.0</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccc}\n",
       "\t& LearningPeriod & ΔvmThresh & Δ\\_\\%\\_vmThresh & Δ\\_fricExp & Δ\\_\\%\\_fricExp & Δ\\_mu\\_scale & \\\\\n",
       "\t\\hline\n",
       "\t& Any & Any & Any & Any & Any & Any & \\\\\n",
       "\t\\hline\n",
       "\t1 & 2030 - 2045 & 2950.94 & 69.4426 & 0.0109701 & -935.296 & 0.044943 & $\\dots$ \\\\\n",
       "\t2 & 2045 - 2060 & 49.035 & 1.15391 & 0.000996436 & -84.9549 & 0.0113058 & $\\dots$ \\\\\n",
       "\t3 & 2060 - 2075 & 857.073 & 20.169 & 0.00453659 & -386.784 & 0.0132468 & $\\dots$ \\\\\n",
       "\t4 & 2075 - 2090 & 346.907 & 8.16355 & 0.00717519 & -611.748 & -0.00394326 & $\\dots$ \\\\\n",
       "\t5 & 2090 - 2105 & 173.415 & 4.08086 & 0.0113467 & -967.404 & 0.0291168 & $\\dots$ \\\\\n",
       "\t6 & 2105 - 2120 & -222.925 & -5.24596 & 0.00481601 & -410.606 & 0.00548521 & $\\dots$ \\\\\n",
       "\t7 & 2120 - 2135 & -813.782 & -19.1502 & 0.00622987 & -531.15 & 0.00188271 & $\\dots$ \\\\\n",
       "\t8 & 2135 - 2150 & 466.664 & 10.9817 & -0.00203925 & 173.864 & 0.00532965 & $\\dots$ \\\\\n",
       "\t9 & 2150 - 2165 & 1206.95 & 28.4023 & 0.00202943 & -173.027 & -0.00801462 & $\\dots$ \\\\\n",
       "\t10 & 2165 - 2180 & -1376.14 & -32.3839 & 0.0126357 & -1077.3 & -0.00801932 & $\\dots$ \\\\\n",
       "\t11 & 2180 - 2195 & -124.64 & -2.93307 & -0.00697696 & 594.847 & -0.0129844 & $\\dots$ \\\\\n",
       "\t12 & 2195 - 2210 & 94.4463 & 2.22255 & -0.00998107 & 850.974 & -0.0255264 & $\\dots$ \\\\\n",
       "\t13 & 2210 - 2225 & 689.765 & 16.2318 & -0.0300118 & 2558.77 & -0.00570419 & $\\dots$ \\\\\n",
       "\t14 & 2225 - 2240 & 81.0382 & 1.90702 & -0.00855245 & 729.171 & 0.00679735 & $\\dots$ \\\\\n",
       "\t15 & 2240 - 2255 & -261.504 & -6.1538 & -0.00214106 & 182.544 & -0.00264107 & $\\dots$ \\\\\n",
       "\t16 & 2255 - 2270 & -308.262 & -7.25413 & -0.00215216 & 183.491 & -0.00262758 & $\\dots$ \\\\\n",
       "\t17 & 2270 - 2285 & 498.216 & 11.7242 & 0.000709491 & -60.4903 & -0.00129089 & $\\dots$ \\\\\n",
       "\t18 & 2285 - 2300 & -57.7269 & -1.35845 & -0.000763606 & 65.104 & -0.00163568 & $\\dots$ \\\\\n",
       "\t19 & 2030 - 2300 & 4249.47 & 100.0 & -0.0011729 & 100.0 & 0.04572 & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m19×13 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m LearningPeriod \u001b[0m\u001b[1m ΔvmThresh \u001b[0m\u001b[1m Δ_%_vmThresh \u001b[0m\u001b[1m Δ_fricExp    \u001b[0m\u001b[1m Δ_%_fricExp \u001b[0m\u001b[1m Δ_m\u001b[0m ⋯\n",
       "     │\u001b[90m Any            \u001b[0m\u001b[90m Any       \u001b[0m\u001b[90m Any          \u001b[0m\u001b[90m Any          \u001b[0m\u001b[90m Any         \u001b[0m\u001b[90m Any\u001b[0m ⋯\n",
       "─────┼──────────────────────────────────────────────────────────────────────────\n",
       "   1 │ 2030 - 2045     2950.94    69.4426       0.0109701     -935.296     0.0 ⋯\n",
       "   2 │ 2045 - 2060     49.035     1.15391       0.000996436   -84.9549     0.0\n",
       "   3 │ 2060 - 2075     857.073    20.169        0.00453659    -386.784     0.0\n",
       "   4 │ 2075 - 2090     346.907    8.16355       0.00717519    -611.748     -0.\n",
       "   5 │ 2090 - 2105     173.415    4.08086       0.0113467     -967.404     0.0 ⋯\n",
       "   6 │ 2105 - 2120     -222.925   -5.24596      0.00481601    -410.606     0.0\n",
       "   7 │ 2120 - 2135     -813.782   -19.1502      0.00622987    -531.15      0.0\n",
       "   8 │ 2135 - 2150     466.664    10.9817       -0.00203925   173.864      0.0\n",
       "   9 │ 2150 - 2165     1206.95    28.4023       0.00202943    -173.027     -0. ⋯\n",
       "  10 │ 2165 - 2180     -1376.14   -32.3839      0.0126357     -1077.3      -0.\n",
       "  11 │ 2180 - 2195     -124.64    -2.93307      -0.00697696   594.847      -0.\n",
       "  12 │ 2195 - 2210     94.4463    2.22255       -0.00998107   850.974      -0.\n",
       "  13 │ 2210 - 2225     689.765    16.2318       -0.0300118    2558.77      -0. ⋯\n",
       "  14 │ 2225 - 2240     81.0382    1.90702       -0.00855245   729.171      0.0\n",
       "  15 │ 2240 - 2255     -261.504   -6.1538       -0.00214106   182.544      -0.\n",
       "  16 │ 2255 - 2270     -308.262   -7.25413      -0.00215216   183.491      -0.\n",
       "  17 │ 2270 - 2285     498.216    11.7242       0.000709491   -60.4903     -0. ⋯\n",
       "  18 │ 2285 - 2300     -57.7269   -1.35845      -0.000763606  65.104       -0.\n",
       "  19 │ 2030 - 2300     4249.47    100.0         -0.0011729    100.0        0.0\n",
       "\u001b[36m                                                               8 columns omitted\u001b[0m"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##CALCULATING THE YEAR BY YEAR CHANGE IN UNCERTAINTY RANGE STANDARD DEVIATION FOR EACH PARAMETER, AS WELL AS PERCENT CONTRIBUTION TO TOTAL CHANGE\n",
    "##\n",
    "cal_years = collect(range(2030,step=15,length=19))\n",
    "\n",
    "Δ_width_var = zeros(19, 6)\n",
    "Δ_width_var_pct = zeros(19, 6)\n",
    "\n",
    "#Total learning from 2015 - 2300\n",
    "\n",
    "# find row indices\n",
    "total_idx1 = only(findall(x -> x == 2030, cal_years))\n",
    "total_idx2 = only(findall(x -> x == 2300, cal_years))\n",
    "\n",
    "# extract vectors (dropping year column)\n",
    "present = collect(params_df_width_var[total_idx1, :])[2:end]\n",
    "final = collect(params_df_width_var[total_idx2, :])[2:end]\n",
    "\n",
    "# compute differences\n",
    "total_diff = final .- present\n",
    "Δ_width_var[19, :] = round.(total_diff, sigdigits = 6) #20\n",
    "Δ_width_var_pct[19,:] .= 100.0\n",
    "\n",
    "learn_periods = []\n",
    "\n",
    "for i in 1:(length(cal_years)-1)\n",
    "    yr1 = cal_years[i]\n",
    "    yr2 = cal_years[i+1]\n",
    "\n",
    "    # find row indices\n",
    "    row_idx1 = only(findall(x -> x == yr1, cal_years))\n",
    "    row_idx2 = only(findall(x -> x == yr2, cal_years))\n",
    "\n",
    "    # extract vectors (dropping year column)\n",
    "    row1 = collect(params_df_width_var[row_idx1, :])[2:end]\n",
    "    row2 = collect(params_df_width_var[row_idx2, :])[2:end]\n",
    "\n",
    "    # compute differences\n",
    "    diff = row2 .- row1\n",
    "    Δ_width_var[i, :] = round.(diff, sigdigits = 6)\n",
    "    Δ_width_var_pct[i, :] = (diff ./ total_diff) .* 100\n",
    "    # Collect this learning period as string for datframe labels\n",
    "    push!(learn_periods, \"$(yr1) - $(yr2)\")\n",
    "end\n",
    "# Add the total learning period (2015 not included since multiple trajectories only began with 2030 caliobration onward)\n",
    "push!(learn_periods, \"2030 - 2300\")\n",
    "width_variance_change = zeros(19,12)\n",
    "\n",
    "# Put the parameter width changes and percent changes together param by param columnwise\n",
    "for i in 1:6\n",
    "    width_variance_change[:,(2*i)-1] = Δ_width_var[:,i]\n",
    "    width_variance_change[:,(2*i)] = Δ_width_var_pct[:,i]\n",
    "end\n",
    "\n",
    "\n",
    "names = [\"LearningPeriod\",\"ΔvmThresh\",\"Δ_%_vmThresh\",\"Δ_fricExp\",\"Δ_%_fricExp\",\"Δ_mu_scale\",\"Δ_%_mu_scale\",\"Δ_stiff_scale\",\"Δ_%_stiff_scale\",\"Δ_gamma0\",\"Δ_%_gamma0\",\"Δ_melt_flux\",\"Δ_%_melt_flux\"]\n",
    "width_variance_w_years = hcat(learn_periods, width_variance_change)\n",
    "df_width_variance_yr_to_yr = DataFrame(width_variance_w_years , names)\n",
    "# CSV.write(\"../Data/Parameter_Learning_Tables/yr_to_yr_change_in_width_uncertainty_log_gamma0_$(gamma_0_is_log).csv\", df_width_variance_yr_to_yr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3197284",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89973969-e1ea-471e-a2cb-fd6eba0124cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################################################\n",
    "#####################################################################################################################\n",
    "#####################################################################################################################\n",
    "###############################                SLR Projection Learning Tables             ###########################\n",
    "#####################################################################################################################\n",
    "#####################################################################################################################\n",
    "#####################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b1acfad-e0db-4463-8c32-540907062547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All years 2016-2300\n",
    "all_years_no_gap = collect(range(2016, step=1, length=285))\n",
    "\n",
    "yrs_dict = Dict{Int64, Int64}()\n",
    "for (idx,yr) in enumerate(all_years_no_gap)\n",
    "        yrs_dict[yr] = idx\n",
    "end\n",
    "\n",
    "\n",
    "Realizations = [string(i) for i in 1:100];\n",
    "\n",
    "cal_years = collect(range(2030,step=15,length=19));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fae2a70-cca9-4b8a-90a3-86eecba0eefb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19,)\n",
      "(19,)\n",
      "(19,)\n"
     ]
    }
   ],
   "source": [
    "# The years of projection considered\n",
    "chosen_projection_years = [2100,2200,2300]\n",
    "\n",
    "# Initialize empty arrays (Some entries will be missing due to calibration past year of projection)\n",
    "all_bounds   = Array{Array{Union{Missing,Tuple{Missing, Missing},Tuple{Float64,Float64},Int64}}}(undef, length(chosen_projection_years))\n",
    "all_widths   = zeros(3,20)\n",
    "all_width_variation = zeros(3,19)\n",
    "# For each projection year considered\n",
    "for (n, year) in enumerate(chosen_projection_years)\n",
    "    \n",
    "    proj_yr_idx = yrs_dict[year]\n",
    "    proj_bounds = Array{Union{Missing,Float64}}(undef,length(Realizations),19,2)\n",
    "    proj_widths = zeros(100,19)\n",
    "    \n",
    "    # For each of the 100 trajectories considered\n",
    "    for j in 1:length(Realizations)\n",
    "        # For each of the 19 calibrating years considered\n",
    "        for (iter,yr) in enumerate(cal_years[2:end])\n",
    "                cal_year_matrix = JLD2.load(\"../Data/Projection_Data/R_$(Realizations[j])/$(Realizations[j])-year$(yr)pred_VAF.jld2\",\n",
    "                    \"sample_post_mm_ssp5\")\n",
    "                proj_bounds[j,iter,1] = quantile(cal_year_matrix[proj_yr_idx,:], 0.05)\n",
    "                proj_bounds[j,iter,2] = quantile(cal_year_matrix[proj_yr_idx,:], 0.95)\n",
    "                proj_widths[j,iter] = proj_bounds[j,iter,2] - proj_bounds[j,iter,1]\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # Average across the 100 trajectories\n",
    "    avg_bounds = dropdims(mean(proj_bounds,dims=1),dims=1)\n",
    "    avg_widths = dropdims(mean(proj_widths,dims=1),dims=1)\n",
    "\n",
    "    # Compute 66% credible interval of the 90% interval widths across the 100 trajectories\n",
    "    width_variation_interval = np.quantile(proj_widths, 0.83,axis=0) .- np.quantile(proj_widths,0.17,axis=0) #31\n",
    "    println(size(width_variation_interval))\n",
    "\n",
    "\n",
    "    # Load the present day projections\n",
    "    present_projections = JLD2.load(\"../Data/Projection_Data/2015_SLR_Projections.jld2\",\"present2015_post_mm_ssp5\")\n",
    "    present_lower = quantile(present_projections[proj_yr_idx,:], 0.05)\n",
    "    present_upper = quantile(present_projections[proj_yr_idx,:], 0.95)\n",
    "    present_width = present_upper - present_lower\n",
    "\n",
    "    # Add present day projections to beginning of lists above\n",
    "    bounds_w_present = vcat([present_lower;; present_upper], avg_bounds)\n",
    "    widths_w_present = vcat([present_width], avg_widths);\n",
    "    # Store the bounds as tuples in one matrix\n",
    "    slr_tuple_bounds = [(round(bounds_w_present[i,1],sigdigits=6),round(bounds_w_present[i,2],sigdigits=6)) for i in 1:length(bounds_w_present[:,1])]\n",
    "\n",
    "    # Push this projection years quantities to list containing all the projection years\n",
    "    all_bounds[n]   = slr_tuple_bounds\n",
    "    all_widths[n,:]   =  widths_w_present\n",
    "    all_width_variation[n,:]  =  width_variation_interval\n",
    "    \n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1684fda1-7917-49d7-a273-29374a7e84db",
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_years = collect(range(2015,step=15,length=20));\n",
    "cal_years = Int.(cal_years)\n",
    "\n",
    "# Add the years of calibration as another column\n",
    "bounds_w_years = hcat(cal_years, reduce(hcat, all_bounds))\n",
    "widths_w_years = hcat(cal_years, all_widths')\n",
    "width_var_w_years = hcat(cal_years[2:end],all_width_variation' )\n",
    "\n",
    "names = [\"Latest year of calibration\",\"2100\", \"2200\",\"2300\"]\n",
    "\n",
    "# Convert to dataframes before saving to disc\n",
    "slr_df_bounds  = DataFrame(bounds_w_years, names)\n",
    "slr_df_widths  = DataFrame(widths_w_years, names)\n",
    "slr_df_width_var = DataFrame(width_var_w_years, names)\n",
    "allowmissing!(slr_df_bounds) \n",
    "allowmissing!(slr_df_widths) \n",
    "allowmissing!(slr_df_width_var);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c66738f-366b-42f2-95c1-b663f78db914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix{Any}\n",
      "\u001b[1m21×4 DataFrame\u001b[0m\n",
      "\u001b[1m Row \u001b[0m│\u001b[1m Latest year of calibration \u001b[0m\u001b[1m 2100    \u001b[0m\u001b[1m 2200    \u001b[0m\u001b[1m 2300    \u001b[0m\n",
      "     │\u001b[90m Any                        \u001b[0m\u001b[90m Any     \u001b[0m\u001b[90m Any     \u001b[0m\u001b[90m Any     \u001b[0m\n",
      "─────┼───────────────────────────────────────────────────────\n",
      "   1 │ 2015.0                      5.81829  65.2261  76.6676\n",
      "   2 │ 2030.0                      4.62033  52.8798  70.4075\n",
      "   3 │ 2045.0                      4.42315  40.4086  69.8543\n",
      "   4 │ 2060.0                      4.22244  22.92    67.1312\n",
      "   5 │ 2075.0                      4.14338  21.8803  66.1392\n",
      "   6 │ 2090.0                      4.02504  20.5155  61.188\n",
      "   7 │ 2105.0                      0.0      17.3835  58.2574\n",
      "   8 │ 2120.0                      0.0      15.5806  56.4196\n",
      "   9 │ 2135.0                      0.0      14.8113  53.0541\n",
      "  10 │ 2150.0                      0.0      14.4658  50.1841\n",
      "  11 │ 2165.0                      0.0      13.6753  42.5954\n",
      "  12 │ 2180.0                      0.0      12.23    35.005\n",
      "  13 │ 2195.0                      0.0      10.0191  29.0676\n",
      "  14 │ 2210.0                      0.0      0.0      20.4525\n",
      "  15 │ 2225.0                      0.0      0.0      17.0559\n",
      "  16 │ 2240.0                      0.0      0.0      15.0905\n",
      "  17 │ 2255.0                      0.0      0.0      14.1069\n",
      "  18 │ 2270.0                      0.0      0.0      13.3744\n",
      "  19 │ 2285.0                      0.0      0.0      12.9264\n",
      "  20 │ 2300.0                      0.0      0.0      0.0\n",
      "  21 │ total_%_decrease            30.8209  84.6394  83.1397\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"../Data/SLR_Learning_Tables/SLR_90_CI_vaXXXXXriation.csv\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove data that has been calibrated past its projection year (i.e projections for year 2100 with parameters calibrated in 2105)\n",
    "for yr in names[2:3]\n",
    "    n_useful = (parse(Int, yr) - 2015) ÷ 15\n",
    "    slr_df_bounds[n_useful+2:end, yr] .= missing\n",
    "    slr_df_widths[n_useful+2:end, yr] .= 0\n",
    "    slr_df_width_var[n_useful+1:end, yr] .= 0    \n",
    "\n",
    "end\n",
    "\n",
    "#Calculate total percent decrease of 90% cred interval width\n",
    "pct_change2100 = ((slr_df_widths[1,2] - slr_df_widths[6,2]) /  slr_df_widths[1,2]) * 100\n",
    "pct_change2200 = ((slr_df_widths[1,3] - slr_df_widths[13,3]) /  slr_df_widths[1,3]) * 100\n",
    "pct_change2300 = ((slr_df_widths[1,4] - slr_df_widths[19,4]) /  slr_df_widths[1,4]) * 100\n",
    "\n",
    "# Make a 1×7 row: first element is label, then pct_change values\n",
    "new_row = hcat(\"total_%_decrease\", pct_change2100, pct_change2200, pct_change2300)\n",
    "println(typeof(new_row))\n",
    "# Convert to DataFrame with the same column names\n",
    "new_df = DataFrame(new_row, names)\n",
    "\n",
    "\n",
    "# Append to params_df_widths\n",
    "append!(slr_df_widths, new_df, promote=true) #22\n",
    "println(slr_df_widths)\n",
    "\n",
    "CSV.write(\"../Data/SLR_Learning_Tables/SLR_90_CI_bounds.csv\", slr_df_bounds)\n",
    "CSV.write(\"../Data/SLR_Learning_Tables/SLR_90_CI_widths.csv\", slr_df_widths)\n",
    "CSV.write(\"../Data/SLR_Learning_Tables/SLR_90_CI_variation.csv\",  slr_df_width_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9f417d8-f020-48d2-9676-df4a9b34b8b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((2300 - 2015) ÷ 15) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "977839e4-d682-4011-be67-80752bbd2a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CALCULATING THE YEAR TO YEAR CHANGE IN 90% UNCERTAINTY RANGES FOR PROJECTIONS OF THE YEARS 2100, 2200, 2300\n",
    "proj_years = [2100,2200,2300]\n",
    "cal_years = collect(range(2015, step=15, length=20))\n",
    "\n",
    "Δ_proj_widths_yty = Array{Array{Union{Float64, Missing}}}(undef, 6)\n",
    "for (i,yr) in enumerate(proj_years)\n",
    "    n_cal_years = ((yr - 2015) ÷ 15) + 1\n",
    "    # Calculate total learning\n",
    "    present_row_idx = only(findall(x -> x == 2015, cal_years))\n",
    "    present_diff = (i == 3) ? slr_df_widths[n_cal_years - 1, i+1] - slr_df_widths[present_row_idx,i+1] : slr_df_widths[n_cal_years, i+1] - slr_df_widths[present_row_idx,i+1]\n",
    "    abs_change = Array{Union{Float64, Missing}}(undef, 20)\n",
    "    pct_change = Array{Union{Float64, Missing}}(undef, 20)\n",
    "    # Calculate the year to year change and percent of total change\n",
    "    proj_yr_widths = slr_df_widths[!,i+1]\n",
    "    abs_change[1:19] = proj_yr_widths[2:20] - proj_yr_widths[1:19] #15\n",
    "    pct_change[1:19] = (abs_change[1:19] ./ present_diff) .* 100\n",
    "    # Add the total change to the end of the list\n",
    "    abs_change[20] = present_diff\n",
    "    # Concatenate to the full matrix\n",
    "    Δ_proj_widths_yty[2*i-1] = abs_change\n",
    "    Δ_proj_widths_yty[2*i] = pct_change\n",
    "        \n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6cd3c056-1c95-4dc7-b536-63b3c1af5787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"../Data/SLR_Learning_Tables/yr_to_yr_90_CI_widthXCXXXX_change.csv\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Labels for datframe rows\n",
    "learn_periods = vcat([\"$(cal_years[i]) - $(cal_years[i+1])\" for i in 1:(length(cal_years) - 1)], [\"Total learning\"])\n",
    "# Collect labels with data\n",
    "mat_yty_width_change = hcat(learn_periods, reduce(hcat, Δ_proj_widths_yty))\n",
    "# We don't care about the change in uncertainty past the point of projection\n",
    "mat_yty_width_change[6,2] = 0.0\n",
    "mat_yty_width_change[6,3] = 0.0\n",
    "mat_yty_width_change[13,4] = 0.0\n",
    "mat_yty_width_change[13,5] = 0.0\n",
    "mat_yty_width_change[19,6] = 0.0\n",
    "mat_yty_width_change[19,7] = 0.0\n",
    "# Column labels\n",
    "names = [\"Learning_Period\",\"Δ_2100\",\"Δ_%_2100\",\"Δ_2200\",\"Δ_%_2200\", \"Δ_2300\",\"Δ_%_2300\"]\n",
    "df_yty_width_change  = DataFrame(mat_yty_width_change, names)\n",
    "CSV.write(\"../Data/SLR_Learning_Tables/yr_to_yr_90_CI_width_change.csv\",   df_yty_width_change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a4564d5-ba16-4e5d-a455-76f8f1ac4ec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>20×7 DataFrame</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">Learning_Period</th><th style = \"text-align: left;\">Δ_2100</th><th style = \"text-align: left;\">Δ_%_2100</th><th style = \"text-align: left;\">Δ_2200</th><th style = \"text-align: left;\">Δ_%_2200</th><th style = \"text-align: left;\">Δ_2300</th><th style = \"text-align: left;\">Δ_%_2300</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"Any\" style = \"text-align: left;\">Any</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: left;\">2015 - 2030</td><td style = \"text-align: left;\">-1.19796</td><td style = \"text-align: left;\">66.8038</td><td style = \"text-align: left;\">-12.3463</td><td style = \"text-align: left;\">22.3636</td><td style = \"text-align: left;\">-6.26004</td><td style = \"text-align: left;\">9.82103</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: left;\">2030 - 2045</td><td style = \"text-align: left;\">-0.197182</td><td style = \"text-align: left;\">10.9958</td><td style = \"text-align: left;\">-12.4713</td><td style = \"text-align: left;\">22.59</td><td style = \"text-align: left;\">-0.553257</td><td style = \"text-align: left;\">0.867974</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: left;\">2045 - 2060</td><td style = \"text-align: left;\">-0.200712</td><td style = \"text-align: left;\">11.1927</td><td style = \"text-align: left;\">-17.4885</td><td style = \"text-align: left;\">31.6781</td><td style = \"text-align: left;\">-2.7231</td><td style = \"text-align: left;\">4.27212</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4</td><td style = \"text-align: left;\">2060 - 2075</td><td style = \"text-align: left;\">-0.0790525</td><td style = \"text-align: left;\">4.40833</td><td style = \"text-align: left;\">-1.0397</td><td style = \"text-align: left;\">1.88327</td><td style = \"text-align: left;\">-0.991968</td><td style = \"text-align: left;\">1.55624</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5</td><td style = \"text-align: left;\">2075 - 2090</td><td style = \"text-align: left;\">-0.118345</td><td style = \"text-align: left;\">6.59948</td><td style = \"text-align: left;\">-1.3648</td><td style = \"text-align: left;\">2.47214</td><td style = \"text-align: left;\">-4.95117</td><td style = \"text-align: left;\">7.76762</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">6</td><td style = \"text-align: left;\">2090 - 2105</td><td style = \"text-align: left;\">0.0</td><td style = \"text-align: left;\">0.0</td><td style = \"text-align: left;\">-3.132</td><td style = \"text-align: left;\">5.67319</td><td style = \"text-align: left;\">-2.93064</td><td style = \"text-align: left;\">4.59772</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">7</td><td style = \"text-align: left;\">2105 - 2120</td><td style = \"text-align: left;\">0.0</td><td style = \"text-align: left;\">-0.0</td><td style = \"text-align: left;\">-1.80292</td><td style = \"text-align: left;\">3.26575</td><td style = \"text-align: left;\">-1.83781</td><td style = \"text-align: left;\">2.88323</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">8</td><td style = \"text-align: left;\">2120 - 2135</td><td style = \"text-align: left;\">0.0</td><td style = \"text-align: left;\">-0.0</td><td style = \"text-align: left;\">-0.769318</td><td style = \"text-align: left;\">1.39352</td><td style = \"text-align: left;\">-3.3655</td><td style = \"text-align: left;\">5.27994</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">9</td><td style = \"text-align: left;\">2135 - 2150</td><td style = \"text-align: left;\">0.0</td><td style = \"text-align: left;\">-0.0</td><td style = \"text-align: left;\">-0.345495</td><td style = \"text-align: left;\">0.625817</td><td style = \"text-align: left;\">-2.86996</td><td style = \"text-align: left;\">4.50251</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">10</td><td style = \"text-align: left;\">2150 - 2165</td><td style = \"text-align: left;\">0.0</td><td style = \"text-align: left;\">-0.0</td><td style = \"text-align: left;\">-0.790551</td><td style = \"text-align: left;\">1.43198</td><td style = \"text-align: left;\">-7.58876</td><td style = \"text-align: left;\">11.9056</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">11</td><td style = \"text-align: left;\">2165 - 2180</td><td style = \"text-align: left;\">0.0</td><td style = \"text-align: left;\">-0.0</td><td style = \"text-align: left;\">-1.44523</td><td style = \"text-align: left;\">2.61784</td><td style = \"text-align: left;\">-7.59036</td><td style = \"text-align: left;\">11.9081</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">12</td><td style = \"text-align: left;\">2180 - 2195</td><td style = \"text-align: left;\">0.0</td><td style = \"text-align: left;\">-0.0</td><td style = \"text-align: left;\">-2.2109</td><td style = \"text-align: left;\">4.00475</td><td style = \"text-align: left;\">-5.93743</td><td style = \"text-align: left;\">9.3149</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">13</td><td style = \"text-align: left;\">2195 - 2210</td><td style = \"text-align: left;\">0.0</td><td style = \"text-align: left;\">-0.0</td><td style = \"text-align: left;\">0.0</td><td style = \"text-align: left;\">0.0</td><td style = \"text-align: left;\">-8.61511</td><td style = \"text-align: left;\">13.5158</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">14</td><td style = \"text-align: left;\">2210 - 2225</td><td style = \"text-align: left;\">0.0</td><td style = \"text-align: left;\">-0.0</td><td style = \"text-align: left;\">0.0</td><td style = \"text-align: left;\">-0.0</td><td style = \"text-align: left;\">-3.3966</td><td style = \"text-align: left;\">5.32874</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">15</td><td style = \"text-align: left;\">2225 - 2240</td><td style = \"text-align: left;\">0.0</td><td style = \"text-align: left;\">-0.0</td><td style = \"text-align: left;\">0.0</td><td style = \"text-align: left;\">-0.0</td><td style = \"text-align: left;\">-1.96539</td><td style = \"text-align: left;\">3.08338</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">16</td><td style = \"text-align: left;\">2240 - 2255</td><td style = \"text-align: left;\">0.0</td><td style = \"text-align: left;\">-0.0</td><td style = \"text-align: left;\">0.0</td><td style = \"text-align: left;\">-0.0</td><td style = \"text-align: left;\">-0.983606</td><td style = \"text-align: left;\">1.54312</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">17</td><td style = \"text-align: left;\">2255 - 2270</td><td style = \"text-align: left;\">0.0</td><td style = \"text-align: left;\">-0.0</td><td style = \"text-align: left;\">0.0</td><td style = \"text-align: left;\">-0.0</td><td style = \"text-align: left;\">-0.732502</td><td style = \"text-align: left;\">1.14918</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">18</td><td style = \"text-align: left;\">2270 - 2285</td><td style = \"text-align: left;\">0.0</td><td style = \"text-align: left;\">-0.0</td><td style = \"text-align: left;\">0.0</td><td style = \"text-align: left;\">-0.0</td><td style = \"text-align: left;\">-0.447993</td><td style = \"text-align: left;\">0.702831</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">19</td><td style = \"text-align: left;\">2285 - 2300</td><td style = \"text-align: left;\">0.0</td><td style = \"text-align: left;\">-0.0</td><td style = \"text-align: left;\">0.0</td><td style = \"text-align: left;\">-0.0</td><td style = \"text-align: left;\">0.0</td><td style = \"text-align: left;\">0.0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">20</td><td style = \"text-align: left;\">Total learning</td><td style = \"text-align: left;\">-1.79325</td><td style = \"font-style: italic; text-align: left;\">missing</td><td style = \"text-align: left;\">-55.207</td><td style = \"font-style: italic; text-align: left;\">missing</td><td style = \"text-align: left;\">-63.7412</td><td style = \"font-style: italic; text-align: left;\">missing</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccc}\n",
       "\t& Learning\\_Period & Δ\\_2100 & Δ\\_\\%\\_2100 & Δ\\_2200 & Δ\\_\\%\\_2200 & Δ\\_2300 & Δ\\_\\%\\_2300\\\\\n",
       "\t\\hline\n",
       "\t& Any & Any & Any & Any & Any & Any & Any\\\\\n",
       "\t\\hline\n",
       "\t1 & 2015 - 2030 & -1.19796 & 66.8038 & -12.3463 & 22.3636 & -6.26004 & 9.82103 \\\\\n",
       "\t2 & 2030 - 2045 & -0.197182 & 10.9958 & -12.4713 & 22.59 & -0.553257 & 0.867974 \\\\\n",
       "\t3 & 2045 - 2060 & -0.200712 & 11.1927 & -17.4885 & 31.6781 & -2.7231 & 4.27212 \\\\\n",
       "\t4 & 2060 - 2075 & -0.0790525 & 4.40833 & -1.0397 & 1.88327 & -0.991968 & 1.55624 \\\\\n",
       "\t5 & 2075 - 2090 & -0.118345 & 6.59948 & -1.3648 & 2.47214 & -4.95117 & 7.76762 \\\\\n",
       "\t6 & 2090 - 2105 & 0.0 & 0.0 & -3.132 & 5.67319 & -2.93064 & 4.59772 \\\\\n",
       "\t7 & 2105 - 2120 & 0.0 & -0.0 & -1.80292 & 3.26575 & -1.83781 & 2.88323 \\\\\n",
       "\t8 & 2120 - 2135 & 0.0 & -0.0 & -0.769318 & 1.39352 & -3.3655 & 5.27994 \\\\\n",
       "\t9 & 2135 - 2150 & 0.0 & -0.0 & -0.345495 & 0.625817 & -2.86996 & 4.50251 \\\\\n",
       "\t10 & 2150 - 2165 & 0.0 & -0.0 & -0.790551 & 1.43198 & -7.58876 & 11.9056 \\\\\n",
       "\t11 & 2165 - 2180 & 0.0 & -0.0 & -1.44523 & 2.61784 & -7.59036 & 11.9081 \\\\\n",
       "\t12 & 2180 - 2195 & 0.0 & -0.0 & -2.2109 & 4.00475 & -5.93743 & 9.3149 \\\\\n",
       "\t13 & 2195 - 2210 & 0.0 & -0.0 & 0.0 & 0.0 & -8.61511 & 13.5158 \\\\\n",
       "\t14 & 2210 - 2225 & 0.0 & -0.0 & 0.0 & -0.0 & -3.3966 & 5.32874 \\\\\n",
       "\t15 & 2225 - 2240 & 0.0 & -0.0 & 0.0 & -0.0 & -1.96539 & 3.08338 \\\\\n",
       "\t16 & 2240 - 2255 & 0.0 & -0.0 & 0.0 & -0.0 & -0.983606 & 1.54312 \\\\\n",
       "\t17 & 2255 - 2270 & 0.0 & -0.0 & 0.0 & -0.0 & -0.732502 & 1.14918 \\\\\n",
       "\t18 & 2270 - 2285 & 0.0 & -0.0 & 0.0 & -0.0 & -0.447993 & 0.702831 \\\\\n",
       "\t19 & 2285 - 2300 & 0.0 & -0.0 & 0.0 & -0.0 & 0.0 & 0.0 \\\\\n",
       "\t20 & Total learning & -1.79325 & \\emph{missing} & -55.207 & \\emph{missing} & -63.7412 & \\emph{missing} \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m20×7 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m Learning_Period \u001b[0m\u001b[1m Δ_2100     \u001b[0m\u001b[1m Δ_%_2100 \u001b[0m\u001b[1m Δ_2200    \u001b[0m\u001b[1m Δ_%_2200 \u001b[0m\u001b[1m Δ_2300    \u001b[0m\u001b[1m \u001b[0m ⋯\n",
       "     │\u001b[90m Any             \u001b[0m\u001b[90m Any        \u001b[0m\u001b[90m Any      \u001b[0m\u001b[90m Any       \u001b[0m\u001b[90m Any      \u001b[0m\u001b[90m Any       \u001b[0m\u001b[90m \u001b[0m ⋯\n",
       "─────┼──────────────────────────────────────────────────────────────────────────\n",
       "   1 │ 2015 - 2030      -1.19796    66.8038   -12.3463   22.3636   -6.26004    ⋯\n",
       "   2 │ 2030 - 2045      -0.197182   10.9958   -12.4713   22.59     -0.553257\n",
       "   3 │ 2045 - 2060      -0.200712   11.1927   -17.4885   31.6781   -2.7231\n",
       "   4 │ 2060 - 2075      -0.0790525  4.40833   -1.0397    1.88327   -0.991968\n",
       "   5 │ 2075 - 2090      -0.118345   6.59948   -1.3648    2.47214   -4.95117    ⋯\n",
       "   6 │ 2090 - 2105      0.0         0.0       -3.132     5.67319   -2.93064\n",
       "   7 │ 2105 - 2120      0.0         -0.0      -1.80292   3.26575   -1.83781\n",
       "   8 │ 2120 - 2135      0.0         -0.0      -0.769318  1.39352   -3.3655\n",
       "   9 │ 2135 - 2150      0.0         -0.0      -0.345495  0.625817  -2.86996    ⋯\n",
       "  10 │ 2150 - 2165      0.0         -0.0      -0.790551  1.43198   -7.58876\n",
       "  11 │ 2165 - 2180      0.0         -0.0      -1.44523   2.61784   -7.59036\n",
       "  12 │ 2180 - 2195      0.0         -0.0      -2.2109    4.00475   -5.93743\n",
       "  13 │ 2195 - 2210      0.0         -0.0      0.0        0.0       -8.61511    ⋯\n",
       "  14 │ 2210 - 2225      0.0         -0.0      0.0        -0.0      -3.3966\n",
       "  15 │ 2225 - 2240      0.0         -0.0      0.0        -0.0      -1.96539\n",
       "  16 │ 2240 - 2255      0.0         -0.0      0.0        -0.0      -0.983606\n",
       "  17 │ 2255 - 2270      0.0         -0.0      0.0        -0.0      -0.732502   ⋯\n",
       "  18 │ 2270 - 2285      0.0         -0.0      0.0        -0.0      -0.447993\n",
       "  19 │ 2285 - 2300      0.0         -0.0      0.0        -0.0      0.0\n",
       "  20 │ Total learning   -1.79325   \u001b[90m missing  \u001b[0m -55.207   \u001b[90m missing  \u001b[0m -63.7412  \u001b[90m \u001b[0m\n",
       "\u001b[36m                                                                1 column omitted\u001b[0m"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_yty_width_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ce7d079-e5f8-4ec5-b55a-6daa3b4f958b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78.51500443127654\n"
     ]
    }
   ],
   "source": [
    "println(sum(df_yty_width_change[1:4, 5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3a826b97-9fe6-4d21-987a-698be6308a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CALCULATING THE YEAR TO YEAR CHANGE IN 90% UNCERTAINTY RANGE STANDARD DEVIATION FOR PROJECTIONS OF THE YEARS 2100, 2200, 2300\n",
    "proj_years = [2100,2200,2300]\n",
    "cal_years = collect(range(2030, step=15, length=19))\n",
    "\n",
    "Δ_proj_width_var_yty = Array{Array{Union{Float64, Missing}}}(undef, 6)\n",
    "for (i,yr) in enumerate(proj_years)\n",
    "    n_cal_years = ((yr - 2030) ÷ 15) + 1\n",
    "    # Calculate total learning\n",
    "    present_row_idx = only(findall(x -> x == 2030, cal_years))\n",
    "    present_diff = (i == 3) ? slr_df_width_var[n_cal_years - 1, i+1] - slr_df_width_var[present_row_idx,i+1] : slr_df_width_var[n_cal_years, i+1] - slr_df_width_var[present_row_idx,i+1]\n",
    "    abs_change = Array{Union{Float64, Missing}}(undef, 19)\n",
    "    pct_change = Array{Union{Float64, Missing}}(undef, 19)\n",
    "    # Calculate the year to year change and percent of total change\n",
    "    proj_yr_width_var = slr_df_width_var[!,i+1]\n",
    "    abs_change[1:18] = proj_yr_width_var[2:19] - proj_yr_width_var[1:18]\n",
    "    pct_change[1:18] = (abs_change[1:18] ./ present_diff) .* 100\n",
    "    # Add the total change to the end of the list\n",
    "    abs_change[19] = present_diff\n",
    "    # Concatenate to the full matrix\n",
    "    Δ_proj_width_var_yty[2*i-1] = abs_change\n",
    "    Δ_proj_width_var_yty[2*i] = pct_change\n",
    "        \n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "56a81fba-c407-4517-817b-99e1a54c515b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"../Data/SLR_Learning_Tables/yr_to_yr_90_CI_widthXXXX_variation_change.csv\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Labels for datframe rows\n",
    "learn_periods = vcat([\"$(cal_years[i]) - $(cal_years[i+1])\" for i in 1:(length(cal_years) - 1)], [\"Total learning\"])\n",
    "# Collect labels with data\n",
    "mat_yty_std_change = hcat(learn_periods, reduce(hcat, Δ_proj_width_var_yty))\n",
    "# We don't care about the change in uncertainty variation past the point of projection\n",
    "mat_yty_std_change[5,2] = 0.0\n",
    "mat_yty_std_change[5,3] = 0.0\n",
    "mat_yty_std_change[12,4] = 0.0\n",
    "mat_yty_std_change[12,5] = 0.0\n",
    "mat_yty_std_change[18,6] = 0.0\n",
    "mat_yty_std_change[18,7] = 0.0\n",
    "# Column labels\n",
    "names = [\"Learning_Period\",\"Δ_2100\",\"Δ_%_2100\",\"Δ_2200\",\"Δ_%_2200\", \"Δ_2300\",\"Δ_%_2300\"]\n",
    "df_yty_std_change  = DataFrame(mat_yty_std_change, names)\n",
    "CSV.write(\"../Data/SLR_Learning_Tables/yr_to_yr_90_CI_width_variation_change.csv\",   df_yty_std_change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4da7b02-27cf-4b79-8477-308ace2a1114",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b83a504-6364-47d7-9709-711f219f6233",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.5",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
