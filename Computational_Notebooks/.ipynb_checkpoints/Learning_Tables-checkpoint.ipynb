{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "388df6e4-4407-4617-9d61-211cfc40124f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "using Turing\n",
    "using LinearAlgebra\n",
    "using Distributions\n",
    "using MultivariateStats\n",
    "import MultivariateStats: reconstruct\n",
    "using GaussianProcesses\n",
    "using StatsBase\n",
    "using Statistics\n",
    "using Suppressor\n",
    "using JLD2\n",
    "using CSV\n",
    "using DataFrames, DataFramesMeta\n",
    "using SplitApplyCombine\n",
    "using KernelFunctions\n",
    "using MCMCChains\n",
    "using PyCall\n",
    "using PyPlot\n",
    "using Printf\n",
    "import PyCall.pyfunction\n",
    "using Missings\n",
    "\n",
    "os = pyimport(\"os\")\n",
    "pyimport(\"scienceplots\")\n",
    "np = pyimport(\"numpy\")\n",
    "\n",
    "\n",
    "PyCall.pygui(:tk)\n",
    "\n",
    "FONTSIZE=20.5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f1a91c-26b3-4068-89fe-9547faa350b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5aa5ac-0334-444f-a7c8-fdf2581842c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1325dfc8-0d6c-41c4-811f-6caaf14853bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################################################\n",
    "#####################################################################################################################\n",
    "#####################################################################################################################\n",
    "###############################                Parameter Learning Tables             ###########################\n",
    "#####################################################################################################################\n",
    "#####################################################################################################################\n",
    "#####################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fdae3ae1-b84e-4a31-94d9-59584d00c36b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"../Data/Parameter_Learning_Tables/param_90_CI_stds_log_gamma0_true.csv\""
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function get_up_low(post_dict, upper_quant, lower_quant, γ0_is_log)\n",
    "    p = [upper_quant,lower_quant]\n",
    "    quantiles = zeros(19, 6, 2)\n",
    "    sorted_keys = sort(collect(keys(post_dict)))\n",
    "    # Adjust for when gamma_0 is considered on the log scale\n",
    "\n",
    "        for i in 1:19\n",
    "            mat = post_dict[ sorted_keys[i] ]\n",
    "            quantiles[i, 1,:] = quantile( mat[:,1], p )\n",
    "            quantiles[i, 2,:] = quantile( mat[:,2], p )\n",
    "            quantiles[i, 3,:] = quantile( mat[:,3], p )\n",
    "            quantiles[i, 4,:] = quantile( mat[:,4], p )\n",
    "            quantiles[i, 5,:] = (γ0_is_log) ? quantile( np.log(mat[:,5]), p ) : quantile( mat[:,5], p )\n",
    "            quantiles[i, 6,:] = quantile( mat[:,6], p )\n",
    "        end\n",
    "\n",
    "    return quantiles\n",
    "end\n",
    "\n",
    "Realizations = [string(i) for i in 1:100];\n",
    "cal_years = collect(range(2015,step=15,length=20));\n",
    "\n",
    "# Load the present day posteriors \n",
    "gamma_0_is_log = true\n",
    "present_posterior = np.load(\"../Data/Training_Data/posterior_samples_All_Combined.npy\");\n",
    "\n",
    "# Compute upper and lower quantile bounds for present day posteriors\n",
    "present_bounds = []\n",
    "present_widths = []\n",
    "for i in 1:6\n",
    "    lower = (i == 5 && gamma_0_is_log) ? quantile(np.log(present_posterior[:,i]), 0.05) : quantile(present_posterior[:,i], 0.05)\n",
    "    upper = (i == 5 && gamma_0_is_log) ? quantile(np.log(present_posterior[:,i]), 0.95) : quantile(present_posterior[:,i], 0.95)\n",
    "    push!(present_bounds, (lower,upper))\n",
    "    push!(present_widths, upper - lower)\n",
    "end\n",
    "present_bounds = reshape(present_bounds, 1, :)\n",
    "present_widths = reshape(present_widths, 1, :);\n",
    "\n",
    "\n",
    "# Change to wherever your posterior dictionaries are located\n",
    "path_to_posteriors = \"../Data/Posterior_Data\"\n",
    "\n",
    "# Initialize empty vectors to hold interval bounds and widths \n",
    "all_widths = zeros(length(Realizations),19,6)\n",
    "all_bounds = zeros(length(Realizations), 19, 6, 2)\n",
    "\n",
    "\n",
    "# Loop to calculate quantiles and credible interval widths\n",
    "    for (iter, r) in enumerate(Realizations)\n",
    "        post = JLD2.load(\"$(path_to_posteriors)/R_$(r)_Posterior_Dict.jld2\", \"post_data\")\n",
    "        cred_int_90_up_low = get_up_low(post, 0.95, 0.05,gamma_0_is_log)\n",
    "        all_bounds[iter, :, :, :] = cred_int_90_up_low\n",
    "        all_widths[iter,:,:] = cred_int_90_up_low[:,:,1] .- cred_int_90_up_low[:,:,2]\n",
    "    end\n",
    "# The average 5th percentile and and 95th percentiles of the six MALI parameters across all trajectories over the 19 years of calibration\n",
    "avg_bounds = mean(all_bounds,dims=1)\n",
    "avg_bounds = dropdims(avg_bounds, dims=1)\n",
    "\n",
    "# The average 90% credible interval widths of the six MALI parameters across all trajectories for each of the 19 years of calibration\n",
    "avg_widths = mean(all_widths,dims=1)\n",
    "avg_widths = dropdims(avg_widths, dims=1)\n",
    "# The standard deviation of 90% credible interval widths of the six MALI parameters across all trajectories for each of the 19 years of calibration\n",
    "std_widths = std(all_widths,dims=1)\n",
    "std_widths = dropdims(std_widths,dims=1);\n",
    "\n",
    "\n",
    "# Store the bounds as tuples in one matrix\n",
    "bounds_as_tuples = fill((0.0,0.0),(19,6))\n",
    "for i in 1:19\n",
    "    for j in 1:6\n",
    "        bounds_as_tuples[i,j] = (avg_bounds[i,j,2], avg_bounds[i,j,1])\n",
    "    end\n",
    "end\n",
    "# Add the 2015 90% credible interval bounds\n",
    "bounds_w_present = vcat(present_bounds, bounds_as_tuples);\n",
    "\n",
    "# Add the 2015 90% credible widths\n",
    "widths_w_present = vcat(present_widths, avg_widths);\n",
    "\n",
    "\n",
    "# Add the years of calibration as another column\n",
    "bounds_w_years = hcat(cal_years, bounds_w_present)\n",
    "widths_w_years = hcat(cal_years, widths_w_present)\n",
    "std_w_years = hcat(cal_years[2:end], std_widths)\n",
    "\n",
    "# Dataframe column names\n",
    "names = [\"Latest_calibration_year\",\"vmThresh\",\"fricExp\",\"mu_scale\",\"stiff_scale\",\"gamma0\",\"melt_flux\"]\n",
    "\n",
    "# Covnert to datframe before saving to disc\n",
    "params_df_bounds = DataFrame(bounds_w_years, names)\n",
    "params_df_widths = DataFrame(widths_w_years, names)\n",
    "params_df_std = DataFrame(std_w_years, names)\n",
    "\n",
    "#Calculate total percent decrease of 90% cred interval width\n",
    "pct_change = ((collect(params_df_widths[1,2:end]) .- collect(params_df_widths[20,2:end])) ./ collect(params_df_widths[1,2:end])) .* 100\n",
    "# Make a 1×7 row: first element is label, then pct_change values\n",
    "new_row = hcat(\"total_%_decrease\", pct_change...)\n",
    "# Convert to DataFrame with the same column names\n",
    "new_df = DataFrame(new_row, names)\n",
    "# Append to params_df_widths\n",
    "append!(params_df_widths, new_df)\n",
    "\n",
    "\n",
    "CSV.write(\"../Data/Parameter_Learning_Tables/param_90_CI_bounds_log_gamma0_$(gamma_0_is_log).csv\",params_df_bounds)\n",
    "CSV.write(\"../Data/Parameter_Learning_Tables/param_90_CI_widths_log_gamma0_$(gamma_0_is_log).csv\",params_df_widths)\n",
    "CSV.write(\"../Data/Parameter_Learning_Tables/param_90_CI_stds_log_gamma0_$(gamma_0_is_log).csv\",   params_df_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "69f30841-4e55-47df-a0a5-03609ccc5678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>20×13 DataFrame</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">LearningPeriod</th><th style = \"text-align: left;\">ΔvmThresh</th><th style = \"text-align: left;\">Δ_%_vmThresh</th><th style = \"text-align: left;\">Δ_fricExp</th><th style = \"text-align: left;\">Δ_%_fricExp</th><th style = \"text-align: left;\">Δ_mu_scale</th><th style = \"text-align: left;\">Δ_%_mu_scale</th><th style = \"text-align: left;\">Δ_stiff_scale</th><th style = \"text-align: left;\">Δ_%_stiff_scale</th><th style = \"text-align: left;\">Δ_gamma0</th><th style = \"text-align: left;\">Δ_%_gamma0</th><th style = \"text-align: left;\">Δ_melt_flux</th><th style = \"text-align: left;\">Δ_%_melt_flux</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"Any\" style = \"text-align: left;\">Any</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: left;\">2015 - 2030</td><td style = \"text-align: left;\">-308.545</td><td style = \"text-align: left;\">3.69178</td><td style = \"text-align: left;\">-0.00499717</td><td style = \"text-align: left;\">3.30688</td><td style = \"text-align: left;\">-0.0199084</td><td style = \"text-align: left;\">13.9869</td><td style = \"text-align: left;\">-0.00978005</td><td style = \"text-align: left;\">8.45708</td><td style = \"text-align: left;\">-0.0647679</td><td style = \"text-align: left;\">2.83889</td><td style = \"text-align: left;\">-0.109738</td><td style = \"text-align: left;\">0.935563</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: left;\">2030 - 2045</td><td style = \"text-align: left;\">-15.5338</td><td style = \"text-align: left;\">0.185864</td><td style = \"text-align: left;\">-0.00828424</td><td style = \"text-align: left;\">5.4821</td><td style = \"text-align: left;\">-0.00453845</td><td style = \"text-align: left;\">3.18854</td><td style = \"text-align: left;\">-0.00531249</td><td style = \"text-align: left;\">4.59386</td><td style = \"text-align: left;\">-0.210791</td><td style = \"text-align: left;\">9.23934</td><td style = \"text-align: left;\">-0.191358</td><td style = \"text-align: left;\">1.63141</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: left;\">2045 - 2060</td><td style = \"text-align: left;\">-122.379</td><td style = \"text-align: left;\">1.46428</td><td style = \"text-align: left;\">-0.00178388</td><td style = \"text-align: left;\">1.18048</td><td style = \"text-align: left;\">-0.00177861</td><td style = \"text-align: left;\">1.24958</td><td style = \"text-align: left;\">-0.00371431</td><td style = \"text-align: left;\">3.21187</td><td style = \"text-align: left;\">-0.455934</td><td style = \"text-align: left;\">19.9844</td><td style = \"text-align: left;\">-0.364953</td><td style = \"text-align: left;\">3.11139</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4</td><td style = \"text-align: left;\">2060 - 2075</td><td style = \"text-align: left;\">-167.098</td><td style = \"text-align: left;\">1.99935</td><td style = \"text-align: left;\">-0.00372934</td><td style = \"text-align: left;\">2.46789</td><td style = \"text-align: left;\">-0.00314946</td><td style = \"text-align: left;\">2.21269</td><td style = \"text-align: left;\">-0.00529938</td><td style = \"text-align: left;\">4.58252</td><td style = \"text-align: left;\">-0.55393</td><td style = \"text-align: left;\">24.2797</td><td style = \"text-align: left;\">-1.69436</td><td style = \"text-align: left;\">14.4451</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5</td><td style = \"text-align: left;\">2075 - 2090</td><td style = \"text-align: left;\">-321.917</td><td style = \"text-align: left;\">3.85177</td><td style = \"text-align: left;\">-0.00170556</td><td style = \"text-align: left;\">1.12866</td><td style = \"text-align: left;\">-0.00494637</td><td style = \"text-align: left;\">3.47513</td><td style = \"text-align: left;\">-0.00561054</td><td style = \"text-align: left;\">4.85159</td><td style = \"text-align: left;\">-0.0411684</td><td style = \"text-align: left;\">1.80448</td><td style = \"text-align: left;\">-1.21598</td><td style = \"text-align: left;\">10.3668</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">6</td><td style = \"text-align: left;\">2090 - 2105</td><td style = \"text-align: left;\">-538.596</td><td style = \"text-align: left;\">6.44437</td><td style = \"text-align: left;\">-0.0058047</td><td style = \"text-align: left;\">3.84127</td><td style = \"text-align: left;\">-0.0168463</td><td style = \"text-align: left;\">11.8356</td><td style = \"text-align: left;\">-0.0112585</td><td style = \"text-align: left;\">9.73551</td><td style = \"text-align: left;\">-0.0666812</td><td style = \"text-align: left;\">2.92275</td><td style = \"text-align: left;\">-0.40298</td><td style = \"text-align: left;\">3.43558</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">7</td><td style = \"text-align: left;\">2105 - 2120</td><td style = \"text-align: left;\">-247.567</td><td style = \"text-align: left;\">2.96217</td><td style = \"text-align: left;\">-0.00649159</td><td style = \"text-align: left;\">4.29581</td><td style = \"text-align: left;\">-0.00608864</td><td style = \"text-align: left;\">4.27765</td><td style = \"text-align: left;\">-0.00357312</td><td style = \"text-align: left;\">3.08977</td><td style = \"text-align: left;\">-0.118359</td><td style = \"text-align: left;\">5.18788</td><td style = \"text-align: left;\">-0.295708</td><td style = \"text-align: left;\">2.52104</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">8</td><td style = \"text-align: left;\">2120 - 2135</td><td style = \"text-align: left;\">-396.591</td><td style = \"text-align: left;\">4.74526</td><td style = \"text-align: left;\">-0.00358477</td><td style = \"text-align: left;\">2.37222</td><td style = \"text-align: left;\">-0.00296495</td><td style = \"text-align: left;\">2.08306</td><td style = \"text-align: left;\">-0.00619757</td><td style = \"text-align: left;\">5.35921</td><td style = \"text-align: left;\">-0.121818</td><td style = \"text-align: left;\">5.33949</td><td style = \"text-align: left;\">-1.96177</td><td style = \"text-align: left;\">16.725</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">9</td><td style = \"text-align: left;\">2135 - 2150</td><td style = \"text-align: left;\">-293.688</td><td style = \"text-align: left;\">3.51401</td><td style = \"text-align: left;\">-0.0040266</td><td style = \"text-align: left;\">2.6646</td><td style = \"text-align: left;\">-0.00290024</td><td style = \"text-align: left;\">2.0376</td><td style = \"text-align: left;\">-0.00486038</td><td style = \"text-align: left;\">4.2029</td><td style = \"text-align: left;\">-0.119725</td><td style = \"text-align: left;\">5.24774</td><td style = \"text-align: left;\">-0.744808</td><td style = \"text-align: left;\">6.34982</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">10</td><td style = \"text-align: left;\">2150 - 2165</td><td style = \"text-align: left;\">-964.573</td><td style = \"text-align: left;\">11.5412</td><td style = \"text-align: left;\">-0.00661458</td><td style = \"text-align: left;\">4.37721</td><td style = \"text-align: left;\">-0.00893586</td><td style = \"text-align: left;\">6.278</td><td style = \"text-align: left;\">-0.0119692</td><td style = \"text-align: left;\">10.3501</td><td style = \"text-align: left;\">-0.0808131</td><td style = \"text-align: left;\">3.54218</td><td style = \"text-align: left;\">-1.84135</td><td style = \"text-align: left;\">15.6983</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">11</td><td style = \"text-align: left;\">2165 - 2180</td><td style = \"text-align: left;\">-1686.36</td><td style = \"text-align: left;\">20.1775</td><td style = \"text-align: left;\">-0.0149479</td><td style = \"text-align: left;\">9.89181</td><td style = \"text-align: left;\">-0.016751</td><td style = \"text-align: left;\">11.7686</td><td style = \"text-align: left;\">-0.0119412</td><td style = \"text-align: left;\">10.3259</td><td style = \"text-align: left;\">-0.124965</td><td style = \"text-align: left;\">5.47744</td><td style = \"text-align: left;\">-0.284675</td><td style = \"text-align: left;\">2.42698</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">12</td><td style = \"text-align: left;\">2180 - 2195</td><td style = \"text-align: left;\">-718.861</td><td style = \"text-align: left;\">8.60126</td><td style = \"text-align: left;\">-0.0193752</td><td style = \"text-align: left;\">12.8216</td><td style = \"text-align: left;\">-0.0221357</td><td style = \"text-align: left;\">15.5517</td><td style = \"text-align: left;\">-0.0123007</td><td style = \"text-align: left;\">10.6367</td><td style = \"text-align: left;\">-0.162757</td><td style = \"text-align: left;\">7.13391</td><td style = \"text-align: left;\">-0.512709</td><td style = \"text-align: left;\">4.37107</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">13</td><td style = \"text-align: left;\">2195 - 2210</td><td style = \"text-align: left;\">-616.187</td><td style = \"text-align: left;\">7.37275</td><td style = \"text-align: left;\">-0.024443</td><td style = \"text-align: left;\">16.1752</td><td style = \"text-align: left;\">-0.0161101</td><td style = \"text-align: left;\">11.3183</td><td style = \"text-align: left;\">-0.00865414</td><td style = \"text-align: left;\">7.48347</td><td style = \"text-align: left;\">-0.0417534</td><td style = \"text-align: left;\">1.83013</td><td style = \"text-align: left;\">-0.634782</td><td style = \"text-align: left;\">5.4118</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">14</td><td style = \"text-align: left;\">2210 - 2225</td><td style = \"text-align: left;\">-1071.7</td><td style = \"text-align: left;\">12.823</td><td style = \"text-align: left;\">-0.0243698</td><td style = \"text-align: left;\">16.1267</td><td style = \"text-align: left;\">-0.0068389</td><td style = \"text-align: left;\">4.80475</td><td style = \"text-align: left;\">-0.00618077</td><td style = \"text-align: left;\">5.34469</td><td style = \"text-align: left;\">-0.0527569</td><td style = \"text-align: left;\">2.31243</td><td style = \"text-align: left;\">-0.251814</td><td style = \"text-align: left;\">2.14683</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">15</td><td style = \"text-align: left;\">2225 - 2240</td><td style = \"text-align: left;\">-196.089</td><td style = \"text-align: left;\">2.34623</td><td style = \"text-align: left;\">-0.00977141</td><td style = \"text-align: left;\">6.46624</td><td style = \"text-align: left;\">-0.00096097</td><td style = \"text-align: left;\">0.675141</td><td style = \"text-align: left;\">-0.000426912</td><td style = \"text-align: left;\">0.369163</td><td style = \"text-align: left;\">-0.0196073</td><td style = \"text-align: left;\">0.859424</td><td style = \"text-align: left;\">-0.293243</td><td style = \"text-align: left;\">2.50003</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">16</td><td style = \"text-align: left;\">2240 - 2255</td><td style = \"text-align: left;\">-232.935</td><td style = \"text-align: left;\">2.78709</td><td style = \"text-align: left;\">-0.00554666</td><td style = \"text-align: left;\">3.67051</td><td style = \"text-align: left;\">-0.00342037</td><td style = \"text-align: left;\">2.40303</td><td style = \"text-align: left;\">-0.00368177</td><td style = \"text-align: left;\">3.18373</td><td style = \"text-align: left;\">-0.0169904</td><td style = \"text-align: left;\">0.744721</td><td style = \"text-align: left;\">-0.272976</td><td style = \"text-align: left;\">2.32724</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">17</td><td style = \"text-align: left;\">2255 - 2270</td><td style = \"text-align: left;\">-208.125</td><td style = \"text-align: left;\">2.49024</td><td style = \"text-align: left;\">-0.00303334</td><td style = \"text-align: left;\">2.00732</td><td style = \"text-align: left;\">-0.00255489</td><td style = \"text-align: left;\">1.79497</td><td style = \"text-align: left;\">-0.00175677</td><td style = \"text-align: left;\">1.51913</td><td style = \"text-align: left;\">-0.0120906</td><td style = \"text-align: left;\">0.529954</td><td style = \"text-align: left;\">-0.278997</td><td style = \"text-align: left;\">2.37857</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">18</td><td style = \"text-align: left;\">2270 - 2285</td><td style = \"text-align: left;\">-176.922</td><td style = \"text-align: left;\">2.11689</td><td style = \"text-align: left;\">-0.00179055</td><td style = \"text-align: left;\">1.1849</td><td style = \"text-align: left;\">-0.000823553</td><td style = \"text-align: left;\">0.578597</td><td style = \"text-align: left;\">-0.00173379</td><td style = \"text-align: left;\">1.49926</td><td style = \"text-align: left;\">-0.0107193</td><td style = \"text-align: left;\">0.469845</td><td style = \"text-align: left;\">-0.159063</td><td style = \"text-align: left;\">1.35608</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">19</td><td style = \"text-align: left;\">2285 - 2300</td><td style = \"text-align: left;\">-73.9552</td><td style = \"text-align: left;\">0.884883</td><td style = \"text-align: left;\">-0.000813894</td><td style = \"text-align: left;\">0.538595</td><td style = \"text-align: left;\">-0.000683377</td><td style = \"text-align: left;\">0.480115</td><td style = \"text-align: left;\">-0.00139174</td><td style = \"text-align: left;\">1.20347</td><td style = \"text-align: left;\">-0.00582455</td><td style = \"text-align: left;\">0.2553</td><td style = \"text-align: left;\">-0.218327</td><td style = \"text-align: left;\">1.86134</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">20</td><td style = \"text-align: left;\">2015 - 2300</td><td style = \"text-align: left;\">-8357.62</td><td style = \"text-align: left;\">100.0</td><td style = \"text-align: left;\">-0.151114</td><td style = \"text-align: left;\">100.0</td><td style = \"text-align: left;\">-0.142336</td><td style = \"text-align: left;\">100.0</td><td style = \"text-align: left;\">-0.115643</td><td style = \"text-align: left;\">100.0</td><td style = \"text-align: left;\">-2.28145</td><td style = \"text-align: left;\">100.0</td><td style = \"text-align: left;\">-11.7296</td><td style = \"text-align: left;\">100.0</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccc}\n",
       "\t& LearningPeriod & ΔvmThresh & Δ\\_\\%\\_vmThresh & Δ\\_fricExp & Δ\\_\\%\\_fricExp & Δ\\_mu\\_scale & \\\\\n",
       "\t\\hline\n",
       "\t& Any & Any & Any & Any & Any & Any & \\\\\n",
       "\t\\hline\n",
       "\t1 & 2015 - 2030 & -308.545 & 3.69178 & -0.00499717 & 3.30688 & -0.0199084 & $\\dots$ \\\\\n",
       "\t2 & 2030 - 2045 & -15.5338 & 0.185864 & -0.00828424 & 5.4821 & -0.00453845 & $\\dots$ \\\\\n",
       "\t3 & 2045 - 2060 & -122.379 & 1.46428 & -0.00178388 & 1.18048 & -0.00177861 & $\\dots$ \\\\\n",
       "\t4 & 2060 - 2075 & -167.098 & 1.99935 & -0.00372934 & 2.46789 & -0.00314946 & $\\dots$ \\\\\n",
       "\t5 & 2075 - 2090 & -321.917 & 3.85177 & -0.00170556 & 1.12866 & -0.00494637 & $\\dots$ \\\\\n",
       "\t6 & 2090 - 2105 & -538.596 & 6.44437 & -0.0058047 & 3.84127 & -0.0168463 & $\\dots$ \\\\\n",
       "\t7 & 2105 - 2120 & -247.567 & 2.96217 & -0.00649159 & 4.29581 & -0.00608864 & $\\dots$ \\\\\n",
       "\t8 & 2120 - 2135 & -396.591 & 4.74526 & -0.00358477 & 2.37222 & -0.00296495 & $\\dots$ \\\\\n",
       "\t9 & 2135 - 2150 & -293.688 & 3.51401 & -0.0040266 & 2.6646 & -0.00290024 & $\\dots$ \\\\\n",
       "\t10 & 2150 - 2165 & -964.573 & 11.5412 & -0.00661458 & 4.37721 & -0.00893586 & $\\dots$ \\\\\n",
       "\t11 & 2165 - 2180 & -1686.36 & 20.1775 & -0.0149479 & 9.89181 & -0.016751 & $\\dots$ \\\\\n",
       "\t12 & 2180 - 2195 & -718.861 & 8.60126 & -0.0193752 & 12.8216 & -0.0221357 & $\\dots$ \\\\\n",
       "\t13 & 2195 - 2210 & -616.187 & 7.37275 & -0.024443 & 16.1752 & -0.0161101 & $\\dots$ \\\\\n",
       "\t14 & 2210 - 2225 & -1071.7 & 12.823 & -0.0243698 & 16.1267 & -0.0068389 & $\\dots$ \\\\\n",
       "\t15 & 2225 - 2240 & -196.089 & 2.34623 & -0.00977141 & 6.46624 & -0.00096097 & $\\dots$ \\\\\n",
       "\t16 & 2240 - 2255 & -232.935 & 2.78709 & -0.00554666 & 3.67051 & -0.00342037 & $\\dots$ \\\\\n",
       "\t17 & 2255 - 2270 & -208.125 & 2.49024 & -0.00303334 & 2.00732 & -0.00255489 & $\\dots$ \\\\\n",
       "\t18 & 2270 - 2285 & -176.922 & 2.11689 & -0.00179055 & 1.1849 & -0.000823553 & $\\dots$ \\\\\n",
       "\t19 & 2285 - 2300 & -73.9552 & 0.884883 & -0.000813894 & 0.538595 & -0.000683377 & $\\dots$ \\\\\n",
       "\t20 & 2015 - 2300 & -8357.62 & 100.0 & -0.151114 & 100.0 & -0.142336 & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m20×13 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m LearningPeriod \u001b[0m\u001b[1m ΔvmThresh \u001b[0m\u001b[1m Δ_%_vmThresh \u001b[0m\u001b[1m Δ_fricExp    \u001b[0m\u001b[1m Δ_%_fricExp \u001b[0m\u001b[1m Δ_m\u001b[0m ⋯\n",
       "     │\u001b[90m Any            \u001b[0m\u001b[90m Any       \u001b[0m\u001b[90m Any          \u001b[0m\u001b[90m Any          \u001b[0m\u001b[90m Any         \u001b[0m\u001b[90m Any\u001b[0m ⋯\n",
       "─────┼──────────────────────────────────────────────────────────────────────────\n",
       "   1 │ 2015 - 2030     -308.545   3.69178       -0.00499717   3.30688      -0. ⋯\n",
       "   2 │ 2030 - 2045     -15.5338   0.185864      -0.00828424   5.4821       -0.\n",
       "   3 │ 2045 - 2060     -122.379   1.46428       -0.00178388   1.18048      -0.\n",
       "   4 │ 2060 - 2075     -167.098   1.99935       -0.00372934   2.46789      -0.\n",
       "   5 │ 2075 - 2090     -321.917   3.85177       -0.00170556   1.12866      -0. ⋯\n",
       "   6 │ 2090 - 2105     -538.596   6.44437       -0.0058047    3.84127      -0.\n",
       "   7 │ 2105 - 2120     -247.567   2.96217       -0.00649159   4.29581      -0.\n",
       "   8 │ 2120 - 2135     -396.591   4.74526       -0.00358477   2.37222      -0.\n",
       "   9 │ 2135 - 2150     -293.688   3.51401       -0.0040266    2.6646       -0. ⋯\n",
       "  10 │ 2150 - 2165     -964.573   11.5412       -0.00661458   4.37721      -0.\n",
       "  11 │ 2165 - 2180     -1686.36   20.1775       -0.0149479    9.89181      -0.\n",
       "  12 │ 2180 - 2195     -718.861   8.60126       -0.0193752    12.8216      -0.\n",
       "  13 │ 2195 - 2210     -616.187   7.37275       -0.024443     16.1752      -0. ⋯\n",
       "  14 │ 2210 - 2225     -1071.7    12.823        -0.0243698    16.1267      -0.\n",
       "  15 │ 2225 - 2240     -196.089   2.34623       -0.00977141   6.46624      -0.\n",
       "  16 │ 2240 - 2255     -232.935   2.78709       -0.00554666   3.67051      -0.\n",
       "  17 │ 2255 - 2270     -208.125   2.49024       -0.00303334   2.00732      -0. ⋯\n",
       "  18 │ 2270 - 2285     -176.922   2.11689       -0.00179055   1.1849       -0.\n",
       "  19 │ 2285 - 2300     -73.9552   0.884883      -0.000813894  0.538595     -0.\n",
       "  20 │ 2015 - 2300     -8357.62   100.0         -0.151114     100.0        -0.\n",
       "\u001b[36m                                                               8 columns omitted\u001b[0m"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##CALCULATING THE YEAR BY YEAR CHANGE IN UNCERTAINTY RANGES FOR EACH PARAMETER, AS WELL AS PERCENT CONTRIBUTION TO TOTAL LEARNING\n",
    "##\n",
    "cal_years = collect(range(2015,step=15,length=20))\n",
    "\n",
    "Δ_param_width = zeros(20, 6)\n",
    "Δ_param_width_pct = zeros(20, 6)\n",
    "\n",
    "#Total learning from 2015 - 2300\n",
    "\n",
    "# find row indices\n",
    "total_idx1 = only(findall(x -> x == 2015, cal_years))\n",
    "total_idx2 = only(findall(x -> x == 2300, cal_years))\n",
    "\n",
    "# extract vectors (dropping year column)\n",
    "present = collect(params_df_widths[total_idx1, :])[2:end]\n",
    "final = collect(params_df_widths[total_idx2, :])[2:end]\n",
    "\n",
    "# compute differences\n",
    "total_diff = final .- present\n",
    "Δ_param_width[20, :] = total_diff\n",
    "Δ_param_width_pct[20,:] .= 100.0\n",
    "\n",
    "learn_periods = []\n",
    "\n",
    "for i in 1:(length(cal_years)-1)\n",
    "    yr1 = cal_years[i]\n",
    "    yr2 = cal_years[i+1]\n",
    "\n",
    "    # find row indices\n",
    "    row_idx1 = only(findall(x -> x == yr1, cal_years))\n",
    "    row_idx2 = only(findall(x -> x == yr2, cal_years))\n",
    "\n",
    "    # extract vectors (dropping year column)\n",
    "    row1 = collect(params_df_widths[row_idx1, :])[2:end]\n",
    "    row2 = collect(params_df_widths[row_idx2, :])[2:end]\n",
    "\n",
    "    # compute differences\n",
    "    diff = row2 .- row1\n",
    "    Δ_param_width[i, :] = diff\n",
    "    Δ_param_width_pct[i, :] = (diff ./ total_diff) .* 100\n",
    "    # Collect this learning period as string for datframe labels\n",
    "    push!(learn_periods, \"$(yr1) - $(yr2)\")\n",
    "end\n",
    "\n",
    "# Add the total learning period\n",
    "push!(learn_periods, \"2015 - 2300\")\n",
    "table_mat = zeros(20,12)\n",
    "\n",
    "# Put the parameter width changes and percent changes together param by param columnwise\n",
    "for i in 1:6\n",
    "    table_mat[:,(2*i)-1] = Δ_param_width[:,i]\n",
    "    table_mat[:,(2*i)] = Δ_param_width_pct[:,i]\n",
    "end\n",
    "\n",
    "\n",
    "names = [\"LearningPeriod\",\"ΔvmThresh\",\"Δ_%_vmThresh\",\"Δ_fricExp\",\"Δ_%_fricExp\",\"Δ_mu_scale\",\"Δ_%_mu_scale\",\"Δ_stiff_scale\",\"Δ_%_stiff_scale\",\"Δ_gamma0\",\"Δ_%_gamma0\",\"Δ_melt_flux\",\"Δ_%_melt_flux\"]\n",
    "table_mat_w_years = hcat(learn_periods, table_mat)\n",
    "df_bounds_benchmarks = DataFrame(table_mat_w_years, names)\n",
    "CSV.write(\"../Data/Parameter_Learning_Tables/delta_yr_to_yr_widths_w_pcgts_log_gamma0_$(gamma_0_is_log).csv\", df_bounds_benchmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "9f9e18f4-875e-46a2-bc3e-318afd6d173a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"../Data/Parameter_Learning_Tables/param_STD_learning_w_pcgts_log_gamma0_true.csv\""
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##CALCULATING THE YEAR BY YEAR CHANGE IN UNCERTAINTY RANGE STANDARD DEVIATION FOR EACH PARAMETER, AS WELL AS PERCENT CONTRIBUTION TO TOTAL CHANGE\n",
    "##\n",
    "cal_years = collect(range(2030,step=15,length=19))\n",
    "\n",
    "Δ_param_std = zeros(19, 6)\n",
    "Δ_param_std_pct = zeros(19, 6)\n",
    "\n",
    "#Total learning from 2015 - 2300\n",
    "\n",
    "# find row indices\n",
    "total_idx1 = only(findall(x -> x == 2030, cal_years))\n",
    "total_idx2 = only(findall(x -> x == 2300, cal_years))\n",
    "\n",
    "# extract vectors (dropping year column)\n",
    "present = collect(params_df_std[total_idx1, :])[2:end]\n",
    "final = collect(params_df_std[total_idx2, :])[2:end]\n",
    "\n",
    "# compute differences\n",
    "total_diff = final .- present\n",
    "Δ_param_std[19, :] = round.(total_diff, sigdigits = 6)\n",
    "Δ_param_std_pct[19,:] .= 100.0\n",
    "\n",
    "learn_periods = []\n",
    "\n",
    "for i in 1:(length(cal_years)-1)\n",
    "    yr1 = cal_years[i]\n",
    "    yr2 = cal_years[i+1]\n",
    "\n",
    "    # find row indices\n",
    "    row_idx1 = only(findall(x -> x == yr1, cal_years))\n",
    "    row_idx2 = only(findall(x -> x == yr2, cal_years))\n",
    "\n",
    "    # extract vectors (dropping year column)\n",
    "    row1 = collect(params_df_std[row_idx1, :])[2:end]\n",
    "    row2 = collect(params_df_std[row_idx2, :])[2:end]\n",
    "\n",
    "    # compute differences\n",
    "    diff = row2 .- row1\n",
    "    Δ_param_std[i, :] = round.(diff, sigdigits = 6)\n",
    "    Δ_param_std_pct[i, :] = (diff ./ total_diff) .* 100\n",
    "    # Collect this learning period as string for datframe labels\n",
    "    push!(learn_periods, \"$(yr1) - $(yr2)\")\n",
    "end\n",
    "# Add the total learning period (2015 not included since multiple trajectories only began with 2030 caliobration onward)\n",
    "push!(learn_periods, \"2030 - 2300\")\n",
    "table_mat = zeros(19,12)\n",
    "\n",
    "# Put the parameter width changes and percent changes together param by param columnwise\n",
    "for i in 1:6\n",
    "    table_mat[:,(2*i)-1] = Δ_param_std[:,i]\n",
    "    table_mat[:,(2*i)] = Δ_param_std_pct[:,i]\n",
    "end\n",
    "\n",
    "\n",
    "names = [\"LearningPeriod\",\"ΔvmThresh\",\"Δ_%_vmThresh\",\"Δ_fricExp\",\"Δ_%_fricExp\",\"Δ_mu_scale\",\"Δ_%_mu_scale\",\"Δ_stiff_scale\",\"Δ_%_stiff_scale\",\"Δ_gamma0\",\"Δ_%_gamma0\",\"Δ_melt_flux\",\"Δ_%_melt_flux\"]\n",
    "table_mat_w_years = hcat(learn_periods, table_mat)\n",
    "df_bounds_benchmarks = DataFrame(table_mat_w_years, names)\n",
    "CSV.write(\"../Data/Parameter_Learning_Tables/delta_yr_to_yr_STD_learning_log_gamma0_$(gamma_0_is_log).csv\", df_bounds_benchmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89973969-e1ea-471e-a2cb-fd6eba0124cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################################################\n",
    "#####################################################################################################################\n",
    "#####################################################################################################################\n",
    "###############################                SLR Projection Learning Tables             ###########################\n",
    "#####################################################################################################################\n",
    "#####################################################################################################################\n",
    "#####################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7b1acfad-e0db-4463-8c32-540907062547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All years 2016-2300\n",
    "all_years_no_gap = collect(range(2016, step=1, length=285))\n",
    "\n",
    "yrs_dict = Dict{Int64, Int64}()\n",
    "for (idx,yr) in enumerate(all_years_no_gap)\n",
    "        yrs_dict[yr] = idx\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5fae2a70-cca9-4b8a-90a3-86eecba0eefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The years of projection considered\n",
    "chosen_projection_years = [2100,2200,2300]\n",
    "\n",
    "# Initialize empty arrays (Some entries will be missing due to calibration past year of projection)\n",
    "all_bounds   = Array{Array{Union{Missing,Tuple{Float64,Float64},Int64}}}(undef, length(chosen_projection_years))\n",
    "all_widths   = Array{Array{Union{Missing,Float64,Int64,String}}}(undef, length(chosen_projection_years)) \n",
    "all_Δ_widths = Array{Array{Union{Missing,Float64,Int64}}}(undef, length(chosen_projection_years))\n",
    "all_std      = Array{Array{Union{Missing,Float64,Int64}}}(undef, length(chosen_projection_years))\n",
    "all_Δ_std    = Array{Array{Union{Missing,Float64,Int64}}}(undef, length(chosen_projection_years))\n",
    "\n",
    "# For each projection year considered\n",
    "for (n, year) in enumerate(chosen_projection_years)\n",
    "    \n",
    "    proj_yr_idx = yrs_dict[year]\n",
    "    proj_bounds = Array{Union{Missing,Float64}}(undef,length(Realizations),19,2)\n",
    "    proj_widths = Array{Union{Missing,Float64}}(undef,length(Realizations),19)\n",
    "    \n",
    "    # For each of the 100 trajectories considered\n",
    "    for j in 1:length(Realizations)\n",
    "        # For each of the 19 calibrating years considered\n",
    "        for (iter,yr) in enumerate(cal_years[2:end])\n",
    "                cal_year_matrix = JLD2.load(\"../Data/Projection_Data/R_$(Realizations[j])/$(Realizations[j])-year$(yr)pred_VAF.jld2\",\n",
    "                    \"sample_post_mm_ssp5\")\n",
    "                proj_bounds[j,iter,1] = quantile(cal_year_matrix[proj_yr_idx,:], 0.05)\n",
    "                proj_bounds[j,iter,2] = quantile(cal_year_matrix[proj_yr_idx,:], 0.95)\n",
    "                proj_widths[j,iter] = proj_bounds[j,iter,2] - proj_bounds[j,iter,1]\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # Average across the 100 trajectories\n",
    "    avg_bounds = dropdims(mean(proj_bounds,dims=1),dims=1)\n",
    "    avg_widths = dropdims(mean(proj_widths,dims=1),dims=1)\n",
    "    std_widths = dropdims(std(proj_widths,dims=1),dims=1)\n",
    "\n",
    "\n",
    "    # Load the present day projections\n",
    "    present_projections = JLD2.load(\"../Data/Projection_Data/2015_SLR_Projections.jld2\",\"present2015_post_mm_ssp5\")\n",
    "    present_lower = quantile(present_projections[proj_yr_idx,:], 0.05)\n",
    "    present_upper = quantile(present_projections[proj_yr_idx,:], 0.95)\n",
    "    present_width = present_upper - present_lower\n",
    "\n",
    "    # Add present day projections to beginning of lists above\n",
    "    bounds_w_present = vcat([present_lower;; present_upper], avg_bounds)\n",
    "    widths_w_present = vcat([present_width], avg_widths);\n",
    "    # Store the bounds as tuples in one matrix\n",
    "    slr_tuple_bounds = [(round(bounds_w_present[i,1],sigdigits=6),round(bounds_w_present[i,2],sigdigits=6)) for i in 1:length(bounds_w_present[:,1])]\n",
    "\n",
    "    # Calculate year to year change in average cred interval width \n",
    "    width_change = widths_w_present[2:end] .- widths_w_present[1:end-1]\n",
    "    # widths_w_present[end] - widths_w_present[1]\n",
    "    \n",
    "    # Calculate year to year change in the standard deviation of the 90% cred interval widths\n",
    "    # As well as the total change from 2030 to 2300\n",
    "    std_width_change = std_widths[2:end] .- std_widths[1:end-1]\n",
    "    # std_widths[end] - std_widths[1]\n",
    "\n",
    "    # Push this projection years quantities to list containing all the projection years\n",
    "    all_bounds[n]   = slr_tuple_bounds\n",
    "    all_widths[n]   =  widths_w_present\n",
    "    all_Δ_widths[n] = width_change\n",
    "    all_std[n]      =  std_widths\n",
    "    all_Δ_std[n]    =  std_width_change\n",
    "    \n",
    "    \n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1684fda1-7917-49d7-a273-29374a7e84db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix{Any}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"../Data/SLR_Learning_Tables/SLR_90_CI_std.csv\""
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add the years of calibration as another column\n",
    "bounds_w_years = hcat(cal_years, reduce(hcat, all_bounds))\n",
    "widths_w_years = hcat(cal_years, reduce(hcat, all_widths))\n",
    "std_w_years = hcat( cal_years[2:end], reduce(hcat, all_std ) )\n",
    "\n",
    "\n",
    "\n",
    "names = [\"Latest year of calibration\",\"2100\", \"2200\",\"2300\"]\n",
    "\n",
    "# Convert to dataframes before saving to disc\n",
    "slr_df_bounds  = DataFrame(bounds_w_years, names)\n",
    "slr_df_widths  = DataFrame(widths_w_years, names)\n",
    "slr_df_std     = DataFrame(std_w_years, names)\n",
    "\n",
    "\n",
    "# Remove data that has been calibrated past its projection year (i.e projections for year 2100 with parameters calibrated in 2105)\n",
    "for yr in names[2:3]\n",
    "    n_useful = (parse(Int, yr) - 2015) ÷ 15\n",
    "    slr_df_bounds[n_useful+2:end, yr] .= missing\n",
    "    slr_df_widths[n_useful+2:end, yr] .= missing \n",
    "    slr_df_std[n_useful+1:end, yr] .= missing    \n",
    "\n",
    "end\n",
    "\n",
    "#Calculate total percent decrease of 90% cred interval width\n",
    "pct_change2100 = ((slr_df_widths[1,2] - slr_df_widths[6,2]) /  slr_df_widths[1,2]) * 100\n",
    "pct_change2200 = ((slr_df_widths[1,3] - slr_df_widths[13,3]) /  slr_df_widths[1,3]) * 100\n",
    "pct_change2300 = ((slr_df_widths[1,4] - slr_df_widths[20,4]) /  slr_df_widths[1,4]) * 100\n",
    "\n",
    "# Make a 1×7 row: first element is label, then pct_change values\n",
    "new_row = hcat(\"total_%_decrease\", pct_change2100, pct_change2200, pct_change2300)\n",
    "println(typeof(new_row))\n",
    "# Convert to DataFrame with the same column names\n",
    "new_df = DataFrame(new_row, names)\n",
    "\n",
    "# Append to params_df_widths\n",
    "append!(slr_df_widths, new_df)\n",
    "    \n",
    "CSV.write(\"../Data/SLR_Learning_Tables/SLR_90_CI_bounds.csv\",slr_df_bounds)\n",
    "CSV.write(\"../Data/SLR_Learning_Tables/SLR_90_CI_widths.csv\",slr_df_widths)\n",
    "CSV.write(\"../Data/SLR_Learning_Tables/SLR_90_CI_std.csv\",   slr_df_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c66738f-366b-42f2-95c1-b663f78db914",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "977839e4-d682-4011-be67-80752bbd2a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CALCULATING THE YEAR TO YEAR CHANGE IN 90% UNCERTAINTY RANGES FOR PROJECTIONS OF THE YEARS 2100, 2200, 2300\n",
    "proj_years = [2100,2200,2300]\n",
    "cal_years = collect(range(2015, step=15, length=20))\n",
    "\n",
    "Δ_proj_widths_yty = Array{Array{Union{Float64, Missing}}}(undef, 6)\n",
    "for (i,yr) in enumerate(proj_years)\n",
    "    n_cal_years = ((yr - 2015) ÷ 15) + 1\n",
    "    # Calculate total learning\n",
    "    present_row_idx = only(findall(x -> x == 2015, cal_years))\n",
    "    present_diff = slr_df_widths[n_cal_years, i+1] - slr_df_widths[present_row_idx,i+1]\n",
    "    abs_change = Array{Union{Float64, Missing}}(undef, 20)\n",
    "    pct_change = Array{Union{Float64, Missing}}(undef, 20)\n",
    "    # Calculate the year to year change and percent of total change\n",
    "    proj_yr_widths = slr_df_widths[!,i+1]\n",
    "    abs_change[1:19] = proj_yr_widths[2:end] - proj_yr_widths[1:end-1]\n",
    "    pct_change[1:19] = (abs_change[1:19] ./ present_diff) .* 100\n",
    "    # Add the total change to the end of the list\n",
    "    abs_change[20] = present_diff\n",
    "    # Concatenate to the full matrix\n",
    "    Δ_proj_widths_yty[2*i-1] = abs_change\n",
    "    Δ_proj_widths_yty[2*i] = pct_change\n",
    "        \n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6cd3c056-1c95-4dc7-b536-63b3c1af5787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"../Data/SLR_Learning_Tables/delta_yr_to_yr_SLR_width.csv\""
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Labels for datframe rows\n",
    "learn_periods = vcat([\"$(cal_years[i]) - $(cal_years[i+1])\" for i in 1:(length(cal_years) - 1)], [\"2015 - 2300\"])\n",
    "# Collect labels with data\n",
    "mat_yty_width_change = hcat(learn_periods, reduce(hcat, Δ_proj_widths_yty))\n",
    "# Column labels\n",
    "names = [\"Learning_Period\",\"Δ_2100\",\"Δ_%_2100\",\"Δ_2200\",\"Δ_%_2200\", \"Δ_2300\",\"Δ_%_2300\"]\n",
    "df_yty_width_change  = DataFrame(mat_yty_width_change, names)\n",
    "CSV.write(\"../Data/SLR_Learning_Tables/delta_yr_to_yr_SLR_width.csv\",   df_yty_width_change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3a826b97-9fe6-4d21-987a-698be6308a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CALCULATING THE YEAR TO YEAR CHANGE IN 90% UNCERTAINTY RANGE STANDARD DEVIATION FOR PROJECTIONS OF THE YEARS 2100, 2200, 2300\n",
    "proj_years = [2100,2200,2300]\n",
    "cal_years = collect(range(2030, step=15, length=19))\n",
    "\n",
    "Δ_proj_widths_yty = Array{Array{Union{Float64, Missing}}}(undef, 6)\n",
    "for (i,yr) in enumerate(proj_years)\n",
    "    n_cal_years = ((yr - 2030) ÷ 15) + 1\n",
    "    # Calculate total learning\n",
    "    present_row_idx = only(findall(x -> x == 2030, cal_years))\n",
    "    present_diff = slr_df_std[n_cal_years, i+1] - slr_df_std[present_row_idx,i+1]\n",
    "    abs_change = Array{Union{Float64, Missing}}(undef, 19)\n",
    "    pct_change = Array{Union{Float64, Missing}}(undef, 19)\n",
    "    # Calculate the year to year change and percent of total change\n",
    "    proj_yr_widths = slr_df_std[!,i+1]\n",
    "    abs_change[1:18] = proj_yr_widths[2:end] - proj_yr_widths[1:end-1]\n",
    "    pct_change[1:18] = (abs_change[1:18] ./ present_diff) .* 100\n",
    "    # Add the total change to the end of the list\n",
    "    abs_change[19] = present_diff\n",
    "    # Concatenate to the full matrix\n",
    "    Δ_proj_widths_yty[2*i-1] = abs_change\n",
    "    Δ_proj_widths_yty[2*i] = pct_change\n",
    "        \n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "56a81fba-c407-4517-817b-99e1a54c515b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"../Data/SLR_Learning_Tables/delta_yr_to_yr_SLR_std.csv\""
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Labels for datframe rows\n",
    "learn_periods = vcat([\"$(cal_years[i]) - $(cal_years[i+1])\" for i in 1:(length(cal_years) - 1)], [\"2030 - 2300\"])\n",
    "# Collect labels with data\n",
    "mat_yty_std_change = hcat(learn_periods, reduce(hcat, Δ_proj_widths_yty))\n",
    "# Column labels\n",
    "names = [\"Learning_Period\",\"Δ_2100\",\"Δ_%_2100\",\"Δ_2200\",\"Δ_%_2200\", \"Δ_2300\",\"Δ_%_2300\"]\n",
    "df_yty_std_change  = DataFrame(mat_yty_std_change, names)\n",
    "CSV.write(\"../Data/SLR_Learning_Tables/delta_yr_to_yr_SLR_std.csv\",   df_yty_std_change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4da7b02-27cf-4b79-8477-308ace2a1114",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.5",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
