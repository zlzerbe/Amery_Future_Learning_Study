{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "388df6e4-4407-4617-9d61-211cfc40124f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "using Turing\n",
    "using LinearAlgebra\n",
    "using Distributions\n",
    "using MultivariateStats\n",
    "import MultivariateStats: reconstruct\n",
    "using GaussianProcesses\n",
    "using StatsBase\n",
    "using Statistics\n",
    "using Suppressor\n",
    "using JLD2\n",
    "using CSV\n",
    "using DataFrames, DataFramesMeta\n",
    "using SplitApplyCombine\n",
    "using KernelFunctions\n",
    "using MCMCChains\n",
    "using PyCall\n",
    "using PyPlot\n",
    "using Printf\n",
    "import PyCall.pyfunction\n",
    "using Missings\n",
    "\n",
    "# Access the matplotlib module\n",
    "matplotlib = pyimport(\"matplotlib\")\n",
    "seaborn = pyimport(\"seaborn\")\n",
    "os = pyimport(\"os\")\n",
    "pyimport(\"scienceplots\")\n",
    "np = pyimport(\"numpy\")\n",
    "\n",
    "plt.style.use([\"default\",\"science\",\"no-latex\"])\n",
    "using StatsPlots\n",
    "\n",
    "seaborn.color_palette(\"colorblind\")\n",
    "\n",
    "PyCall.pygui(:tk)\n",
    "\n",
    "# Set a seed for reproducibility\n",
    "using Random\n",
    "Random.seed!(11);\n",
    "\n",
    "FONTSIZE=20.5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98f1a91c-26b3-4068-89fe-9547faa350b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_up_low (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function get_up_low(post_dict, upper_quant, lower_quant)\n",
    "    p = [upper_quant,lower_quant]\n",
    "    quantiles = zeros(19, 6, 2)\n",
    "    sorted_keys = sort(collect(keys(post_dict)))\n",
    "    for i in 1:19\n",
    "        mat = post_dict[ sorted_keys[i] ]\n",
    "        quantiles[i, 1,:] = quantile( mat[:,1], p )\n",
    "        quantiles[i, 2,:] = quantile( mat[:,2], p )\n",
    "        quantiles[i, 3,:] = quantile( mat[:,3], p )\n",
    "        quantiles[i, 4,:] = quantile( mat[:,4], p )\n",
    "        quantiles[i, 5,:] = quantile( mat[:,5], p )\n",
    "        quantiles[i, 6,:] = quantile( mat[:,6], p )\n",
    "    end\n",
    "    return quantiles\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7f5aa5ac-0334-444f-a7c8-fdf2581842c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Realizations = [string(i) for i in 1:100];\n",
    "cal_years = collect(range(2015,step=15,length=20));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1325dfc8-0d6c-41c4-811f-6caaf14853bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################################################\n",
    "#####################################################################################################################\n",
    "#####################################################################################################################\n",
    "###############################                Parameter Learning Tables             ###########################\n",
    "#####################################################################################################################\n",
    "#####################################################################################################################\n",
    "#####################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fdae3ae1-b84e-4a31-94d9-59584d00c36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the present day posteriors \n",
    "present_posterior = np.load(\"../Data/Training_Data/posterior_samples_All_Combined.npy\");\n",
    "# Take the mean of each parameter\n",
    "present_bounds = []\n",
    "present_widths = []\n",
    "for i in 1:6\n",
    "    lower = quantile(present_posterior[:,i], 0.05)\n",
    "    upper = quantile(present_posterior[:,i], 0.95)\n",
    "    push!(present_bounds, (lower,upper))\n",
    "    push!(present_widths, upper - lower)\n",
    "end\n",
    "present_bounds = reshape(present_bounds, 1, :)\n",
    "present_widths = reshape(present_widths, 1, :);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "420fb17f-657a-4e61-88d3-e14f88d920ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 19, 6)\n"
     ]
    }
   ],
   "source": [
    "#CHANGE THIS LINE TO WHERE THE POSTERIORS ARE LOCATED\n",
    "#path_to_posteriors = \"Data/Posterior_Data\"\n",
    "path_to_posteriors = \"../../BrookhavenCode/ProjectNotebooks/Sanket_Results_Posteriors\"\n",
    "\n",
    "output_file_name = \"../Plots/Parametric_Learning_Plots/Without_Trajectories/parametric_learning.csv\"\n",
    "\n",
    "# Initialize empty vectors to hold interval bounds and widths \n",
    "all_widths = zeros(length(Realizations),19,6)\n",
    "all_bounds = zeros(length(Realizations), 19, 6, 2)\n",
    "\n",
    "    for (iter, r) in enumerate(Realizations)\n",
    "        post = JLD2.load(\"$(path_to_posteriors)/R_$(r)_Posterior_Dict.jld2\", \"post_data\")\n",
    "        cred_int_90_up_low = get_up_low(post, 0.95, 0.05)\n",
    "        all_bounds[iter, :, :, :] = cred_int_90_up_low\n",
    "        all_widths[iter,:,:] = cred_int_90_up_low[:,:,1] .- cred_int_90_up_low[:,:,2]\n",
    "    end\n",
    "# The average 5th percentile and and 95th percentiles of the six MALI parameters across all trajectories over the 19 years of calibration\n",
    "avg_bounds = mean(all_bounds,dims=1)\n",
    "avg_bounds = dropdims(avg_bounds, dims=1)\n",
    "\n",
    "# The average 90% credible interval widths of the six MALI parameters across all trajectories for each of the 19 years of calibration\n",
    "avg_widths = mean(all_widths,dims=1)\n",
    "avg_widths = dropdims(avg_widths, dims=1)\n",
    "# The standard deviation of 90% credible interval widths of the six MALI parameters across all trajectories for each of the 19 years of calibration\n",
    "std_widths = std(all_widths,dims=1)\n",
    "println(size(std_widths))\n",
    "std_widths = dropdims(std_widths,dims=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a0d89113-e504-4776-b22e-693807c95ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds_as_tuples = fill((0.0,0.0),(19,6))\n",
    "for i in 1:19\n",
    "    for j in 1:6\n",
    "        bounds_as_tuples[i,j] = (r_avg_bounds[i,j,2], r_avg_bounds[i,j,1])\n",
    "    end\n",
    "end\n",
    "#Include the 2015 90% credible interval bounds\n",
    "bounds_w_present = vcat(present_bounds, bounds_as_tuples);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "743f66c2-6bf0-45dc-81ed-a96ad67f5952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 6)\n",
      "(119,)\n"
     ]
    }
   ],
   "source": [
    "#Include the 2015 90% credible widths\n",
    "widths_w_present = vcat(present_widths, avg_widths);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "a86196e0-2d77-4238-8da4-84c65afea9f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 6)\n",
      "(20, 6)\n"
     ]
    }
   ],
   "source": [
    "width_change = widths_w_present[2:end,:] .- widths_w_present[1:end-1,:];\n",
    "#Append the total width change to the end\n",
    "width_change = vcat(width_change, (widths_w_present[1,:] .- widths_w_present[end,:])')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "ab27613c-4bec-4338-8e1b-b72b40ac2574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19, 6)\n",
      "(19, 6)\n"
     ]
    }
   ],
   "source": [
    "std_change = std_widths[2:end, :] .- std_widths[1:end-1,:];\n",
    "#Append the total std change to the end\n",
    "std_change = vcat(std_change, (std_widths[1, :] .- std_widths[end,:])')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "0e27e752-5334-4f9e-a5e0-4bd80f233289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"../Data/Results_Tables/param_int_width_std_change.csv\""
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add the years of calibration as another column\n",
    "bounds_w_years = hcat(cal_years, bounds_w_present)\n",
    "widths_w_years = hcat(cal_years, widths_w_present)\n",
    "std_w_years = hcat(cal_years[2:end], std_widths)\n",
    "Δ_width_w_years = hcat(vcat(cal_years[2:end], \"Total\"), width_change)\n",
    "Δ_std_w_years = hcat(vcat(cal_years[3:end], \"Total\"), std_change)\n",
    "\n",
    "names = [\"Latest year of calibration\",\"vmThresh\",\"fricExp\",\"mu_scale\",\"stiff_scale\",\"gamma0\",\"melt_flux\"]\n",
    "\n",
    "# Covnert to datframe before saving to disc\n",
    "df_bounds = DataFrame(bounds_w_years, names)\n",
    "df_widths = DataFrame(widths_w_years, names)\n",
    "df_std = DataFrame(std_w_years, names)\n",
    "df_Δ_width = DataFrame(Δ_width_w_years, names)\n",
    "df_Δ_std   = DataFrame(Δ_std_w_years, names)\n",
    "\n",
    "CSV.write(\"../Data/Parameter_Learning_Tables/param_ninety_percent_bounds.csv\",df_bounds)\n",
    "CSV.write(\"../Data/Parameter_Learning_Tables/param_ninety_percent_widths.csv\",df_widths)\n",
    "CSV.write(\"../Data/Parameter_Learning_Tables/param_ninety_percent_std.csv\",df_std)\n",
    "CSV.write(\"../Data/Parameter_Learning_Tables/param_int_width_change.csv\",df_Δ_width)\n",
    "CSV.write(\"../Data/Parameter_Learning_Tables/param_int_width_std_change.csv\",df_Δ_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89973969-e1ea-471e-a2cb-fd6eba0124cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################################################\n",
    "#####################################################################################################################\n",
    "#####################################################################################################################\n",
    "###############################                SLR Projection Learning Tables             ###########################\n",
    "#####################################################################################################################\n",
    "#####################################################################################################################\n",
    "#####################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "7b1acfad-e0db-4463-8c32-540907062547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All years 2016-2300\n",
    "all_years_no_gap = collect(range(2016, step=1, length=285))\n",
    "\n",
    "yrs_dict = Dict{Int64, Int64}()\n",
    "for (idx,yr) in enumerate(all_years_no_gap)\n",
    "        yrs_dict[yr] = idx\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "5fae2a70-cca9-4b8a-90a3-86eecba0eefb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base.ReshapedArray{Union{Missing, Float64}, 2, Array{Union{Missing, Float64}, 3}, Tuple{}}\n",
      "Vector{Float64}\n",
      ".ReshapedArray{Union{Missing, Float64}, 2, Array{Union{Missing, Float64}, 3}, Tuple{}}\n",
      "Vector{Float64}\n",
      "ReshapedArray{Union{Missing, Float64}, 2, Array{Union{Missing, Float64}, 3}, Tuple{}}\n",
      "Vector{Float64}\n"
     ]
    }
   ],
   "source": [
    "chosen_projection_years = [2100,2200,2300]\n",
    "\n",
    "all_bounds   = Array{Array{Union{Missing,Tuple{Float64,Float64},Int64}}}(undef, length(chosen_projection_years))\n",
    "all_widths   = Array{Array{Union{Missing,Float64,Int64}}}(undef, length(chosen_projection_years)) \n",
    "all_Δ_widths = Array{Array{Union{Missing,Float64,Int64}}}(undef, length(chosen_projection_years))\n",
    "all_std      = Array{Array{Union{Missing,Float64,Int64}}}(undef, length(chosen_projection_years))\n",
    "all_Δ_std    = Array{Array{Union{Missing,Float64,Int64}}}(undef, length(chosen_projection_years))\n",
    "\n",
    "for (n, year) in enumerate(chosen_projection_years)\n",
    "    \n",
    "    proj_yr_idx = yrs_dict[year]\n",
    "    proj_bounds = Array{Union{Missing,Float64}}(undef,length(Realizations),19,2)\n",
    "    proj_widths = Array{Union{Missing,Float64}}(undef,length(Realizations),19)\n",
    "    \n",
    "    \n",
    "    for j in 1:length(Realizations)\n",
    "        for (iter,yr) in enumerate(cal_years[2:end])\n",
    "                cal_year_matrix = JLD2.load(\"../../BrookhavenCode/SLR_Projection_Data/Sanket_Results_Projection/R_$(Realizations[j])/$(Realizations[j])-year$(yr)pred_VAF.jld2\",\n",
    "                    \"sample_post_mm_ssp5\")\n",
    "                proj_bounds[j,iter,1] = quantile(cal_year_matrix[proj_yr_idx,:], 0.05)\n",
    "                proj_bounds[j,iter,2] = quantile(cal_year_matrix[proj_yr_idx,:], 0.95)\n",
    "                proj_widths[j,iter] = proj_bounds[j,iter,2] - proj_bounds[j,iter,1]\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # Average across the 100 trajectories\n",
    "    avg_bounds = dropdims(mean(proj_bounds,dims=1),dims=1)\n",
    "    avg_widths = dropdims(mean(proj_widths,dims=1),dims=1)\n",
    "    std_widths = dropdims(std(proj_widths,dims=1),dims=1)\n",
    "    println(typeof(avg_bounds))\n",
    "    println(typeof(std_widths))\n",
    "\n",
    "    \n",
    "    # Load the present day projections\n",
    "    present_projections = JLD2.load(\"../Data/Projection_Data/2015_SLR_Projections.jld2\",\"present2015_post_mm_ssp5\")\n",
    "    present_lower = quantile(present_projections[proj_yr_idx,:], 0.05)\n",
    "    present_upper = quantile(present_projections[proj_yr_idx,:], 0.95)\n",
    "    present_width = present_upper - present_lower\n",
    "\n",
    "    # Add present day projections to beginning of lists above\n",
    "    bounds_w_present = vcat([present_lower;; present_upper], avg_bounds)\n",
    "    slr_tuple_bounds = [(bounds_w_present[i,1],bounds_w_present[i,2]) for i in 1:length(bounds_w_present[:,1])]\n",
    "    widths_w_present = vcat([present_width], avg_widths);\n",
    "\n",
    "    # Calculate year to year change in average cred interval width \n",
    "    # As well as the total change from 2015 to 2300\n",
    "    width_change = vcat(\n",
    "        widths_w_present[2:end] .- widths_w_present[1:end-1],\n",
    "        widths_w_present[end] - widths_w_present[1]\n",
    "    )\n",
    "    \n",
    "    # Calculate year to year change in the standard deviation of the 90% cred interval widths\n",
    "    # As well as the total change from 2030 to 2300\n",
    "    std_width_change = vcat(\n",
    "        std_widths[2:end] .- std_widths[1:end-1],\n",
    "        std_widths[end] - std_widths[1]\n",
    "    )\n",
    "\n",
    "    # Push this projection years quantities to list containing all the projection years\n",
    "    all_bounds[n] = slr_tuple_bounds\n",
    "    all_widths[n]   =  widths_w_present\n",
    "    all_Δ_widths[n] = width_change\n",
    "    all_std[n]      =  std_widths\n",
    "    all_Δ_std[n]    =  std_width_change\n",
    "    \n",
    "    \n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "1684fda1-7917-49d7-a273-29374a7e84db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"../Data/SLR_Learning_Tables/SLR_int_width_std_change.csv\""
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add the years of calibration as another column\n",
    "bounds_w_years = hcat(cal_years, reduce(hcat, all_bounds))\n",
    "widths_w_years = hcat(cal_years, reduce(hcat, all_widths))\n",
    "Δ_width_w_years = hcat( vcat(cal_years[2:end], \"Total\") , reduce(hcat, all_Δ_widths) )\n",
    "std_w_years = hcat( cal_years[2:end], reduce(hcat, all_std ) )\n",
    "Δ_std_w_years = hcat(vcat(cal_years[3:end], \"Total\"), reduce(hcat, all_Δ_std))\n",
    "\n",
    "\n",
    "names = [\"Latest year of calibration\",\"2100\", \"2200\",\"2300\"]\n",
    "\n",
    "# Convert to dataframes before saving to disc\n",
    "df_bounds  = DataFrame(bounds_w_years, names)\n",
    "df_widths  = DataFrame(widths_w_years, names)\n",
    "df_std     = DataFrame(std_w_years, names)\n",
    "df_Δ_width = DataFrame(Δ_width_w_years, names)\n",
    "df_Δ_std   = DataFrame(Δ_std_w_years, names)\n",
    "\n",
    "# Remove data that has been calibrated past its projection year (i.e projections for year 2100 with parameters calibrated in 2105)\n",
    "for yr in names[2:3]\n",
    "    n_useful = (parse(Int, yr) - 2015) ÷ 15\n",
    "    df_bounds[n_useful+2:end, yr] .= missing\n",
    "    df_widths[n_useful+2:end, yr] .= missing \n",
    "    df_std[n_useful+1:end, yr] .= missing    \n",
    "    df_Δ_width[n_useful+1:end, yr] .= missing\n",
    "    df_Δ_std[n_useful:end, yr] .= missing  \n",
    "end\n",
    "    \n",
    "CSV.write(\"../Data/SLR_Learning_Tables/SLR_ninety_percent_bounds.csv\",df_bounds)\n",
    "CSV.write(\"../Data/SLR_Learning_Tables/SLR_ninety_percent_widths.csv\",df_widths)\n",
    "CSV.write(\"../Data/SLR_Learning_Tables/SLR_ninety_percent_std.csv\",df_std)\n",
    "CSV.write(\"../Data/SLR_Learning_Tables/SLR_int_width_change.csv\",df_Δ_width)\n",
    "CSV.write(\"../Data/SLR_Learning_Tables/SLR_int_width_std_change.csv\",df_Δ_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b85e73a-2d9b-4234-9e4d-c51fe1984332",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d29ee6-7d2a-4548-8915-5fc74a0b2fc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a826b97-9fe6-4d21-987a-698be6308a1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.5",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
