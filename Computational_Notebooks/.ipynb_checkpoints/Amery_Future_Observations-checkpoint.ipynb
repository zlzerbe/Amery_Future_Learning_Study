{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c1744e5-1721-4946-94f1-65bef04f4d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names: [:vmThresh, :fricExp, :mu_scale, :stiff_scale, :gamma0, :melt_flux]\n",
      "[:y_grd_vol_2030, :y_grd_vol_2045, :y_grd_vol_2060, :y_grd_vol_2075, :y_grd_vol_2090, :y_grd_vol_2105, :y_grd_vol_2120, :y_grd_vol_2135, :y_grd_vol_2150, :y_grd_vol_2165, :y_grd_vol_2180, :y_grd_vol_2195, :y_grd_vol_2210, :y_grd_vol_2225, :y_grd_vol_2240, :y_grd_vol_2255, :y_grd_vol_2270, :y_grd_vol_2285, :y_grd_vol_2300]\n",
      "[2030, 2045, 2060, 2075, 2090, 2105, 2120, 2135, 2150, 2165, 2180, 2195, 2210, 2225, 2240, 2255, 2270, 2285, 2300]\n",
      "19\n",
      "Sigma values for selected years (via comprehension): [21.402280252346944, 30.80314269680936, 37.94218760166577, 43.936153677808434, 49.20530052748382, 53.96237207536377, 58.33278323550145, 62.39783329571628, 66.21378708396009, 69.82149812199677, 73.25174127623178, 76.5283842766852, 79.67038094549316, 82.6930807262615, 85.60912100938778, 88.42905404899454, 91.16179901691278, 93.81497535042047, 96.39515340513755]\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "using Turing\n",
    "using LinearAlgebra\n",
    "using Distributions\n",
    "using MultivariateStats\n",
    "import MultivariateStats: reconstruct\n",
    "using GaussianProcesses\n",
    "using StatsBase\n",
    "using Statistics\n",
    "using Suppressor\n",
    "using JLD2\n",
    "using CSV\n",
    "using DataFrames, DataFramesMeta\n",
    "using SplitApplyCombine\n",
    "using KernelFunctions\n",
    "using MCMCChains\n",
    "using PyCall\n",
    "using PyPlot\n",
    "using Printf\n",
    "import PyCall.pyfunction\n",
    "\n",
    "\n",
    "scipy = pyimport(\"scipy\")\n",
    "np = pyimport(\"numpy\")\n",
    "skl_model_selection = pyimport(\"sklearn.model_selection\")\n",
    "\n",
    "include(\"../Utils/scale_utils.jl\")\n",
    "using .ScaleUtils\n",
    "\n",
    "include(\"../Utils/gp_utils.jl\")\n",
    "using .GPUtils\n",
    "\n",
    "\n",
    "# Set a seed for reproducibility\n",
    "using Random\n",
    "Random.seed!(734);\n",
    "\n",
    "#####################################################################################################################\n",
    "#####################################################################################################################\n",
    "#####################################################################################################################\n",
    "\n",
    "# Load input parameters from the respective CSV file\n",
    "X_raw = CSV.read(\"../Data/Training_Data/Amery_Input_Parameters_Filtered.csv\", DataFrame);\n",
    "\n",
    "# 1) Grab all column‐names as Symbols\n",
    "cols = Symbol.(names(X_raw))\n",
    "\n",
    "# 2) Remove the index‐column symbol\n",
    "cols = filter(c -> c != :Column1, cols)\n",
    "println(\"Column names: \", cols)\n",
    "\n",
    "# 3) Now call get_scaled_matrix on the remaining columns\n",
    "X_scaled_t, X_scalers, X_mins, X_maxs = ScaleUtils.get_scaled_matrix(X_raw, cols);\n",
    "\n",
    "X_scaled = X_scaled_t'\n",
    "\n",
    "#####################################################################################################################\n",
    "#####################################################################################################################\n",
    "#####################################################################################################################\n",
    "\n",
    "# Grounded Volume Change\n",
    "y_grd_vol_raw = CSV.read(\"../Data/Training_Data/Amery_Grd_Vol_Change_time_series_2300_ssp5.csv\", DataFrame)\n",
    "\n",
    "# 2) Convert each to a plain 119×285 Array\n",
    "# 2.1. Not(1) drops the first column\n",
    "# 2.2. Matrix(...) converts the DataFrame to a plain Matrix \n",
    "# 2.3. collect(...) turns the transpose matrix into a real Array\n",
    "y_grd_vol_fut = collect(Matrix(select(y_grd_vol_raw, Not(1))));\n",
    "\n",
    "# 3) Build the list of “representative” years and their column‐indices\n",
    "gap = 15\n",
    "years = [y for y in 2015:gap:2300 if y != 2015]\n",
    "# Since column 1 corresponds to year 2017, column i ↦ year = 2016 + i.\n",
    "# So to get year Y, use col = (Y – 2016). Equivalently: (Y - 2017) + 1.\n",
    "col_idx = (years .- 2016) \n",
    "\n",
    "# 4) Subset columns of the 119×285 matrix:\n",
    "y_grd_vol_sub = y_grd_vol_fut[:, col_idx]\n",
    "\n",
    "years_all = years\n",
    "y_grd_vol_all = hcat(y_grd_vol_sub)\n",
    "\n",
    "# 5) Build column names for these subset columns:\n",
    "colnames_grd_vol = Symbol.(\"y_grd_vol_\" .* string.(years_all))\n",
    "println(colnames_grd_vol)\n",
    "\n",
    "# 6) Wrap each matrix in a DataFrame, then scale **each column** to [0,1]:\n",
    "df_y_grd_vol_all = DataFrame(y_grd_vol_all, colnames_grd_vol)\n",
    "\n",
    "\n",
    "y_grd_vol_scaled, y_grd_vol_scalers, y_grd_vol_mins, y_grd_vol_maxs =\n",
    "    ScaleUtils.get_scaled_matrix(df_y_grd_vol_all, colnames_grd_vol);\n",
    "\n",
    "\n",
    "#####################################################################################################################\n",
    "#####################################################################################################################\n",
    "#####################################################################################################################\n",
    "\n",
    "\n",
    "# Load dictionaries from disk:\n",
    "#gp_grd_vol_dict = load_emulators(grd_vol_path)\n",
    "gps_Vol_all = GPUtils.load_emulators(\"../Data/Grd_vol_change_gap_15_emulators.jld2\");\n",
    "\n",
    "# Inspect available years:\n",
    "println(\"Emulated years: \", sort(collect(keys(gps_Vol_all))))\n",
    "# => [2030,2045,2060,…,2285]\n",
    "\n",
    "#####################################################################################################################\n",
    "#####################################################################################################################\n",
    "#####################################################################################################################\n",
    "\n",
    "\n",
    "θ_posterior_expert = np.load(\"../Data/Training_Data/posterior_samples_All_Combined.npy\")\n",
    "\n",
    "post_full = DataFrame(vmThresh_post=θ_posterior_expert[:,1], fricExp_post=θ_posterior_expert[:,2], \n",
    "    mu_scale_post=θ_posterior_expert[:,3], stiff_scale_post=θ_posterior_expert[:,4], \n",
    "    gamma0_post=θ_posterior_expert[:,5], melt_flux_post=θ_posterior_expert[:,6]);\n",
    "\n",
    "\n",
    "sample_size = 10000\n",
    "\n",
    "# Get the total number of rows in the DataFrame\n",
    "total_rows = nrow(post_full)\n",
    "# Generate random indices to select rows\n",
    "random_indices = randperm(total_rows)[1:sample_size]\n",
    "# Select the subset of rows using the random indices\n",
    "post = post_full[random_indices, :]\n",
    "\n",
    "\n",
    "\n",
    "#####################################################################################################################\n",
    "#####################################################################################################################\n",
    "#####################################################################################################################\n",
    "\n",
    "# Generate years from 2017 to 2300\n",
    "years = 2017:2300\n",
    "\n",
    "# Compute sigma for each year: 5.720 * sqrt(year - 2016)\n",
    "sigma = 5.720 .* sqrt.(years .- 2016)\n",
    "\n",
    "# Create DataFrame\n",
    "sig_grd_vol = DataFrame(year = collect(years), sigma = sigma)\n",
    "\n",
    "\n",
    "\n",
    "#####################################################################################################################\n",
    "#####################################################################################################################\n",
    "#####################################################################################################################\n",
    "\n",
    "\n",
    "# 1) Extract the future years and count them.\n",
    "years_selected = years_all[1:end]         # e.g. [2030, 2045, …, 2285]\n",
    "n_fut = length(years_selected)           # number of future years\n",
    "println(n_fut)\n",
    "σ_grd_vol = [sig_grd_vol[sig_grd_vol.year .== y, :sigma][1] for y in years_selected]\n",
    "println(\"Sigma values for selected years (via comprehension): \", σ_grd_vol)\n",
    "\n",
    "\n",
    "# 2) Build arrays of GPs and min/max lists in the same order as years_selected:\n",
    "gps_grd_vol = [gps_Vol_all[y] for y in years_selected]\n",
    "\n",
    "Y_gv_mins = [y_grd_vol_mins[Symbol(\"y_grd_vol_$(y)\")] for y in years_selected]\n",
    "Y_gv_maxs = [y_grd_vol_maxs[Symbol(\"y_grd_vol_$(y)\")] for y in years_selected]\n",
    "\n",
    "# 3) Decide how many posterior draws you’ll use (here = 100):\n",
    "n_draws = 50\n",
    "\n",
    "# 4) Pre‐allocate three matrices of size (n_draws × n_fut):\n",
    "Y_grd_vol_obs = zeros(n_draws, n_fut)\n",
    "\n",
    "# 5) Loop over the first n_draws rows of `post`:\n",
    "#    Each row `x` contains the six “_post” parameters you want to rescale → θ.\n",
    "emul_dir = mkpath(\"../Data/Future_Observation_Data/Future_Observations_Test\")\n",
    "\n",
    "for j in 1:n_draws\n",
    "    x = eachrow(post)[j]   # if `post` is a DataFrame; otherwise adjust indexing.\n",
    "\n",
    "    # 5a) Rescale the six inputs into [0,1]:\n",
    "    p_vm     = (x.vmThresh_post    - X_mins[:vmThresh])   / (X_maxs[:vmThresh]    - X_mins[:vmThresh])\n",
    "    p_fric   = (x.fricExp_post     - X_mins[:fricExp])    / (X_maxs[:fricExp]     - X_mins[:fricExp])\n",
    "    p_mu     = (x.mu_scale_post    - X_mins[:mu_scale])   / (X_maxs[:mu_scale]    - X_mins[:mu_scale])\n",
    "    p_stiff  = (x.stiff_scale_post - X_mins[:stiff_scale])/(X_maxs[:stiff_scale] - X_mins[:stiff_scale])\n",
    "    p_gamma0 = (x.gamma0_post      - X_mins[:gamma0])     / (X_maxs[:gamma0]      - X_mins[:gamma0])\n",
    "    p_melt   = (x.melt_flux_post   - X_mins[:melt_flux])  / (X_maxs[:melt_flux]   - X_mins[:melt_flux])\n",
    "\n",
    "    θ = [p_vm;; p_fric;; p_mu;; p_stiff;; p_gamma0;; p_melt]'    # 1×6 row‐vector\n",
    "\n",
    "    # 5b) Predict all future‐year GPs in one “broadcast” call:\n",
    "    grd_vol_preds = predict_y.(gps_grd_vol, Ref(θ))\n",
    "\n",
    "    # 5c) Unpack raw‐means & raw‐vars from each tuple:\n",
    "    μ_gv_raws   = only.([gv[1] for gv in grd_vol_preds])\n",
    "    var_gv_raws = [gv[2][1] for gv in grd_vol_preds]\n",
    "\n",
    "    s_gv_raw = sqrt.(var_gv_raws)\n",
    "\n",
    "    # 5d) Un‐scale raw GPs into original units for each of the n_fut years:\n",
    "    μ_gv_un = μ_gv_raws .* (Y_gv_maxs .- Y_gv_mins) .+ Y_gv_mins\n",
    "    s_gv_un = s_gv_raw    .* (Y_gv_maxs .- Y_gv_mins)\n",
    "\n",
    "    # 5e) Finally, draw a single noisy observation for each future year i:\n",
    "    for i in 1:n_fut\n",
    "        total_sd_grd_vol = sqrt(σ_grd_vol[i]^2 + s_gv_un[i]^2)\n",
    "        Y_grd_vol_obs[j, i] = rand(Normal(μ_gv_un[i], total_sd_grd_vol))\n",
    "    end\n",
    "\n",
    "    # Saveout the 'generative parameters' and the emulator predictions for this trajectory\n",
    "    @save \"$(emul_dir)/$(j)_test_emulator_data.jld2\" θ grd_vol_preds\n",
    "end\n",
    "\n",
    "# Saveout all 100 trajectories to disk\n",
    "@save \"../Data/Future_Observation_Data/test_fut_obs.jld2\" Y_grd_vol_obs\n",
    "\n",
    "\n",
    "#####################################################################################################################\n",
    "#####################################################################################################################\n",
    "#####################################################################################################################\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11e5853-76af-479e-a8ff-991d2c60a781",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.5",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
