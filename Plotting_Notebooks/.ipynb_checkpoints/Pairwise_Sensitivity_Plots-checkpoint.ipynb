{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37bb97fa-f41d-40c3-8ec2-6900f3b87cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "using Turing\n",
    "using LinearAlgebra\n",
    "using Distributions\n",
    "using MultivariateStats\n",
    "import MultivariateStats: reconstruct\n",
    "using GaussianProcesses\n",
    "using StatsBase\n",
    "using Statistics\n",
    "using Suppressor\n",
    "using JLD2\n",
    "using CSV\n",
    "using DataFrames, DataFramesMeta\n",
    "using SplitApplyCombine\n",
    "using KernelFunctions\n",
    "using MCMCChains\n",
    "using PyCall\n",
    "using PyPlot\n",
    "using Printf\n",
    "import PyCall.pyfunction\n",
    "using Optim\n",
    "\n",
    "include(\"../Utils/scale_utils.jl\")\n",
    "using .ScaleUtils\n",
    "\n",
    "include(\"../Utils/gp_utils.jl\")\n",
    "using .GPUtils\n",
    "\n",
    "# Access the matplotlib module\n",
    "matplotlib = pyimport(\"matplotlib\")\n",
    "seaborn = pyimport(\"seaborn\")\n",
    "os = pyimport(\"os\")\n",
    "pyimport(\"scienceplots\")\n",
    "np = pyimport(\"numpy\")\n",
    "scipy = pyimport(\"scipy\")\n",
    "skl_model_selection = pyimport(\"sklearn.model_selection\")\n",
    "plt.style.use([\"default\",\"science\",\"no-latex\"])\n",
    "using StatsPlots\n",
    "\n",
    "seaborn.color_palette(\"colorblind\")\n",
    "\n",
    "PyCall.pygui(:tk)\n",
    "\n",
    "# Set a seed for reproducibility\n",
    "using Random\n",
    "Random.seed!(11);\n",
    "\n",
    "#import Pkg\n",
    "#Pkg.add(\"PrettyTables\")\n",
    "FONTSIZE=20.5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c050e81b-0c7b-4928-aec2-d4fac95ee078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject <class 'matplotlib.backends.backend_pdf.PdfPages'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matplotlib_backends_pdf = pyimport(\"matplotlib.backends.backend_pdf\")\n",
    "PdfPages = matplotlib_backends_pdf.PdfPages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aef35fd5-6637-4481-a1e2-3974d3fcc8e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unscale_params (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function unscale_params(params)\n",
    "    \n",
    "    unscaled_θ_1 = ( params[1] * (X_maxs[:vmThresh] - X_mins[:vmThresh]) ) + X_mins[:vmThresh]\n",
    "    unscaled_θ_2 = ( params[2] * (X_maxs[:fricExp] - X_mins[:fricExp]) ) + X_mins[:fricExp]\n",
    "    unscaled_θ_3 = ( params[3] * (X_maxs[:mu_scale] - X_mins[:mu_scale]) ) + X_mins[:mu_scale]\n",
    "    unscaled_θ_4 = ( params[4] * (X_maxs[:stiff_scale] - X_mins[:stiff_scale]) ) + X_mins[:stiff_scale]\n",
    "    unscaled_θ_5 = ( params[5] * (X_maxs[:gamma0] - X_mins[:gamma0]) ) + X_mins[:gamma0]\n",
    "    unscaled_θ_6 = ( params[6] * (X_maxs[:melt_flux] - X_mins[:melt_flux]) ) + X_mins[:melt_flux];\n",
    "    unscaled_thetas = [unscaled_θ_1\n",
    "                        unscaled_θ_2\n",
    "                        unscaled_θ_3\n",
    "                        unscaled_θ_4\n",
    "                        unscaled_θ_5\n",
    "                        unscaled_θ_6];\n",
    "    return unscaled_thetas\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4f450cc-70a7-48aa-ac7c-9356c7a08454",
   "metadata": {},
   "outputs": [],
   "source": [
    "#All years from 2016 - 2300\n",
    "all_years_no_gap = collect(range(2016, step=1, length=285))\n",
    "yrs_gapped = collect(range(2030, step=15, length=19));\n",
    "\n",
    "# Mapping those years to indicies in a list\n",
    "yrs_dict = Dict{Int64, Int64}()\n",
    "for (idx,yr) in enumerate(all_years_no_gap)\n",
    "        yrs_dict[yr] = idx\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc47725c-9726-4ac9-9779-396814291a99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "calculate_quantiles_mean (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Returns means, upper, and lower quntailes for a single year's prediction from a single (R, yr_calibrated) pair\n",
    "function calculate_quantiles_mean(sample, row)\n",
    "    slice = sample[row, :]\n",
    "    mean_data = mean(slice)\n",
    "    quantile_5 = quantile(slice, 0.05)\n",
    "    quantile_95 = quantile(slice, 0.95)\n",
    "    \n",
    "    return mean_data, quantile_5, quantile_95\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "736a653b-1efb-4586-93c0-af704a848699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple_to_idx (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading original parameter data for scaling purposes\n",
    "X_raw = CSV.read(\"../Data/Training_Data/Amery_Input_Parameters_Filtered.csv\", DataFrame);\n",
    "# 1) Grab all column‐names as Symbols\n",
    "cols = Symbol.(names(X_raw))\n",
    "# 2) Remove the index‐column symbol\n",
    "cols = filter(c -> c != :Column1, cols)\n",
    "# 3) Now call get_scaled_matrix on the remaining columns\n",
    "X_scaled_t, X_scalers, X_mins, X_maxs = ScaleUtils.get_scaled_matrix(X_raw, cols);\n",
    "\n",
    "function tuple_to_idx(x,y)\n",
    "    return ( (3*x - 3) + y )\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77f68923-f3ef-4575-8d8c-1a6df7ff08de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "plot_figure_six (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function plot_figure_six(calibrating_year, year_projected, pdf_saveout)\n",
    "\n",
    "    fig, ax = PyPlot.subplots(nrows=6, ncols=6, figsize=(40, 40), dpi=300,\n",
    "                         gridspec_kw=Dict(\"height_ratios\"=> [1,1,1,1,1,1], \"width_ratios\" => [1,1,1,1,1,1],\n",
    "                                        \"wspace\"=> 0.45, \"hspace\"=> 0.35))\n",
    "    \n",
    "    # Vector holding all SLR cred int widths for projections of the year \"year_projected\" \n",
    "    widths = Vector{Float64}()\n",
    "    # Dictionaries to hold the vectors of generative constraining parameter values for the 100 trajectories \n",
    "    params = Dict([1 => Vector{Float64}(), 2 => Vector{Float64}() , 3 => Vector{Float64}(),\n",
    "        4 => Vector{Float64}(), 5 => Vector{Float64}(), 6 => Vector{Float64}() ])\n",
    "    \n",
    "    #Change the path to wherever your SLR Projections are stored\n",
    "    SLR_projections_path = \"../../BrookhavenCode/SLR_Projection_Data/Sanket_Results_Projection\"\n",
    "    \n",
    "    \n",
    "    for dir in readdir(SLR_projections_path)\n",
    "        if occursin(\"R_\", dir)\n",
    "            n = Int(findfirst(\"_\", dir).start)\n",
    "            r = dir[n+1:end]\n",
    "            proj = JLD2.load(\"$(SLR_projections_path)/$(dir)/$(r)-year$(calibrating_year)pred_VAF.jld2\", \n",
    "                \"sample_post_mm_ssp5\" )            \n",
    "            #Calculate_quantiles and width\n",
    "            mean, lower, upper = calculate_quantiles_mean(proj, yrs_dict[year_projected])\n",
    "            int_width = upper - lower\n",
    "            push!(widths, int_width)\n",
    "            #Load the parameters that generated this trajectories future realistic observations\n",
    "            θ = JLD2.load(\"../Data/Future_Observation_Data/Generative_Parameters/Official_Constraining_Observations-metadata/$(r)_emulator_data.jld2\", \"θ\")\n",
    "            vec_θ = vec(θ)\n",
    "            θ_un = unscale_params(θ)\n",
    "            #Push each parameter into its respective list\n",
    "            for (idx, el) in enumerate(θ_un)\n",
    "                push!(params[idx], el)\n",
    "            end\n",
    "    \n",
    "        end\n",
    "    end\n",
    "\n",
    "    #Define the color map\n",
    "    norm = PyPlot.matplotlib.colors.Normalize(vmin=minimum(widths), vmax=maximum(widths))\n",
    "    cmap = PyPlot.cm.get_cmap(\"magma_r\")\n",
    "    \n",
    "    \n",
    "    for i in 1:6\n",
    "        for j in 1:6\n",
    "            # Plot the SLR cred interval width against each of the unique pairs of the 6 parameter values \n",
    "            if !(i <= j)\n",
    "                    ax[i,j].scatter(params[i], params[j], c=widths,s = 150,cmap=\"magma_r\")\n",
    "                    ax[i,j].set_xlabel(title_dict[i], fontsize = FONTSIZE*1.8,labelpad=20)\n",
    "                    ax[i,j].set_ylabel(title_dict[j],fontsize = FONTSIZE*1.8,labelpad=20)\n",
    "                    ax[i,j].tick_params(axis=\"both\", which=\"major\", labelsize=FONTSIZE*1.2)\n",
    "                    ax[i,j].set_xticks(tick_dict[i])\n",
    "                    ax[i,j].set_yticks(tick_dict[j])\n",
    "                    ax[i,j].grid(true, alpha=0.25, zorder=1)\n",
    "            else\n",
    "                ax[i,j].set_visible(false) \n",
    "            end\n",
    "            \n",
    "        end\n",
    "    end\n",
    "    \n",
    "    scalar_mappable = PyPlot.matplotlib.cm.ScalarMappable(norm=norm, cmap=cmap)\n",
    "    scalar_mappable.set_array(widths)\n",
    "    cbar_ax = fig.add_axes([0.76, 0.22, 0.02, 0.5])  # Position: [left, bottom, width, height]\n",
    "    color_bar = plt.colorbar(scalar_mappable, cax=cbar_ax, pad = 0.1)\n",
    "    cbar_ax.set_title(\"Cred int width\", fontsize=FONTSIZE*2, pad=20)\n",
    "    cbar_ax.tick_params(axis=\"both\", which=\"major\", labelsize=FONTSIZE*1.5)\n",
    "    \n",
    "    \n",
    "    pdf_saveout.savefig(fig)\n",
    "    PyPlot.close(fig)\n",
    "\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92c56488-6da2-4643-9c73-49718d2e57af",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_dict = Dict([\n",
    "            1 => L\"\\sigma_{max}\", 2 => L\"q\" , 3 => L\"C_{\\mu}\" ,\n",
    "            4 => L\"C_{\\phi}\", 5 => L\"log(\\gamma_0)\", 6 => L\"\\overline{m}\" ]) \n",
    "\n",
    "tick_dict = Dict([\n",
    "        1 => [110000,120000,130000,140000], 2 => [0.15,0.2,0.25,0.3], 3 => [0.8,0.9,1,1.1],\n",
    "        4 => [0.8,0.9,1,1.1], 5 => [50000,150000,250000], 6 => [20,30,40,50] ]) \n",
    "\n",
    "#Defining the years at which calibrations take place\n",
    "cal_years = collect(range(2030,step=15,length=19))\n",
    "#Define the year for which you want projection uncertainties\n",
    "chosen_pred_year = 2300\n",
    "#Choose only the calibration years before that chosen projection year\n",
    "truncated_years = filter(x -> x <= chosen_pred_year, cal_years)\n",
    "\n",
    "#Define your plot saveout location\n",
    "param_space_learning_saveout = \"../Plots/Figure_Five_Plots/pw_parameter_space_analysis_draft_$(chosen_pred_year).pdf\"\n",
    "pdf_pages = PdfPages(param_space_learning_saveout)\n",
    "\n",
    "try       \n",
    "    for i in 1:length(truncated_years)\n",
    "        plot_figure_six(cal_years[i], chosen_pred_year, pdf_pages)\n",
    "    end     \n",
    "    \n",
    "finally \n",
    "    # --- Always close the PdfPages object to finalize the PDF file ---\n",
    "    # This ensures the PDF is properly written to disk and not corrupted.\n",
    "    pdf_pages.close()\n",
    "end  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31679097-be5e-4b1f-8d73-bd00b7ef42c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- inputs you already have ---\n",
    "future_obs_directory = \"../Data/Future_Observation_Data/Generative_Parameters/Official_Constraining_Observations-metadata\"\n",
    "output_file_name   = \"../Plots/Sensitivity_Plots/SLR_sensitivity_wrt_parameters.pdf\"\n",
    "SLR_projections_path = \"../Data/Projection_Data\"\n",
    "\n",
    "chosen_year =  2300\n",
    "row_idx = yrs_dict[chosen_year]\n",
    "\n",
    "# --- collect widths for all realizations ---\n",
    "widths = Array{Float64}(undef, length(realizations))\n",
    "θ_mat  = Array{Float64}(undef, length(realizations), 6)\n",
    "\n",
    "# Calculate 90% credible interval widths \n",
    "for (i, r) in enumerate(realizations)\n",
    "    vaf_sample = JLD2.load(joinpath(path_to_projections, \"R_$(r)\", \"$(r)-year$(chosen_year)pred_VAF.jld2\"),\n",
    "                           \"sample_post_mm_ssp5\")\n",
    "    # no trailing comma\n",
    "    μ, lower, upper = calculate_quantiles_mean(vaf_sample, row_idx)\n",
    "\n",
    "    widths_all_years = upper .- lower          # elementwise\n",
    "    widths[i] = widths_all_years[end]          # last year’s width (or use row_idx if that’s per-year already)\n",
    "\n",
    "    θ = JLD2.load(joinpath(future_obs_directory, \"$(r)_emulator_data.jld2\"), \"θ\")\n",
    "    θ_mat[i, :] = unscale_params(θ)            # ensure this returns a 6-vector\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8715a4-1103-48ab-a1ae-51fe8fab9446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assumptions you already have:\n",
    "# - θ_mat :: Matrix{Float64}  (n_realizations × 6)   # parameters per realization\n",
    "# - widths :: Vector{Float64}  (n_realizations)      # 90% CI width at chosen_year\n",
    "# - FONTSIZE, SIZE, EDGECOLOR defined\n",
    "# - title_dict, tick_dict like in your snippet (LaTeXStrings are fine)\n",
    "\n",
    "output_file_name = \"../Plots/Pairwise_Sensitivity_Plots/SLR_sensitivity_wrt_pairwise_parameter_test.pdf\"\n",
    "\n",
    "# Choose a sequential cmap and robust color limits for widths (since widths ≥ 0)\n",
    "const mpl = PyPlot.matplotlib\n",
    "cmap = mpl.cm.get_cmap(\"RdBu\")\n",
    "# vmin, vmax = quantile(widths, [0.05, 0.95])   # robust limits; change to [minimum(widths), maximum(widths)] if you prefer\n",
    "# norm = mpl.colors.Normalize(vmin=vmin, vmax=vmax)\n",
    "\n",
    "# Build all 15 unique pairs (1..6 choose 2), row-major ordering\n",
    "pairs = [(a,b) for a in 1:6 for b in a+1:6]  # length = 15\n",
    "\n",
    "# Figure: 5 rows × 3 cols\n",
    "fig, ax = PyPlot.subplots(nrows=5, ncols=3, figsize=(22, 29))\n",
    "fig.suptitle(\"Sea-level Contributions 90% Credible Interval Widths at $(chosen_year)\"; fontsize=30, fontweight=\"bold\", y=1.008)\n",
    "\n",
    "# If ax is a Matrix{PyObject}, indexing is ax[row, col]\n",
    "for (idx, (xk, yk)) in enumerate(pairs)\n",
    "    rI = 1 + (idx-1) ÷ 3\n",
    "    cI = 1 + (idx-1) % 3\n",
    "    axi = ax[rI, cI]\n",
    "\n",
    "    # Scatter: x = param xk, y = param yk, color = widths\n",
    "    x_var = (xk == 5) ? log.(θ_mat[:, xk]) : θ_mat[:, xk]\n",
    "    y_var = (yk == 5) ? log.(θ_mat[:, yk]) : θ_mat[:, yk]\n",
    "\n",
    "    axi.set_rasterization_zorder(0)\n",
    "    sc = axi.scatter(x_var, y_var;\n",
    "                     s=SIZE*5, c=widths, cmap=cmap, \n",
    "                     edgecolor=EDGECOLOR, linewidth=0.5,\n",
    "                     rasterized=true)\n",
    "\n",
    "    # Labels/ticks/limits\n",
    "    axi.set_xlabel(string(title_dict[xk]), fontsize=FONTSIZE, labelpad=10)\n",
    "    axi.set_ylabel(string(title_dict[yk]), fontsize=FONTSIZE, labelpad=10)\n",
    "    axi.ticklabel_format(style=\"sci\", scilimits=(-3,3), useMathText=true)\n",
    "    axi.tick_params(axis=\"both\", which=\"major\", labelsize=FONTSIZE*0.8)\n",
    "    axi.xaxis.offsetText.set_fontsize(FONTSIZE*0.8)\n",
    "    axi.yaxis.offsetText.set_fontsize(FONTSIZE*0.8)\n",
    "    axi.locator_params(tight=true, nbins=6)\n",
    "    axi.grid(true, alpha=0.5, zorder=1)\n",
    "    axi.set_xticks(tick_dict[xk])\n",
    "    axi.set_yticks(tick_dict[yk])\n",
    "    axi.set_xlim(xlim_dict[xk])\n",
    "    axi.set_ylim(xlim_dict[yk])\n",
    "end\n",
    "\n",
    "# Single shared colorbar on the right\n",
    "plt.tight_layout(rect=[0.0, 0.0, 0.95, 1.0])  # leave room for colorbar\n",
    "cax = fig.add_axes([0.99, 0.25, 0.02, 0.5])  # [left, bottom, width, height]\n",
    "sm = mpl.cm.ScalarMappable(norm=norm, cmap=cmap); sm.set_array([])\n",
    "cbar = fig.colorbar(sm, cax=cax)\n",
    "cbar.ax.set_title(\"90% CI Width\", fontsize=FONTSIZE, pad=20)\n",
    "cbar.ax.tick_params(axis=\"both\", which=\"major\", labelsize=FONTSIZE*0.8)\n",
    "\n",
    "mkpath(dirname(output_file_name))\n",
    "fig.savefig(output_file_name; bbox_inches=\"tight\", dpi=300) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.5",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
