{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b3fed31-0c32-46ad-8491-850d24eb91f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "using Turing\n",
    "using LinearAlgebra\n",
    "using Distributions\n",
    "using MultivariateStats\n",
    "import MultivariateStats: reconstruct\n",
    "using GaussianProcesses\n",
    "using StatsBase\n",
    "using Statistics\n",
    "using Suppressor\n",
    "using JLD2\n",
    "using CSV\n",
    "using DataFrames, DataFramesMeta\n",
    "using SplitApplyCombine\n",
    "using KernelFunctions\n",
    "using MCMCChains\n",
    "using PyCall\n",
    "using PyPlot\n",
    "using Printf\n",
    "import PyCall.pyfunction\n",
    "using Optim\n",
    "\n",
    "include(\"../Utils/scale_utils.jl\")\n",
    "using .ScaleUtils\n",
    "\n",
    "include(\"../Utils/gp_utils.jl\")\n",
    "using .GPUtils\n",
    "\n",
    "# Access the matplotlib module\n",
    "matplotlib = pyimport(\"matplotlib\")\n",
    "seaborn = pyimport(\"seaborn\")\n",
    "os = pyimport(\"os\")\n",
    "pyimport(\"scienceplots\")\n",
    "np = pyimport(\"numpy\")\n",
    "scipy = pyimport(\"scipy\")\n",
    "skl_model_selection = pyimport(\"sklearn.model_selection\")\n",
    "plt.style.use([\"default\",\"science\",\"no-latex\"])\n",
    "using StatsPlots\n",
    "\n",
    "seaborn.color_palette(\"colorblind\")\n",
    "\n",
    "PyCall.pygui(:tk)\n",
    "\n",
    "# Set a seed for reproducibility\n",
    "using Random\n",
    "Random.seed!(11);\n",
    "\n",
    "#import Pkg\n",
    "#Pkg.add(\"PrettyTables\")\n",
    "FONTSIZE=20.5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1f44fa3-ef0c-4f9e-ba30-05e9e23a34af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject <class 'matplotlib.backends.backend_pdf.PdfPages'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matplotlib_backends_pdf = pyimport(\"matplotlib.backends.backend_pdf\")\n",
    "PdfPages = matplotlib_backends_pdf.PdfPages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3b6cafa-9c49-4f7f-8ac1-3321f7eef5cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unscale_params (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function unscale_params(params)\n",
    "    \n",
    "    unscaled_θ_1 = ( params[1] * (X_maxs[:vmThresh] - X_mins[:vmThresh]) ) + X_mins[:vmThresh]\n",
    "    unscaled_θ_2 = ( params[2] * (X_maxs[:fricExp] - X_mins[:fricExp]) ) + X_mins[:fricExp]\n",
    "    unscaled_θ_3 = ( params[3] * (X_maxs[:mu_scale] - X_mins[:mu_scale]) ) + X_mins[:mu_scale]\n",
    "    unscaled_θ_4 = ( params[4] * (X_maxs[:stiff_scale] - X_mins[:stiff_scale]) ) + X_mins[:stiff_scale]\n",
    "    unscaled_θ_5 = ( params[5] * (X_maxs[:gamma0] - X_mins[:gamma0]) ) + X_mins[:gamma0]\n",
    "    unscaled_θ_6 = ( params[6] * (X_maxs[:melt_flux] - X_mins[:melt_flux]) ) + X_mins[:melt_flux];\n",
    "    unscaled_thetas = [unscaled_θ_1\n",
    "                        unscaled_θ_2\n",
    "                        unscaled_θ_3\n",
    "                        unscaled_θ_4\n",
    "                        unscaled_θ_5\n",
    "                        unscaled_θ_6];\n",
    "    return unscaled_thetas\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cba02ed-30eb-4132-aaf5-6eb569d13033",
   "metadata": {},
   "outputs": [],
   "source": [
    "#All years from 2016 - 2300\n",
    "all_years_no_gap = collect(range(2016, step=1, length=285))\n",
    "yrs_gapped = collect(range(2030, step=15, length=19));\n",
    "\n",
    "# Mapping those years to indicies in a list\n",
    "yrs_dict = Dict{Int64, Int64}()\n",
    "for (idx,yr) in enumerate(all_years_no_gap)\n",
    "        yrs_dict[yr] = idx\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ce88061-13f1-43d1-ae6d-aa26766a5185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple_to_idx (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading original parameter data for scaling purposes\n",
    "X_raw = CSV.read(\"../Data/Training_Data/Amery_Input_Parameters_Filtered.csv\", DataFrame);\n",
    "# 1) Grab all column‐names as Symbols\n",
    "cols = Symbol.(names(X_raw))\n",
    "# 2) Remove the index‐column symbol\n",
    "cols = filter(c -> c != :Column1, cols)\n",
    "# 3) Now call get_scaled_matrix on the remaining columns\n",
    "X_scaled_t, X_scalers, X_mins, X_maxs = ScaleUtils.get_scaled_matrix(X_raw, cols);\n",
    "\n",
    "function tuple_to_idx(x,y)\n",
    "    return ( (3*x - 3) + y )\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "258c9437-eddb-40d0-93ab-2322c71740ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "calculate_quantiles_mean (generic function with 1 method)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Returns means, upper, and lower quntailes for a single year's prediction from a single (R, yr_calibrated) pair\n",
    "function calculate_quantiles_mean(sample, row)\n",
    "    slice = sample[row, :]\n",
    "    mean_data = mean(slice)\n",
    "    quantile_5 = quantile(slice, 0.05)\n",
    "    quantile_95 = quantile(slice, 0.95)\n",
    "    \n",
    "    return mean_data, quantile_5, quantile_95\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "234547da-42cf-4baf-955f-a8c54fce8be7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "plot_figure_five (generic function with 1 method)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Function to plot the six parameter values against the learning observed for their corresponding trajectories\n",
    "function plot_figure_five(calibrating_year, year_projected, pdf_saveout)\n",
    "        \n",
    "        fig, ax = PyPlot.subplots(nrows=2, ncols=3, figsize=(18, 11), dpi=300,\n",
    "                             gridspec_kw=Dict(\"height_ratios\"=> [1, 1], \"width_ratios\" => [1, 1, 1],\n",
    "                                            \"wspace\"=> 0.175, \"hspace\"=> 0.25))\n",
    "        #Vectors to hold all quantities of interest from the trajectories\n",
    "        widths = Vector{Float64}()\n",
    "        params = Dict([1 => Vector{Float64}(), 2 => Vector{Float64}() , 3 => Vector{Float64}() ,\n",
    "            4 => Vector{Float64}(), 5 => Vector{Float64}(), 6 => Vector{Float64}() ])\n",
    "\n",
    "        #Change the path to wherever your SLR Projections are stored\n",
    "        SLR_projections_path = \"../../BrookhavenCode/SLR_Projection_Data/Sanket_Results_Projection\"\n",
    "    \n",
    "        #Go through each folder in the directory containing the SLR projection data\n",
    "        for dir in readdir(SLR_projections_path)\n",
    "            if occursin(\"R_\", dir)\n",
    "                #Grab the index of the file string containing the realization number\n",
    "                n = Int(findfirst(\"_\", dir).start)\n",
    "                r = dir[n+1:end]\n",
    "                # Load this specific sample of projections\n",
    "                proj = JLD2.load(\"$(SLR_projections_path)/$(dir)/$(r)-year$(calibrating_year)pred_VAF.jld2\", \n",
    "                    \"sample_post_mm_ssp5\" )            \n",
    "                #Calculate_quantiles and width of the projections of the chosen year\n",
    "                mean, lower, upper = calculate_quantiles_mean(proj, yrs_dict[year_projected])\n",
    "                int_width = upper - lower\n",
    "                push!(widths, int_width)\n",
    "                #Load the parameters that generated this trajectories future realstic observations\n",
    "                θ = JLD2.load(\"../Data/Future_Observation_Data/Generative_Parameters/0.8244943887658679-data/$(r)_emulator_data.jld2\", \"θ\")\n",
    "                vec_θ = vec(θ)\n",
    "                θ_un = unscale_params(θ)\n",
    "                #Push each parameter into its respective list\n",
    "                for (idx, el) in enumerate(θ_un)\n",
    "                    push!(params[idx], el)\n",
    "                end\n",
    "\n",
    "            end\n",
    "        end\n",
    "    \n",
    "        #Plotting\n",
    "        for i in 1:2\n",
    "            for j in 1:3\n",
    "                var_idx = tuple_to_idx(i,j)\n",
    "                ax[i,j].scatter(params[var_idx], widths,label=\"Individual Trajectory\")\n",
    "                #Linear Regression line\n",
    "                m, c = np.polyfit(params[var_idx], widths, 1)\n",
    "                ax[i,j].plot(params[var_idx], (params[var_idx] .* m .+ c), color = \"red\",label=\"Linear regression\")\n",
    "                ax[i,j].set_title(title_dict[var_idx],fontsize=1.2*FONTSIZE, pad=10)    #(\"von Mises threshold (Pa)\")        \n",
    "                ax[i,j].tick_params(axis=\"both\", which=\"major\", labelsize=FONTSIZE*0.8)\n",
    "                ax[i,j].grid(true, alpha=0.25, zorder=1)\n",
    "                ax[i,j].set_xticks(tick_dict[var_idx])\n",
    "\n",
    "            end\n",
    "        end\n",
    "        handles, labels = ax[1,1].get_legend_handles_labels()\n",
    "        desired_indices = [1,2]\n",
    "        sorted_handles = [handles[i] for i in desired_indices]\n",
    "        sorted_labels = [labels[i] for i in desired_indices]\n",
    "        fig.legend(sorted_handles, sorted_labels, loc=\"upper center\", ncol=6, fontsize=FONTSIZE,\n",
    "                   bbox_to_anchor=(0.512, 1), bbox_transform=PyPlot.gcf().transFigure,\n",
    "                   frameon=\"True\", framealpha=1)\n",
    "        fig.supxlabel(\"Parameter value\", fontsize=FONTSIZE*1.2)\n",
    "        fig.supylabel(\"90% uncertainty range\", fontsize=FONTSIZE*1.2)\n",
    "    \n",
    "        pdf_saveout.savefig(fig)\n",
    "        PyPlot.close(fig)\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dccd3283-bc75-4d80-9286-43c58418a3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_dict = Dict([\n",
    "            1 => L\"\\sigma_{max}\", 2 => L\"q\" , 3 => L\"C_{\\mu}\" ,\n",
    "            4 => L\"C_{\\phi}\", 5 => L\"\\gamma_0\", 6 => L\"\\overline{m}\" ]) \n",
    "\n",
    "tick_dict = Dict([\n",
    "        1 => [110000,120000,130000,140000], 2 => [0.15,0.2,0.25,0.3], 3 => [0.8,0.9,1,1.1],\n",
    "        4 => [0.85,0.9,0.95,1,1.05], 5 => [50000,150000,250000], 6 => [20,30,40,50] ]) \n",
    "\n",
    "#Defining the years at which calibrations take place\n",
    "cal_years = collect(range(2030,step=15,length=19))\n",
    "#Define the year for which you want projection uncertainties\n",
    "chosen_pred_year = 2300\n",
    "#Choose only the calibration years before that chosen projection year\n",
    "truncated_years = filter(x -> x <= chosen_pred_year, cal_years)\n",
    "\n",
    "#Define your plot saveout location\n",
    "param_space_learning_saveout = \"../Plots/Figure_Four_Plots/parameter_space_vs_slr_learning_draft_$(chosen_pred_year).pdf\"\n",
    "pdf_pages = PdfPages(param_space_learning_saveout)\n",
    "\n",
    "try       \n",
    "    for i in 1:length(truncated_years)\n",
    "        plot_figure_five(cal_years[i], chosen_pred_year, pdf_pages)\n",
    "    end     \n",
    "    \n",
    "finally \n",
    "    # --- Always close the PdfPages object to finalize the PDF file ---\n",
    "    # This ensures the PDF is properly written to disk and not corrupted.\n",
    "    pdf_pages.close()\n",
    "end  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f789d1f8-3c39-4ba5-9547-0594b6a52211",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e883e9-8558-478a-9a2a-dc59bd6d9b15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.5",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
