{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ceee28d5-cb64-4861-9604-9ca0eb4ad23d",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "SystemError: opening file \"/Users/zachzerbe/BrookhavenPaperDirectory/ProjectNotebooks/scale_utils.jl\": No such file or directory",
     "output_type": "error",
     "traceback": [
      "SystemError: opening file \"/Users/zachzerbe/BrookhavenPaperDirectory/ProjectNotebooks/scale_utils.jl\": No such file or directory",
      "",
      "Stacktrace:",
      " [1] \u001b[0m\u001b[1minclude\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mfname\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m",
      "\u001b[90m   @\u001b[39m \u001b[35mMain\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4msysimg.jl:38\u001b[24m\u001b[39m",
      " [2] top-level scope",
      "\u001b[90m   @\u001b[39m \u001b[90m\u001b[4mIn[1]:25\u001b[24m\u001b[39m"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "using Turing\n",
    "using LinearAlgebra\n",
    "using Distributions\n",
    "using MultivariateStats\n",
    "import MultivariateStats: reconstruct\n",
    "using GaussianProcesses\n",
    "using StatsBase\n",
    "using Statistics\n",
    "using Suppressor\n",
    "using JLD2\n",
    "using CSV\n",
    "using DataFrames, DataFramesMeta\n",
    "using SplitApplyCombine\n",
    "using KernelFunctions\n",
    "using MCMCChains\n",
    "using PyCall\n",
    "using PyPlot\n",
    "using Printf\n",
    "import PyCall.pyfunction\n",
    "using Optim\n",
    "using MCMCChains\n",
    "using DataFrames\n",
    "\n",
    "include(\"./ProjectNotebooks/scale_utils.jl\")\n",
    "using .ScaleUtils\n",
    "\n",
    "include(\"./ProjectNotebooks/gp_utils.jl\")\n",
    "using .GPUtils\n",
    "\n",
    "const CONDA_PREFIX = \"/home/sjantre/miniconda3/envs/julia_new\"\n",
    "using Libdl\n",
    "Libdl.dlopen(joinpath(CONDA_PREFIX, \"lib\", \"libstdc++.so.6\"), Libdl.RTLD_GLOBAL)\n",
    "Libdl.dlopen(joinpath(CONDA_PREFIX, \"lib\", \"libgcc_s.so.1\"), Libdl.RTLD_GLOBAL)\n",
    "using PyCall\n",
    "@show PyCall.python \n",
    "\n",
    "# Access the matplotlib module\n",
    "matplotlib = pyimport(\"matplotlib\")\n",
    "seaborn = pyimport(\"seaborn\")\n",
    "os = pyimport(\"os\")\n",
    "pyimport(\"scienceplots\")\n",
    "np = pyimport(\"numpy\")\n",
    "scipy = pyimport(\"scipy\")\n",
    "plt.style.use([\"default\",\"science\",\"no-latex\"])\n",
    "using StatsPlots\n",
    "const mpl = PyPlot.matplotlib\n",
    "\n",
    "# seaborn.color_palette(\"colorblind\")\n",
    "\n",
    "PyCall.pygui(:tk)\n",
    "\n",
    "# Set a seed for reproducibil7ity\n",
    "using Random\n",
    "rng = MersenneTwister(99)\n",
    "BLAS.set_num_threads(11)\n",
    "np.random.seed(99)\n",
    "Random.seed!(99);\n",
    "\n",
    "#import Pkg\n",
    "#Pkg.add(\"PrettyTables\")\n",
    "FONTSIZE=20.5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdbf1820-024f-4d34-a8c8-0d88803369a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject <class 'matplotlib.backends.backend_pdf.PdfPages'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matplotlib_backends_pdf = pyimport(\"matplotlib.backends.backend_pdf\")\n",
    "PdfPages = matplotlib_backends_pdf.PdfPages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "579561c0-9d61-490e-9942-1ab03ab20d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Loading all calibrated posteriors from a given realization of future observations, storing them into a dictionary\n",
    "\n",
    "# #Note that this function assumes a specific file structure of the HPC_Output_Folder:\n",
    "#     # Example:   Root/output_R1_job808_task0/chains_dir/2030_chain.jld2\n",
    "\n",
    "# sample_size = 5000\n",
    "\n",
    "# function load_data(realization, HPC_Results_Folder, saveout_directory)\n",
    "#     post_data = Dict{Int64, Matrix{Float64}}()\n",
    "\n",
    "#     for dir in readdir(HPC_Results_Folder)\n",
    "#         if occursin(\"_R$(realization)_\", dir)\n",
    "#             chain_path = joinpath(HPC_Results_Folder, dir, \"chains_dir\" )\n",
    "#             #Read only the chains, not the generated quantities, for now\n",
    "#             chain_string = only(readdir(chain_path))\n",
    "#             #Get the current year\n",
    "#             year = parse(Int, SubString(chain_string, 1:4))\n",
    "#             #Load the chain from disc\n",
    "#             current_chain = JLD2.load(\"$(chain_path)/$(chain_string)\", \"chain\" )\n",
    "#             #Convert the chain into a matrix\n",
    "#             chain_matrix = get_params(current_chain)\n",
    "#             θ_post = [chain_matrix.vmThresh;; chain_matrix.fricExp;; chain_matrix.mu_scale;; \n",
    "#                          chain_matrix.stiff_scale;; chain_matrix.gamma0;; chain_matrix.melt_flux]\n",
    "#             #Add this matrix to the dicrtionary according to its last year of constraining observation\n",
    "\n",
    "#             post_data[ year ] = θ_post\n",
    "    \n",
    "#         end\n",
    "#     end\n",
    "#     #Save this dictionary to disk\n",
    "#     @save \"$(saveout_directory)/R_$(realization)_Posterior_Dict.jld2\" post_data\n",
    "    \n",
    "#     return nothing\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d06adf33-d105-4958-87f9-8c6f7c7f7008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Define the path to where your HPC results are\n",
    "# hpc_data_directory = \"./MCMC_Outputs_Sanket_ReRuns_New_All\" # \"../../BrookhavenCode/ProjectNotebooks/MCMC_Outputs_Sanket\"\n",
    "# saveout_location = \"./Data/Posterior_Data_New_All\"\n",
    "\n",
    "# #Realization numbers\n",
    "# Realizations = [i for i in 1:100];\n",
    "# # Realizations = [4, 15, 20, 25, 44, 47, 67, 81, 82, 89, 100]\n",
    "\n",
    "# for r in Realizations\n",
    "#     load_data(r, hpc_data_directory, saveout_location)\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4820ba3-37b4-4646-ab1b-698c7f00853d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Measures\n",
    "# base = \"/home/sjantre/Projects/Future_Learning/BrookhavenCode/MCMC_Outputs_Sanket_Failed_ReRuns_New_2\"\n",
    "# real = 67\n",
    "# years = [2060, 2075, 2090, 2105]                       # <-- change freely\n",
    "# want   = [:vmThresh, :fricExp, :mu_scale, :stiff_scale, :gamma0, :melt_flux]\n",
    "# max_iter = 50_00                            # target draws per chain for plotting\n",
    "# trace_outdir  = \"./Plots/Trace_Plots\"\n",
    "# corner_outdir = \"./Plots/Pairwise\"\n",
    "\n",
    "# # --- helpers ---\n",
    "# function find_chain_path(base::AbstractString, realization::Int, year::Int)\n",
    "#     dirs = filter(d -> occursin(\"_R$(realization)_\", d), readdir(base))\n",
    "#     for d in dirs\n",
    "#         chain_dir = joinpath(base, d, \"chains_dir\")\n",
    "#         isdir(chain_dir) || continue\n",
    "#         files = readdir(chain_dir)\n",
    "#         isempty(files) && continue\n",
    "#         f = only(files)                           # one file per chains_dir\n",
    "#         y = parse(Int, first(f, 4))               # first 4 chars are the year\n",
    "#         y == year && return joinpath(chain_dir, f)\n",
    "#     end\n",
    "#     error(\"No chain file found for realization $realization, year $year in $base\")\n",
    "# end\n",
    "\n",
    "# mkpath(trace_outdir); mkpath(corner_outdir)\n",
    "\n",
    "# # load chains for requested years\n",
    "# paths  = Dict(y => find_chain_path(base, real, y) for y in years)\n",
    "# chains = Dict(y => JLD2.load(paths[y], \"chain\") for y in years)  # Dict{Int,Chains}\n",
    "\n",
    "# chain_matrix(ch::Chains, vars) = begin\n",
    "#     A = Array(ch[:, vars, :])                     # (iter, param, chain)\n",
    "#     reshape(A, size(A,1) * size(A,3), size(A,2))  # -> (draws, params)\n",
    "# end\n",
    "\n",
    "# # # winsorize columns to robust limits\n",
    "# # function winsorize_cols!(X; lo=0.005, hi=0.995)\n",
    "# #     @assert 0.0 ≤ lo < hi ≤ 1.0\n",
    "# #     for j in axes(X, 2)\n",
    "# #         v = view(X, :, j)                      # SubArray view of column j\n",
    "# #         qlo, qhi = quantile(v, (lo, hi))\n",
    "# #         @. v = clamp(v, qlo, qhi)\n",
    "# #     end\n",
    "# #     return X\n",
    "# # end\n",
    "\n",
    "\n",
    "# for y in years\n",
    "#     ch = chains[y]\n",
    "#     pars = isempty(want) ? names(ch, :parameters) : intersect(want, names(ch, :parameters))\n",
    "\n",
    "#     # thin to ~max_iter iterations\n",
    "#     step    = max(1, cld(size(ch, 1), max_iter))\n",
    "#     ch_thin = ch[1:step:end, pars, :]  # (iter, parameters, chain)\n",
    "\n",
    "#     # — trace plot (renumber iterations for a clean x-axis) —\n",
    "#     ch_plot = Chains(Array(ch_thin), collect(pars); start=1, thin=1)\n",
    "#     p_trace = StatsPlots.plot(ch_plot; seriestype=:traceplot, legend=false,\n",
    "#         title=\"Realization $real — Year $y (thinned ×$step)\",\n",
    "#         layout=(length(pars), 1), size=(1100, max(220*length(pars), 300)))\n",
    "#     StatsPlots.savefig(p_trace, joinpath(trace_outdir, \"R$(real)_$(y)_trace_thin_New_2.pdf\"))\n",
    "\n",
    "#     gr(size=(400,300))\n",
    "#     # --- corner (pairwise) plot ---\n",
    "#     if length(pars) ≥ 2\n",
    "#         X = chain_matrix(ch_thin, pars)  # draws × params\n",
    "#         cell = 380\n",
    "#         n    = size(X, 2)\n",
    "\n",
    "#         p_corr = corrplot(\n",
    "#             X ,compact=true;\n",
    "#             label = permutedims(String.(pars)),  # labels per column\n",
    "#             grid  = true,\n",
    "#             size  = (cell*n, cell*n)\n",
    "#         )\n",
    "#         StatsPlots.savefig(p_corr, joinpath(corner_outdir, \"R$(real)_$(y)_corner_New_2.pdf\"))\n",
    "#     else\n",
    "#         @info \"Skipping corner plot for year $y (need ≥2 parameters)\", pars\n",
    "#     end\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc89d2c0-b7d7-4cc1-bd65-d8fa4f4fc559",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "################################################################################\n",
    "################################################################################\n",
    "\n",
    "# KDE PLOTS\n",
    "\n",
    "################################################################################\n",
    "################################################################################\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a9ede78-4569-4840-bd43-c5542534bff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # PRIOR DISTRIBUTIONS\n",
    "\n",
    "# sample_size = 5000\n",
    "\n",
    "# vmThresh_vals = collect(np.linspace(80000+0.00001, 180000-0.00001, sample_size))\n",
    "# fricExp_vals = collect(np.linspace(0.1+0.00001, 0.333-0.00001, sample_size))\n",
    "# mu_scale_vals = collect(np.linspace(0.8+0.00001, 1.2-0.00001, sample_size))\n",
    "# stiff_scale_vals = collect(np.linspace(0.8+0.00001, 1.2-0.00001, sample_size))\n",
    "# gamma0_vals = collect(np.linspace(9620+0.0001, 471000-0.0001, sample_size))\n",
    "# melt_flux_vals = collect(np.linspace(12+0.0001, 58-0.0001, sample_size))\n",
    "\n",
    "\n",
    "# vmThresh_prior = collect(scipy.stats.truncnorm.pdf(vmThresh_vals, a=-3, b=3, loc=130000, scale=50000/3))\n",
    "# fricExp_prior = collect(scipy.stats.trapezoid.pdf(fricExp_vals, c=0.05/0.233, d=0.18/0.233, loc=0.1, scale=0.233))\n",
    "# mu_scale_prior = collect(scipy.stats.truncnorm.pdf(mu_scale_vals, a=-2, b=2, loc=1.0, scale=0.1))\n",
    "# stiff_scale_prior = collect(scipy.stats.truncnorm.pdf(stiff_scale_vals, a=-2, b=2, loc=1.0, scale=0.1))\n",
    "# trunc_norm_gamma0 = scipy.stats.truncnorm(a=np.log(9620)-10, b=np.log(471000)-10, loc=10, scale=1)\n",
    "# gamma0_prior = collect(trunc_norm_gamma0.pdf(np.log(gamma0_vals)) ./ gamma0_vals)\n",
    "# melt_flux_prior = collect(scipy.stats.truncnorm.pdf(melt_flux_vals, a=-2, b=2, loc=35, scale=11.5))\n",
    "\n",
    "# θ_prior = [vmThresh_prior;; fricExp_prior;; mu_scale_prior;; \n",
    "#      stiff_scale_prior;; gamma0_prior;; melt_flux_prior];\n",
    "\n",
    "#Loading original parameter data for scaling purposes\n",
    "X_raw = CSV.read(\"./ProjectNotebooks/Data/Amery_Input_Parameters_Filtered.csv\", DataFrame);\n",
    "# 1) Grab all column‐names as Symbols\n",
    "cols = Symbol.(names(X_raw))\n",
    "# 2) Remove the index‐column symbol\n",
    "cols = filter(c -> c != :Column1, cols)\n",
    "# 3) Now call get_scaled_matrix on the remaining columns\n",
    "X_scaled_t, X_scalers, X_mins, X_maxs = ScaleUtils.get_scaled_matrix(X_raw, cols);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1ebd439-0ef2-442a-8b08-f8730d410159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unscale_params (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function unscale_params(params)\n",
    "    \n",
    "    unscaled_θ_1 = ( params[1] * (X_maxs[:vmThresh] - X_mins[:vmThresh]) ) + X_mins[:vmThresh]\n",
    "    unscaled_θ_2 = ( params[2] * (X_maxs[:fricExp] - X_mins[:fricExp]) ) + X_mins[:fricExp]\n",
    "    unscaled_θ_3 = ( params[3] * (X_maxs[:mu_scale] - X_mins[:mu_scale]) ) + X_mins[:mu_scale]\n",
    "    unscaled_θ_4 = ( params[4] * (X_maxs[:stiff_scale] - X_mins[:stiff_scale]) ) + X_mins[:stiff_scale]\n",
    "    unscaled_θ_5 = ( params[5] * (X_maxs[:gamma0] - X_mins[:gamma0]) ) + X_mins[:gamma0]\n",
    "    unscaled_θ_6 = ( params[6] * (X_maxs[:melt_flux] - X_mins[:melt_flux]) ) + X_mins[:melt_flux];\n",
    "    unscaled_thetas = [unscaled_θ_1\n",
    "                        unscaled_θ_2\n",
    "                        unscaled_θ_3\n",
    "                        unscaled_θ_4\n",
    "                        unscaled_θ_5\n",
    "                        unscaled_θ_6];\n",
    "    return unscaled_thetas\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1314eca2-7f6f-45f7-a5ac-5f791e2c087c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using KernelDensity\n",
    "\n",
    "# @inline function _trapz(x::AbstractVector{<:Real}, y::AbstractVector{<:Real})\n",
    "#     @assert length(x) == length(y) && length(x) ≥ 2\n",
    "#     s = zero(eltype(x))\n",
    "#     @inbounds for i in 1:length(x)-1\n",
    "#         s += (x[i+1] - x[i]) * (y[i+1] + y[i])\n",
    "#     end\n",
    "#     return s/2\n",
    "# end\n",
    "\n",
    "# function rescale_kde(data, a, b; npoints=1024)\n",
    "#     # # Fit a KDE to the data\n",
    "#     # x = sort(float.(collect(skipmissing(data))))\n",
    "#     # lo, hi = minmax(float(a), float(b))\n",
    "#     # if lo == hi\n",
    "#     #     δ = max(eps(lo)*100, 1e-9)\n",
    "#     #     lo -= δ; hi += δ\n",
    "#     # end\n",
    "#     # kd = kde(x)\n",
    "#     # xs = range(lo, hi; length=npoints)\n",
    "#     # ys = pdf(kd, xs)\n",
    "#     # # normalize on [lo,hi]\n",
    "#     # mass = _trapz(xs, ys)\n",
    "#     # ys = mass > 0 ? ys ./ mass : zeros(length(xs))\n",
    "#     # return collect(xs), ys\n",
    "\n",
    "#     # Fit a KDE to the data\n",
    "#     data_sorted = sort(data)\n",
    "#     kde = KernelDensity.kde(data_sorted)\n",
    "#     # Evaluate the KDE at the grid points\n",
    "#     kde_values = pdf(kde, data_sorted)\n",
    "#     # Compute the CDF\n",
    "#     cdf = cumsum(kde_values)\n",
    "#     # Normalize the CDF\n",
    "#     cdf ./= cdf[end]\n",
    "#     # Calculate the probability that the variable is between a and b\n",
    "#     last = searchsortedfirst(data_sorted, b)\n",
    "#     if  last > size(data_sorted)[1]\n",
    "#         last = last - 1\n",
    "#     end\n",
    "#     prob_a_to_b = cdf[last] - cdf[searchsortedfirst(data_sorted, a)]\n",
    "#     # Filter all the data to be less than b or greater than a\n",
    "#     mask = a .<= data_sorted .<= b\n",
    "#     filtered_data = data_sorted[mask]\n",
    "\n",
    "#     # Rescale the KDE values within [a, b] and zero out values outside\n",
    "#     #Since we're looking at values between A and B and we want to get a PDF for those values,\n",
    "#     # the curve must integrate to 1 to be valid. Rescaling below allows this to happen.\n",
    "#     kde_values_rescaled = pdf(kde, filtered_data) / prob_a_to_b\n",
    "\n",
    "# #     return data_sorted, kde_values_rescaled\n",
    "#     return filtered_data, kde_values_rescaled\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c47e881c-421b-4b76-84ad-015c3a4eb8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Previous paper's Calibrated Posteriors\n",
    "θ_posterior_2015 = np.load(\"./ProjectNotebooks/Data/posterior_samples_All_Combined.npy\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "493f113f-c285-430a-a424-af574c56e1d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple_to_idx (generic function with 1 method)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #Just a helper function that maps a tuple to a single index for a 2x3 grid of plots\n",
    "function tuple_to_idx(x,y)\n",
    "    return ( (3*x - 3) + y )\n",
    "end\n",
    "\n",
    "# #Function that plots a specific parameter's distribution from the posteriors dervied in Sanket's Paper\n",
    "# function plot_previous(previous_post, ax, var_idx)\n",
    "\n",
    "#         uppers_and_lowers = Dict([  1 => (80000,180000), 2 => (0.1,0.333),\n",
    "#                             3 => (0.8,1.2), 4 => (0.8,1.2),\n",
    "#                             5 => (np.log(9620),np.log(471000)), 6 => (12,58)  ])\n",
    "    \n",
    "#         current_params = previous_post[:, var_idx]\n",
    "#         param_mean = mean(current_params)\n",
    "#         #Gamma_0 requires a log scale\n",
    "#         if var_idx == 5\n",
    "#             x, y = rescale_kde(np.log(current_params), uppers_and_lowers[var_idx][1], uppers_and_lowers[var_idx][2] )\n",
    "#             ax.plot(x, y,color=\"red\", label = 2015, lw=1.75)\n",
    "#             #ax.axvline(x=param_mean) #ymin=0, ymax=ax.get_ylim()[2], color = \"red\", linestyle=\"dashed\"\n",
    "\n",
    "\n",
    "#         else\n",
    "#             x, y = rescale_kde(current_params, uppers_and_lowers[var_idx][1], uppers_and_lowers[var_idx][2] )\n",
    "#             ax.plot(x, y, color=\"red\", label = \"Present-day (2015) posterior\", lw=1.75)\n",
    "#             #ax.axvline(x=param_mean) #ymin=0, ymax=ax.get_ylim()[2], color = \"red\", linestyle=\"dashed\"\n",
    "                \n",
    "#         end\n",
    "# end\n",
    "    \n",
    "    \n",
    "# #Function to plot all years worth of a specific paramerters distributions\n",
    "# function plot_one_var_posterior(post_dict, years, ax, var_idx, cmaplist)\n",
    "\n",
    "#     uppers_and_lowers = Dict([  1 => (80000,180000), 2 => (0.1,0.333),\n",
    "#                                 3 => (0.8,1.2), 4 => (0.8,1.2),\n",
    "#                                 5 => (np.log(9620),np.log(471000)), 6 => (12,58)  ])\n",
    "    \n",
    "#     for i in 1:length(years)\n",
    "#         #Get all n_obs posteriors for one variable\n",
    "#         #Below is line 41\n",
    "#         current_params = post_dict[years[i]][:,var_idx]\n",
    "\n",
    "#         x = filter(isfinite, float.(current_params))\n",
    "#         a, b = uppers_and_lowers[var_idx][1], uppers_and_lowers[var_idx][2]\n",
    "#         # println(\"a=$(a) b=$(b)  extrema(x)=$(extrema(x))  var≈\", var(x))\n",
    "        \n",
    "#         #Gamma_0 requires a log scale\n",
    "#         if var_idx == 5\n",
    "#                 x, y = rescale_kde(np.log(current_params), uppers_and_lowers[var_idx][1], uppers_and_lowers[var_idx][2] )\n",
    "#                 ax.plot(x, y, lw=1.8, color= cmaplist(norm(years[i])))\n",
    "#         else\n",
    "#                 x, y = rescale_kde(current_params, uppers_and_lowers[var_idx][1], uppers_and_lowers[var_idx][2] )\n",
    "#                 ax.plot(x, y, lw=1.8, color= cmaplist(norm(years[i])) )\n",
    "#         end\n",
    "#     end       \n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b0eb3ab-ad3d-4b93-b4c6-9fa8b919d0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Function that plots all posterior distribtuons of all parameters\n",
    "\n",
    "# function plot_all_Rs_KDE_pdf(real, post_dict, years, cmaplist, prev, pdf, theta)\n",
    "   \n",
    "#             fig, ax = PyPlot.subplots(nrows=2, ncols=3, figsize=(18, 11), dpi=300,\n",
    "#                              gridspec_kw=Dict(\"height_ratios\"=> [1, 1], \"width_ratios\" => [1, 1, 1],\n",
    "#                                               \"wspace\"=> 0.175, \"hspace\"=> 0.25))\n",
    "\n",
    "#             # fig.suptitle(\"Realization $real\"; fontsize=30, fontweight=\"bold\", y=0.96)\n",
    "    \n",
    "#             title_dict = Dict([\n",
    "#                 1 => L\"\\sigma_{max}\", 2 => L\"q\" , 3 => L\"C_{\\mu}\" ,\n",
    "#                 4 => L\"C_{\\phi}\", 5 => L\"\\log(\\gamma_0)\", 6 => L\"\\overline{m}\" ]) \n",
    "    \n",
    "#             tick_dict = Dict([\n",
    "#                     1 => [80000,100000,120000,140000,160000,180000], 2 => [0.1,0.15,0.215,0.28,0.333], 3 => [0.8,0.9,1,1.1,1.2],\n",
    "#                     4 => [0.8,0.9,1,1.1,1.2], 5 => [9.17,10,11,12,13.06], 6 => [12,20,30,40,50,58] ]) \n",
    "            \n",
    "#             lim_dict = Dict([\n",
    "#                     1 => ([0.75e5,1.85e5], [0.01e-5,4.15e-5]), 2 => ([0.093,0.34], [0.01,8] ), 3 => ([0.79,1.21], [0.01,6.45] ),\n",
    "#                     4 => ([0.79,1.21], [0.01,6.85] ), 5 => ([5,13.2], [0.001,1] ), 6 => ( [10.5,59.5], [0.0001,0.0465] )  ]) \n",
    "        \n",
    "#             for i in 1:2\n",
    "#                 for j in 1:3\n",
    "#                     var_idx = tuple_to_idx(i,j)\n",
    "#                     #Plot the posteriors\n",
    "#                     plot_one_var_posterior(post_dict, years, ax[i,j], var_idx , cmaplist )\n",
    "#                     #Plot the 2015 relx posteriors\n",
    "#                     plot_previous(prev, ax[i,j], var_idx)\n",
    "    \n",
    "#                     #Plot formatting\n",
    "#                     ax[i,j].set_title(title_dict[var_idx],fontsize=1.2*FONTSIZE, pad=10)    #(\"von Mises threshold (Pa)\")        \n",
    "#                     ax[i,j].ticklabel_format(style=\"sci\", scilimits=(-2,2), useMathText=true)\n",
    "#                     ax[i,j].tick_params(axis=\"both\", which=\"major\", labelsize=FONTSIZE*0.8)\n",
    "#                     ax[i,j].xaxis.offsetText.set_fontsize(FONTSIZE*0.8)\n",
    "#                     ax[i,j].yaxis.offsetText.set_fontsize(FONTSIZE*0.8)\n",
    "#                     ax[i,j].set_xticks(tick_dict[var_idx])\n",
    "#                     ax[i,j].locator_params(tight=true, nbins=6)\n",
    "#                     #ax[i,j].set_xlim(lim_dict[var_idx][1])\n",
    "#                     #ax[i,j].set_ylim(lim_dict[var_idx][2])\n",
    "#                     ax[i,j].grid(true, alpha=0.5, zorder=1)\n",
    "                \n",
    "#                 end\n",
    "#             end\n",
    "        \n",
    "#         # --- Plotting Priors --- #\n",
    "#             ax[1,1].plot(vmThresh_vals, θ_prior[:,1], lw=1.5, ls=\"dashed\", label=\"Prior\", color = \"green\")\n",
    "#             ax[1,2].plot(fricExp_vals, θ_prior[:,2], lw=1.5, ls=\"dashed\", color = \"green\")\n",
    "#             ax[1,3].plot(mu_scale_vals, θ_prior[:,3], lw=1.5, ls=\"dashed\", color = \"green\")\n",
    "#             ax[2,1].plot(stiff_scale_vals, θ_prior[:,4], lw=1.5, ls=\"dashed\", color = \"green\")\n",
    "#             ax[2,2].plot(np.log(gamma0_vals), θ_prior[:,5].*gamma0_vals, lw=1.5, linestyle=\"dashed\", color = \"green\")\n",
    "#             ax[2,3].plot(melt_flux_vals, θ_prior[:,6], lw=1.5, ls=\"dashed\", color = \"green\")\n",
    "        \n",
    "\n",
    "#             ax[1,1].axvline(x = theta[1], lw = 1.75, color = \"black\", ls = \"dashdot\", label = \"Sample from present-day posterior\")\n",
    "#             ax[1,2].axvline(x = theta[2], lw = 1.75, color = \"black\", ls = \"dashdot\")\n",
    "#             ax[1,3].axvline(x = theta[3], lw = 1.75, color = \"black\", ls = \"dashdot\")\n",
    "#             ax[2,1].axvline(x = theta[4], lw = 1.75, color = \"black\", ls = \"dashdot\")\n",
    "#             ax[2,2].axvline(x = np.log(theta[5]), lw = 1.75, color = \"black\", ls = \"dashdot\")\n",
    "#             ax[2,3].axvline(x = theta[6], lw = 1.75, color = \"black\", ls = \"dashdot\")\n",
    "\n",
    "        \n",
    "    \n",
    "#         # --- Colorbar Implementation --- #\n",
    "#             scalar_mappable = PyPlot.matplotlib.cm.ScalarMappable(norm=norm, cmap=cmap)\n",
    "#             scalar_mappable.set_array(max_years)\n",
    "#             #plt.tight_layout()\n",
    "#             cbar_ax = fig.add_axes([0.928, 0.25, 0.02, 0.5])  # Position: [left, bottom, width, height]\n",
    "#             color_bar = plt.colorbar(scalar_mappable, cax=cbar_ax, pad = 0.1)\n",
    "    \n",
    "#             color_bar.set_ticks(max_years)\n",
    "#             color_bar.ax.set_title(\"Analysis \\nyear\", fontsize=FONTSIZE*0.8, pad=20)\n",
    "#             color_bar.set_ticklabels([\"$(y)\" for y in max_years])\n",
    "#             color_bar.ax.tick_params(axis=\"both\", which=\"major\", labelsize=FONTSIZE*0.8)\n",
    "    \n",
    "#             handles, labels = ax[1,1].get_legend_handles_labels()\n",
    "#             desired_indices = [1,2,3]\n",
    "#             sorted_handles = [handles[i] for i in desired_indices]\n",
    "#             sorted_labels = [labels[i] for i in desired_indices]\n",
    "#             fig.legend(sorted_handles, sorted_labels, loc=\"lower center\", ncol=6, fontsize=FONTSIZE,\n",
    "#                        bbox_to_anchor=(0.512, 0.0), bbox_transform=PyPlot.gcf().transFigure,\n",
    "#                        frameon=\"True\", framealpha=1)  \n",
    "            \n",
    "#             pdf.savefig(fig)   \n",
    "#             PyPlot.close(fig)  \n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5c53bb1-4778-4144-8a4a-26b904e55ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using MCMCDiagnosticTools\n",
    "# #Define plot saveout location\n",
    "# figure_save_path = \"./Plots/KDE_Plots/KDE_plots_Realization_test.pdf\"\n",
    "# #Where your posteriors are located\n",
    "# posteriors_directory = \"./Data/Posterior_Data_New_All\" \n",
    "# #Where your generating parameters sets are located\n",
    "# future_obs_directory = \"./IntermediateData/emulator_pred/0.8244943887658679-data\"\n",
    "\n",
    "# max_years = collect(range(2030, step=45, length=7))\n",
    "# yr_min, yr_max = minimum(max_years), maximum(max_years)\n",
    "# norm = PyPlot.matplotlib.colors.Normalize(vmin=yr_min, vmax=yr_max)\n",
    "# cmap = PyPlot.cm.get_cmap(\"cool\")\n",
    "\n",
    "\n",
    "# pdf_pages = PdfPages(figure_save_path)\n",
    "\n",
    "# #Realization numbers\n",
    "# realizations = [58] #[i for i in 1:100];\n",
    "# r_filtered = [string(i) for i in realizations];\n",
    "\n",
    "# try\n",
    "#     for realization in r_filtered\n",
    "#         ### Enter correct posterior dict in line below\n",
    "#         chosen_dict = JLD2.load(\"$(posteriors_directory)/R_$(realization)_Posterior_Dict.jld2\", \"post_data\")\n",
    "#         θ = JLD2.load(\"$(future_obs_directory)/$(realization)_emulator_data.jld2\",\"θ\");\n",
    "#         θ_un = unscale_params(θ)\n",
    "#         @show size(chosen_dict[2090])\n",
    "#         A = chosen_dict[2090]  # size: iters × params  (check this!)\n",
    "#         pnames = [:vmThresh, :fricExp, :mu_scale, :stiff_scale, :gamma0, :melt_flux]\n",
    "        \n",
    "#         A3 = reshape(A, size(A,1), size(A,2), 1)   # (iter, param, chain)\n",
    "#         ch = Chains(A3, pnames; start=1, thin=1)   # <-- names are positional here\n",
    "        \n",
    "#         # @show MCMCDiagnosticTools.ess(ch)               # bulk ESS per param\n",
    "        \n",
    "#         plot_all_Rs_KDE_pdf(realization, chosen_dict, max_years, cmap, θ_posterior_2015, pdf_pages, θ_un)\n",
    "#         println(\"Done with realization: $(realization) \")\n",
    "#     end\n",
    "        \n",
    "\n",
    "# finally \n",
    "#     # --- Always close the PdfPages object to finalize the PDF file ---\n",
    "#     # This ensures the PDF is properly written to disk and not corrupted.\n",
    "#     pdf_pages.close()\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0564a0fd-a3ee-498e-b869-431ba0470c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "########################################\n",
    "# ESS\n",
    "########################################\n",
    "########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c6688b3-302a-4b9a-8eec-0f24a6b50ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using JLD2, MCMCChains, DataFrames, Printf\n",
    "\n",
    "# posteriors_directory = \"./Data/Posterior_Data_New_All\"\n",
    "\n",
    "# years = collect(range(2030, step=15, length=19))\n",
    "# threshold = 1000.0\n",
    "\n",
    "# for realization in realizations\n",
    "#     chosen_dict = JLD2.load(\"$(posteriors_directory)/R_$(realization)_Posterior_Dict.jld2\", \"post_data\")\n",
    "\n",
    "#     for year in years\n",
    "#         # skip if this year isn't present in the dict\n",
    "#         haskey(chosen_dict, year) || continue\n",
    "\n",
    "#         A = chosen_dict[year]  # iters × params (or params × iters)\n",
    "#         pnames = Symbol[:vmThresh, :fricExp, :mu_scale, :stiff_scale, :gamma0, :melt_flux]\n",
    "\n",
    "#         if size(A,2) != length(pnames) && size(A,1) == length(pnames)\n",
    "#             @warn \"Transposing A; it seems to be params × iters\" sizeA=size(A)\n",
    "#             A = A'\n",
    "#         end\n",
    "\n",
    "#         ch = Chains(reshape(A, size(A,1), size(A,2), 1), pnames; start=1, thin=1)\n",
    "#         df = DataFrame(MCMCChains.summarystats(ch; sections=:parameters))  # has :ess\n",
    "\n",
    "#         if any(df.ess .< threshold)\n",
    "#             println(\"Realization $(realization) — \", year, \"  (at least one ESS < $(threshold))\")\n",
    "#             # Print ESS “as is” for this realization+year\n",
    "#             for row in eachrow(df)\n",
    "#                 @printf(\"%-14s  ESS=%g\\n\", String(row.parameters), row.ess)\n",
    "#             end\n",
    "#             println()\n",
    "#         end\n",
    "#     end\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cbe3617c-1d83-4fa3-b476-c4436c1fe5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# realization = 4\n",
    "# years = collect(range(2030, step=15, length=19))\n",
    "\n",
    "# # for realization in realizations\n",
    "# for year in years\n",
    "#     chosen_dict = JLD2.load(\"$(posteriors_directory)/R_$(realization)_Posterior_Dict.jld2\", \"post_data\")\n",
    "\n",
    "#     A = chosen_dict[year]  # iters × params\n",
    "#     pnames = [:vmThresh, :fricExp, :mu_scale, :stiff_scale, :gamma0, :melt_flux]\n",
    "#     if size(A,2) != length(pnames) && size(A,1) == length(pnames)\n",
    "#         @warn \"Transposing A; it seems to be params × iters\" sizeA=size(A)\n",
    "#         A = A'\n",
    "#     end\n",
    "\n",
    "#     ch  = Chains(reshape(A, size(A,1), size(A,2), 1), pnames; start=1, thin=1)\n",
    "\n",
    "#     stats = MCMCChains.summarystats(ch; sections=:parameters)  # ChainDataFrame with mean,std,mcse,ess,rhat\n",
    "#     df    = DataFrame(stats)\n",
    "\n",
    "#     println(\"Realization $(realization) — \", year)\n",
    "#     for row in eachrow(df)\n",
    "#         @printf(\"%-14s  ESS=%g  mean=%g  sd=%g\\n\",\n",
    "#                 String(row.parameters), row.ess, row.mean, row.std)\n",
    "#     end\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "536b0d1f-a465-49a9-bf1f-02ad3fab0f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "################################################################################\n",
    "################################################################################\n",
    "\n",
    "# PARAMETRIC LEARNING PLOTS\n",
    "\n",
    "################################################################################\n",
    "################################################################################\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea4a6c09-0db1-4159-bc0d-2652895ac5a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_up_low (generic function with 1 method)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function get_up_low(post_dict, upper_quant, lower_quant)\n",
    "    p = [upper_quant,lower_quant]\n",
    "    quantiles = zeros(19, 6, 2)\n",
    "    sorted_keys = sort(collect(keys(post_dict)))\n",
    "    for i in 1:19\n",
    "        mat = post_dict[ sorted_keys[i] ]\n",
    "        quantiles[i, 1,:] = quantile( mat[:,1], p )\n",
    "        quantiles[i, 2,:] = quantile( mat[:,2], p )\n",
    "        quantiles[i, 3,:] = quantile( mat[:,3], p )\n",
    "        quantiles[i, 4,:] = quantile( mat[:,4], p )\n",
    "        quantiles[i, 5,:] = quantile( mat[:,5], p )\n",
    "        quantiles[i, 6,:] = quantile( mat[:,6], p )\n",
    "    end\n",
    "    return quantiles\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bd5e3f55-bfa7-4454-8400-76923a65e7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHANGE THIS LINE TO WHERE THE POSTERIORS ARE LOCATED\n",
    "path_to_posteriors = \"Data/Posterior_Data_New_All\"\n",
    "\n",
    "realizations = [i for i in 1:100];\n",
    "\n",
    "total_widths = zeros(length(realizations),19,6)\n",
    "sorted_keys = collect(range(2030,step=15,length=19))\n",
    "\n",
    "#Plot each parameter's learning against last year observed, for each trajectory\n",
    "for (iter, r) in enumerate(realizations)\n",
    "    post = JLD2.load(\"$(path_to_posteriors)/R_$(r)_Posterior_Dict.jld2\", \"post_data\")\n",
    "    cred_int_90_up_low = get_up_low(post, 0.95, 0.05)\n",
    "    for i in 1:2\n",
    "        for j in 1:3\n",
    "            var_idx = tuple_to_idx(i,j)\n",
    "            cred_int_90_upper = (var_idx == 5) ? log.(cred_int_90_up_low[:,var_idx,1]) : cred_int_90_up_low[:,var_idx,1]\n",
    "            cred_int_90_lower = (var_idx == 5) ? log.(cred_int_90_up_low[:,var_idx,2]) : cred_int_90_up_low[:,var_idx,2]\n",
    "            widths = cred_int_90_upper .- cred_int_90_lower\n",
    "            total_widths[iter, :, var_idx] = widths\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "un_cred_int_66_up_low = zeros(19,6,2)\n",
    "mean_width = zeros(19,6)\n",
    "for i in 1:19\n",
    "    quant = [0.83, 0.17]\n",
    "    for j in 1:6\n",
    "        un_cred_int_66_up_low[i,j,:] = quantile(total_widths[:,i,j], quant)\n",
    "        mean_width[i,j] = mean(total_widths[:,i,j])\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7eee384f-b584-4a9a-a092-32e8bf6b9320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19×6×2 Array{Float64, 3}:\n",
       "[:, :, 1] =\n",
       " 34838.9  0.17295    0.219647  0.204614  2.59605   30.5689\n",
       " 36159.1  0.171431   0.234789  0.217744  2.57528   30.625\n",
       " 35792.8  0.171121   0.239066  0.216527  2.03941   30.6383\n",
       " 36280.9  0.170384   0.244918  0.211495  1.42668   29.8154\n",
       " 36454.5  0.16965    0.241209  0.211346  1.37924   29.3861\n",
       " 36120.9  0.168318   0.232562  0.201596  1.33878   29.333\n",
       " 35602.4  0.163805   0.228151  0.200078  1.20754   28.9072\n",
       " 34298.8  0.164154   0.227405  0.19081   1.0694    27.0048\n",
       " 34767.2  0.15745    0.229452  0.191317  0.950148  26.0632\n",
       " 34791.2  0.152069   0.217923  0.176527  0.936934  23.9165\n",
       " 31823.8  0.146068   0.196372  0.161301  0.828032  23.5102\n",
       " 31047.1  0.11998    0.165602  0.148611  0.578037  22.8268\n",
       " 30288.2  0.0936757  0.136328  0.13951   0.540335  22.4723\n",
       " 29908.7  0.0529133  0.123532  0.130817  0.470111  22.5477\n",
       " 29816.4  0.0379874  0.125962  0.134712  0.429524  21.8907\n",
       " 29186.7  0.0322482  0.121593  0.125126  0.409949  21.7279\n",
       " 28825.6  0.0276577  0.117635  0.124165  0.412834  21.3517\n",
       " 28981.3  0.0266774  0.116921  0.116885  0.400666  21.2403\n",
       " 28804.4  0.0251642  0.113791  0.112703  0.385517  20.9876\n",
       "\n",
       "[:, :, 2] =\n",
       " 32809.3  0.161652   0.207964   0.18819    2.31287   30.0958\n",
       " 31178.5  0.149163   0.178162   0.161326   1.92773   29.6228\n",
       " 30763.2  0.147856   0.171134   0.155555   1.49337   28.8571\n",
       " 30394.2  0.142583   0.163739   0.14591    1.06915   26.5543\n",
       " 30221.0  0.134674   0.163973   0.141023   1.03164   24.8269\n",
       " 29714.0  0.121995   0.12621    0.131277   0.852557  23.7864\n",
       " 29418.4  0.112666   0.116314   0.122798   0.805027  23.5757\n",
       " 28928.5  0.106785   0.113684   0.11665    0.675722  22.1995\n",
       " 28930.2  0.102121   0.110402   0.10786    0.56785   21.3321\n",
       " 27747.3  0.0947096  0.106888   0.0986701  0.39839   19.8505\n",
       " 26156.1  0.0760731  0.0933562  0.0904595  0.292743  19.6118\n",
       " 25504.1  0.0569623  0.0755706  0.0862267  0.245157  18.9567\n",
       " 24650.7  0.0406389  0.0718232  0.0725756  0.215711  17.844\n",
       " 23581.4  0.0298883  0.0647307  0.0649379  0.194543  17.5716\n",
       " 23408.1  0.0235149  0.0603636  0.0664697  0.171227  17.2118\n",
       " 23039.8  0.0199167  0.0586357  0.0630219  0.157562  17.1585\n",
       " 22987.0  0.0174784  0.0573051  0.0628715  0.14806   17.0862\n",
       " 22644.5  0.0157886  0.0578825  0.0584639  0.142887  16.9832\n",
       " 22525.3  0.015039   0.0563883  0.062097   0.135915  16.8272"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "un_cred_int_66_up_low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d10ebc4c-8323-4469-b061-2687b4153f3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19×6 Matrix{Float64}:\n",
       " 33780.8  0.167235   0.21296    0.195873   2.46702   30.3705\n",
       " 33765.3  0.15895    0.208421   0.190561   2.25623   30.1791\n",
       " 33642.9  0.157167   0.206643   0.186847   1.8003    29.8141\n",
       " 33475.8  0.153437   0.203493   0.181547   1.24637   28.1198\n",
       " 33153.9  0.151732   0.198547   0.175937   1.2052    26.9038\n",
       " 32615.3  0.145927   0.181701   0.164678   1.13852   26.5008\n",
       " 32367.7  0.139435   0.175612   0.161105   1.02016   26.2051\n",
       " 31971.1  0.135851   0.172647   0.154908   0.898344  24.2433\n",
       " 31677.4  0.131824   0.169747   0.150047   0.778619  23.4985\n",
       " 30712.9  0.125209   0.160811   0.138078   0.697806  21.6572\n",
       " 29026.5  0.110262   0.14406    0.126137   0.572841  21.3725\n",
       " 28307.6  0.0908863  0.121924   0.113836   0.410084  20.8598\n",
       " 27691.4  0.0664433  0.105814   0.105182   0.368331  20.225\n",
       " 26619.7  0.0420735  0.0989751  0.0990011  0.315574  19.9732\n",
       " 26423.7  0.0323021  0.0980142  0.0985742  0.295967  19.68\n",
       " 26190.7  0.0267554  0.0945938  0.0948924  0.278976  19.407\n",
       " 25982.6  0.023722   0.0920389  0.0931356  0.266886  19.128\n",
       " 25805.7  0.0219315  0.0912153  0.0914018  0.256166  18.9689\n",
       " 25731.7  0.0211176  0.090532   0.0900101  0.250342  18.7506"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f1b8701b-fa80-44b6-9606-4affb287b3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_name = \"Plots/Parametric_Learning_Plots/parametric_learning_with_trajectories.pdf\"\n",
    "\n",
    "title_dict = Dict([\n",
    "            1 => L\"\\sigma_{max}\", 2 => L\"q\" , 3 => L\"C_{\\mu}\" ,\n",
    "            4 => L\"C_{\\phi}\", 5 => L\"\\log(\\gamma_0)\", 6 => L\"\\overline{m}\" ])\n",
    "\n",
    "tick_dict  = Dict(1=>[22000,26000,30000,34000,38000],\n",
    "                  2=>[0.02,0.06,0.10,0.14,0.18],\n",
    "                  3=>[0.05,0.10,0.15,0.20,0.25],\n",
    "                  4=>[0.06,0.10,0.14,0.18,0.22],\n",
    "                  5=>[0.0,0.5,1.0,1.5,2.0,2.5,3.0],\n",
    "                  6=>[16,20,24,28,32])\n",
    "\n",
    "ylim_dict = Dict([1 => [2.1e4,3.85e4],\n",
    "                  2 => [0.00,0.19], \n",
    "                  3 => [0.04,0.26],\n",
    "                  4 => [0.045,0.235], \n",
    "                  5 => [-0.1,2.8], \n",
    "                  6 => [14.75,32.75]])\n",
    "\n",
    "selections = [13,26,39,44,49,70,78]\n",
    "\n",
    "fig, ax = PyPlot.subplots(nrows=2, ncols=3, figsize=(18, 11), dpi=300,\n",
    "                     gridspec_kw=Dict(\"height_ratios\"=> [1, 1], \"width_ratios\" => [1, 1, 1],\n",
    "                                    \"wspace\"=> 0.175, \"hspace\"=> 0.25))\n",
    "FONTSIZE=20.5\n",
    "\n",
    "#Plot each parameter's average learning across all the trajectories\n",
    "for i in 1:2\n",
    "    for j in 1:3\n",
    "        var_idx = tuple_to_idx(i,j)\n",
    "        \n",
    "        current = total_widths[:,:,var_idx]\n",
    "        mean_widths = vec(mean(current, dims=1))\n",
    "        upper = un_cred_int_66_up_low[:,var_idx,1]\n",
    "        lower = un_cred_int_66_up_low[:,var_idx,2]\n",
    "        ax[i,j].plot(sorted_keys, mean_widths, color=\"green\",lw=2.5,label=\"Mean\", zorder = 601)\n",
    "        ax[i,j].fill_between(sorted_keys, upper, lower, color=\"palegreen\",alpha = 0.3, label=\"66% credible interval\",zorder = 600)\n",
    "\n",
    "        #UNCOMMENT LINE BELOW TO ADD TRAJECTORIES TO PLOTS\n",
    "        for iter in selections\n",
    "            ax[i,j].plot(sorted_keys, total_widths[iter, :, var_idx], marker = \"o\", markersize= 4, \n",
    "                        label = iter == selections[1] ? \"Individual scenario\" : \"_nolegend_\",ls=\"dashed\", \n",
    "                        color = \"black\", markerfacecolor=\"green\")\n",
    "        end\n",
    "        \n",
    "        ax[i,j].set_title(title_dict[var_idx],fontsize=1.2*FONTSIZE, pad=10)\n",
    "        ax[i,j].ticklabel_format(style=\"sci\", scilimits=(-2,4), useMathText=true)\n",
    "        ax[i,j].tick_params(axis=\"both\", which=\"major\", labelsize=FONTSIZE*0.8)\n",
    "        ax[i,j].xaxis.offsetText.set_fontsize(FONTSIZE*0.8)\n",
    "        ax[i,j].yaxis.offsetText.set_fontsize(FONTSIZE*0.8)\n",
    "        ax[i,j].set_yticks(tick_dict[var_idx])\n",
    "        # ax[i,j].set_ylim(ylim_dict[var_idx])\n",
    "        ax[i,j].set_xlim([2030,2300])\n",
    "        # ax[i,j].locator_params(tight=true, nbins=6)\n",
    "        ax[i,j].grid(true, alpha=0.5, zorder=1)\n",
    "\n",
    "    end\n",
    "end\n",
    "\n",
    "handles, labels = ax[1,1].get_legend_handles_labels()\n",
    "n = length(handles)\n",
    "desired_indices = filter(i -> 1 ≤ i ≤ n, [1,2,3]) \n",
    "sorted_handles = [handles[i] for i in desired_indices]\n",
    "sorted_labels = [labels[i] for i in desired_indices]\n",
    "fig.legend(sorted_handles, sorted_labels, loc=\"lower center\", ncol=3, fontsize=0.8*FONTSIZE,\n",
    "           bbox_to_anchor=(0.512, 0.92), bbox_transform=PyPlot.gcf().transFigure,\n",
    "           frameon=\"True\", framealpha=1)\n",
    "\n",
    "fig.supxlabel(\"Analysis year\", fontsize=FONTSIZE*1.2, y=0.036)\n",
    "fig.supylabel(\"90% credible interval width\", fontsize=FONTSIZE*1.2, x=0.066)\n",
    "\n",
    "plt.savefig(output_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ec6326b-2ab2-4284-aff0-3c7700fa2c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "################################################################################\n",
    "################################################################################\n",
    "\n",
    "# SLR PCA PROJECTION\n",
    "\n",
    "################################################################################\n",
    "################################################################################\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18c6f00f-1b77-4c9d-9bde-29fa831f57c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gps, PC_min, PC_max, p, num_pcs = JLD2.load(\"VAF_PCA_GP_Emulators.jld2\", \n",
    "#     \"gps\", \"PC_min\", \"PC_max\", \"p\", \"num_pcs\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b11e8bd4-375c-4910-8407-f12860f8e7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# project(pca, Y, J=size(Y,1)) = (projection(pca)[:,1:J])' * centralize(Y, pca.mean)\n",
    "# reconstruct(pca, W, J=size(W,1)) = decentralize(projection(pca)[:,1:J] * W, mean(pca))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f546c4bd-a722-4070-9e93-28a6d6949f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = CSV.read(\"Data/Training_Data/Amery_VAF_time_series_2300_ssp_5_8.5.csv\", DataFrame)\n",
    "y = select(y, Not(1))\n",
    "y = Matrix(y)\n",
    "y = collect(y');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d6313bb-011c-4638-a90e-331fdf827cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = CSV.read(\"Data/Training_Data/Amery_GP_Emulator_RELX_Ensemble_Filtered.csv\", DataFrame);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d112cf52-5b94-456f-b06a-9772d9593d55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6×119 adjoint(::Matrix{Float64}) with eltype Float64:\n",
       " 0.407891   0.584329  0.879853  0.35452   …  0.89069    0.435987   0.727361\n",
       " 0.0356264  0.509296  0.437061  0.789839     0.0620034  0.412618   0.840317\n",
       " 0.354441   0.449709  0.200242  0.311622     0.394692   0.0504651  0.712968\n",
       " 0.485306   0.770992  0.664396  0.733916     0.555406   0.342915   0.709687\n",
       " 0.607262   0.45634   0.784528  0.921009     0.959423   0.688045   0.451809\n",
       " 0.91086    0.239113  0.835963  0.482451  …  0.11399    0.180736   0.683243"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vmThresh_min, vmThresh_max = minimum(x.vmThresh), maximum(x.vmThresh)\n",
    "scaler_vmThresh = fit(UnitRangeTransform, x.vmThresh)\n",
    "d_01 = StatsBase.transform(scaler_vmThresh, x.vmThresh)\n",
    "\n",
    "fricExp_min, fricExp_max = minimum(x.fricExp), maximum(x.fricExp)\n",
    "scaler_fricExp = fit(UnitRangeTransform, x.fricExp)\n",
    "d_02 = StatsBase.transform(scaler_fricExp, x.fricExp)\n",
    "\n",
    "mu_scale_min, mu_scale_max = minimum(x.mu_scale), maximum(x.mu_scale)\n",
    "scaler_mu_scale = fit(UnitRangeTransform, x.mu_scale)\n",
    "d_03 = StatsBase.transform(scaler_mu_scale, x.mu_scale)\n",
    "\n",
    "stiff_scale_min, stiff_scale_max = minimum(x.stiff_scale), maximum(x.stiff_scale)\n",
    "scaler_stiff_scale = fit(UnitRangeTransform, x.stiff_scale)\n",
    "d_04 = StatsBase.transform(scaler_stiff_scale, x.stiff_scale)\n",
    "\n",
    "gamma0_min, gamma0_max = minimum(x.gamma0), maximum(x.gamma0)\n",
    "scaler_gamma0 = fit(UnitRangeTransform, x.gamma0)\n",
    "d_05 = StatsBase.transform(scaler_gamma0, x.gamma0)\n",
    "\n",
    "melt_flux_min, melt_flux_max = minimum(x.melt_flux), maximum(x.melt_flux)\n",
    "scaler_melt_flux = fit(UnitRangeTransform, x.melt_flux)\n",
    "d_06 = StatsBase.transform(scaler_melt_flux, x.melt_flux)\n",
    "\n",
    "param_mins = [vmThresh_min,fricExp_min,mu_scale_min,stiff_scale_min,gamma0_min,melt_flux_min]\n",
    "param_maxs = [vmThresh_max,fricExp_max,mu_scale_max,stiff_scale_max,gamma0_max,melt_flux_max]\n",
    "\n",
    "design_scaled = DataFrame(vmThresh_scaled=d_01, fricExp_scaled=d_02, mu_scale_scaled=d_03,\n",
    "                          stiff_scale_scaled=d_04, gamma0_scaled=d_05, melt_flux_scaled=d_06)\n",
    "\n",
    "X = Matrix(design_scaled)' # matrix 6 x N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d97f2544-1c70-4ff9-8b4d-4a3ca47d5e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "present2015_post_mm_ssp5 = JLD2.load(\"2015_SLR_Projections.jld2\", \"present2015_post_mm_ssp5\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dc33147f-be7b-47e3-afe3-9d26191878d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function that projects sea level contribution for the sequence of calibrated posteriors 2030-2300 for a given realization(trajectory)\n",
    "# function sequential_prediction_func(\n",
    "#         posterior_dict::Dict{Int64, Matrix{Float64}},\n",
    "#         realization::String,\n",
    "#         num_pcs,\n",
    "#         min_PC,\n",
    "#         max_PC,\n",
    "#         X_mins,\n",
    "#         X_maxs,\n",
    "#         fit,\n",
    "#         vfa,\n",
    "#         emulators\n",
    "\n",
    "#     )\n",
    "        \n",
    "#         sample_size = 5000\n",
    "#         projection_dict = Dict{Int64, Matrix{Float64}}()\n",
    "#         #Project forward for each posterior in dictionary\n",
    "        \n",
    "#         for key in keys(posterior_dict)\n",
    "#             #println(key)\n",
    "#             post_full = DataFrame(vmThresh_post=posterior_dict[key][:,1], fricExp_post=posterior_dict[key][:,2], \n",
    "#             mu_scale_post=posterior_dict[key][:,3], stiff_scale_post=posterior_dict[key][:,4], \n",
    "#             gamma0_post=posterior_dict[key][:,5], melt_flux_post=posterior_dict[key][:,6])\n",
    "\n",
    "#             Random.seed!(11)\n",
    "#             # Get the total number of rows in the DataFrame\n",
    "#             total_rows = nrow(post_full)\n",
    "#             # Generate random indices to select rows\n",
    "#             random_indices = randperm(total_rows)[1:sample_size]\n",
    "#             # Select the subset of rows using the random indices\n",
    "#             post = post_full[random_indices, :]\n",
    "\n",
    "#             #Initialize empty arrays for saving\n",
    "#             mu_post = [Vector{Float64}() for _ in 1:num_pcs]\n",
    "#             sig_post = [Vector{Float64}() for _ in 1:num_pcs]\n",
    "            \n",
    "#             #Predict with each PC emulator for samples of the posterior\n",
    "#             for x in eachrow(post)\n",
    "#                 #scale parameters\n",
    "#                 p1_t = (x.vmThresh_post- X_mins[1])/(X_maxs[1]-X_mins[1])\n",
    "#                 p2_t = (x.fricExp_post- X_mins[2])/(X_maxs[2]-X_mins[2])\n",
    "#                 p3_t = (x.mu_scale_post- X_mins[3])/(X_maxs[3]-X_mins[3])\n",
    "#                 p4_t = (x.stiff_scale_post - X_mins[4])/(X_maxs[4]-X_mins[4])\n",
    "#                 p5_t = (x.gamma0_post- X_mins[5])/(X_maxs[5]-X_mins[5])\n",
    "#                 p6_t = (x.melt_flux_post- X_mins[6])/(X_maxs[6]-X_mins[6])\n",
    "                \n",
    "#                 α = [p1_t;; p2_t;; p3_t;; p4_t;; p5_t;; p6_t]'\n",
    "                \n",
    "#                 #Predict on each PC\n",
    "#                 for i in 1:num_pcs\n",
    "#                     μ, σ = predict_gp_eml(emulators[i], α)\n",
    "#                     mu =  only(μ)*(max_PC[i] - min_PC[i]) + min_PC[i]\n",
    "#                     sig = only(σ)*(max_PC[i] - min_PC[i])\n",
    "#                     append!(mu_post[i], mu)\n",
    "#                     append!(sig_post[i], sig)\n",
    "#                 end\n",
    "#             end\n",
    "\n",
    "#             #Save the Principal components predictions \n",
    "#             PC_mean_pred_post = hcat(mu_post...)\n",
    "#             PC_sig_pred_post = hcat(sig_post...)\n",
    "\n",
    "#             # mkpath(\"../../SLR_Projection_Data/pred_mean_PC/R_$(realization)\")\n",
    "#             # mkpath(\"../../SLR_Projection_Data/pred_std_PC/R_$(realization)\")\n",
    "#             # @save \"../../SLR_Projection_Data/pred_mean_PC/R_$(realization)/$(realization)-year$(key)mean_PCs.jld2\" PC_mean_pred_post\n",
    "#             # @save \"../../SLR_Projection_Data/pred_std_PC/R_$(realization)/$(realization)-year$(key)std_PCs.jld2\" PC_sig_pred_post\n",
    "\n",
    "#             sample_post = Matrix{Float64}(undef, 0, size(vfa, 1))\n",
    "\n",
    "#             #Reconstruct the PC predictions to get VAF outputs\n",
    "#             for (mu_sample, sigma_sample) in zip(eachrow(PC_mean_pred_post), eachrow(PC_sig_pred_post))\n",
    "#                 # Appendix B.2 steps combined to generate multivariate normal back tranformed sample\n",
    "#                 sample = reconstruct(fit, rand.(Normal.(mu_sample,sigma_sample)), num_pcs)\n",
    "#                 sample_post = [sample_post; sample']\n",
    "#             end\n",
    "#             sample_post = sample_post'\n",
    "#             sample_post_mm_ssp5 = sample_post./(-362)\n",
    "#             projection_dict[key] = sample_post_mm_ssp5\n",
    "#             mkpath(\"Data/Projection_Data/R_$(realization)\")\n",
    "#             @save \"Data/Projection_Data/R_$(realization)/$(realization)-year$(key)pred_VAF.jld2\" sample_post_mm_ssp5\n",
    "         \n",
    "\n",
    "#         end\n",
    "    \n",
    "#         return nothing\n",
    "#     end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8c75ca19-1bc6-44c6-813a-2def0292ab2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Use this cell to project foward for a set of trajectories of posteriors\n",
    "\n",
    "# #Realization numbers\n",
    "# Realizations = [i for i in 1:100];\n",
    "# r_string = [string(i) for i in Realizations]\n",
    "\n",
    "# yrs_all = collect(range(2030, step=15, length=19));\n",
    "\n",
    "# for r in r_string\n",
    "#     θ_posterior_fut = JLD2.load(\"Data/Posterior_Data_New_All/R_$(r)_Posterior_Dict.jld2\", \"post_data\");\n",
    "#     sequential_prediction_func(\n",
    "#         θ_posterior_fut,\n",
    "#         r,\n",
    "#         5,\n",
    "#         PC_min,\n",
    "#         PC_max,\n",
    "#         param_mins,\n",
    "#         param_maxs,\n",
    "#         p,\n",
    "#         y,\n",
    "#         gps)\n",
    "#     println(\"Done with realization $(r)...\")\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "96d391ce-dcac-4d64-8266-6277fa649f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "################################################################################\n",
    "################################################################################\n",
    "\n",
    "# SLR LEARNING PLOTS\n",
    "\n",
    "################################################################################\n",
    "################################################################################\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ccc4a2f5-9bea-4b21-9945-081d6677a8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE=21\n",
    "FONTSIZE=21\n",
    "DOTCOLOR=\"green\"\n",
    "EDGECOLOR=\"gray\"\n",
    "plt.style.use([\"default\",\"science\",\"no-latex\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1f03041b-660d-4ce8-b94e-fb7bd5174865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "calculate_quantiles_mean (generic function with 1 method)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Returns means, upper, and lower quntailes for a single year's prediction from a single (R, yr_calibrated) pair\n",
    "function calculate_quantiles_mean(sample, row)\n",
    "    slice = sample[row, :]\n",
    "    mean_data = mean(slice)\n",
    "    quantile_5 = quantile(slice, 0.05)\n",
    "    quantile_95 = quantile(slice, 0.95)\n",
    "    \n",
    "    return mean_data, quantile_5, quantile_95\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "972c1592-5a2a-408d-9ac9-1e1193e7cf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_years_no_gap = collect(range(2016, step=1, length=285))\n",
    "yrs_gapped = collect(range(2030, step=15, length=19));\n",
    "\n",
    "yrs_dict = Dict{Int64, Int64}()\n",
    "for (idx,yr) in enumerate(all_years_no_gap)\n",
    "        yrs_dict[yr] = idx\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "75201cbb-f6c5-49bf-8867-273a99a179ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function plot_trajectorys(iter, selections, axis, x_values, y_values, present_value, face_color)\n",
    "#     all_y = vcat([present_value], y_values)\n",
    "#     axis.plot(x_values, all_y, marker = \"o\", markersize= 6.6, color=\"black\", ls=\"dashed\",\n",
    "#         markerfacecolor=face_color, label = iter == selections[1] ? \"Individual scenario\" : \"_nolegend_\")\n",
    " \n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a38905b9-a70b-4801-ad31-4b5e0f9582dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### FIGURE 4 Plotting Script\n",
    "# #Change this path to \"Data/Projection_Data\" once you have run the previous PCA Projection setting on your posteriors\n",
    "# path_to_projections = \"Data/Projection_Data\"\n",
    "\n",
    "# #Realization numbers\n",
    "# realizations = [string(i) for i in 1:100];\n",
    "\n",
    "# color_dict = Dict(\n",
    "#                 2100 => \"darkblue\", 2200=> \"chocolate\", 2300=>\"purple\"\n",
    "# )\n",
    "\n",
    "# fill_color_dict = Dict(\n",
    "#                 2100 => \"dodgerblue\", 2200=> \"orange\", 2300=>\"plum\"\n",
    "# )\n",
    "\n",
    "# xticks_dict = Dict(2100 => [2015,2030,2045,2060,2075,2090], \n",
    "#                    2200 => [2015,2045,2075,2105,2135,2165,2195], \n",
    "#                    2300 => [2015,2050,2100,2150,2200,2250,2300])\n",
    "\n",
    "# yticks_dict = Dict(2100 => [3,3.5,4,4.5,5,5.5,6],\n",
    "#                    2200 => [10,20,30,40,50,60,70],\n",
    "#                    2300 => [10,20,30,40,50,60,70,80])\n",
    "\n",
    "# ylim_dict = Dict(2100 => [2.64,6.32],\n",
    "#                  2200 => [6,76],\n",
    "#                  2300 => [6,88])\n",
    "\n",
    "# selections = [13,27,40,45,58,70,78]\n",
    "\n",
    "\n",
    "\n",
    "# # fig, ax = subplots(nrows=1, ncols=1, figsize=(10.5, 8))\n",
    "# fig, axes = subplots(nrows=1, ncols=3, figsize=(32, 6))\n",
    "# fig.subplots_adjust(wspace=0.14, hspace=0.0) \n",
    "\n",
    "# FONTSIZE=26\n",
    "# # output_file_name = \"Plots/SLR_Learning_Plots/With_Trajectories/yr_$(chosen_year)_slr_learning.pdf\"\n",
    "# output_file_name = \"Plots/SLR_Learning_Plots/slr_learning_with_trajectories.pdf\"\n",
    "\n",
    "# letters = [\"a\", \"b\", \"c\"]\n",
    "# for (a,chosen_year) in enumerate([2100, 2200, 2300])\n",
    "#     ax = axes[a]\n",
    "\n",
    "#     #Corresponding row in the matrix of projections\n",
    "#     row_idx = yrs_dict[chosen_year]\n",
    "#     n_cal_years = fld(chosen_year-2015,15) + 1\n",
    "#     full_yr_range = collect(range(2015, step=15, length= n_cal_years ))\n",
    "    \n",
    "#     #Get 2015 projections upper and lower quantile bounds\n",
    "#     present2015_post_mm_ssp5 = JLD2.load(\"2015_SLR_Projections.jld2\", \"present2015_post_mm_ssp5\")\n",
    "#     present_mu, present_lower, present_upper, = calculate_quantiles_mean(present2015_post_mm_ssp5, row_idx)\n",
    "#     present_width = present_upper - present_lower\n",
    "    \n",
    "#     #Vector to hold the widths of each trajectory, for averaging purposes later\n",
    "#     total_widths = zeros(100,length(full_yr_range))\n",
    "#     for (iter,realization) in enumerate(realizations)\n",
    "#         one_trajectorys_widths = Vector{Float64}()\n",
    "#         #loop through the years at which calibrations occur\n",
    "#         for yr in full_yr_range[2:end]\n",
    "#             #load projections matrix \n",
    "#             vaf_sample = JLD2.load(\"$(path_to_projections)/R_$(realization)/$(realization)-year$(yr)pred_VAF.jld2\",\n",
    "#                 \"sample_post_mm_ssp5\")\n",
    "#             mu, lower, upper, = calculate_quantiles_mean(vaf_sample, row_idx)\n",
    "#             push!(one_trajectorys_widths, upper - lower)\n",
    "#         end\n",
    "#         #UNCOMMENT LINE BELOW TO ADD TRJAECTORIES TO PLOT\n",
    "#         if iter in selections\n",
    "#             plot_trajectorys(iter, selections, ax, full_yr_range, one_trajectorys_widths, present_width, color_dict[chosen_year])\n",
    "#         end\n",
    "#         total_widths[iter,:] = vcat(present_width, one_trajectorys_widths)\n",
    "#     end\n",
    "\n",
    "#     #Calculate averages and standard deviations across trajectories\n",
    "#     mean_widths = vec(mean(total_widths, dims=1))\n",
    "#     upper = vec(mapslices(x -> quantile(x, 0.83), total_widths; dims=1))\n",
    "#     lower = vec(mapslices(x -> quantile(x, 0.17), total_widths; dims=1))\n",
    "#     # std_widths = vec(std(total_widths, dims=1))\n",
    "#     # upper = mean_widths .+ std_widths\n",
    "#     # lower = mean_widths .- std_widths\n",
    "#     ax.plot(full_yr_range, mean_widths, color=color_dict[chosen_year],lw=2.5,label=\"Mean\", zorder = 500)\n",
    "#     ax.fill_between(full_yr_range, upper,lower, color=fill_color_dict[chosen_year],alpha = 0.3, label=\"66% credible interval\", zorder = 499)\n",
    "    \n",
    "#     ax.set_xlabel(\"Analysis year\", fontsize= FONTSIZE*0.8, labelpad=10)\n",
    "#     if a == 1\n",
    "#         ax.set_ylabel(\"90% credible interval width (mm)\", fontsize= FONTSIZE*0.8, labelpad=12)\n",
    "#     end\n",
    "#     ax.tick_params(axis=\"both\", which=\"major\", labelsize=FONTSIZE*0.68)\n",
    "#     ax.set_xlim(2015,full_yr_range[n_cal_years])\n",
    "#     ax.set_ylim(ylim_dict[chosen_year])\n",
    "#     ax.set_xticks(xticks_dict[chosen_year])\n",
    "#     ax.set_yticks(yticks_dict[chosen_year])\n",
    "#     ax.grid(true, alpha=0.5, zorder=1)\n",
    "    \n",
    "#     handles, labels = ax.get_legend_handles_labels()\n",
    "#     n = length(handles)\n",
    "#     desired_indices = filter(i -> 1 ≤ i ≤ n, [1,2,3]) \n",
    "#     sorted_handles = [handles[i] for i in desired_indices]\n",
    "#     sorted_labels = [labels[i] for i in desired_indices]\n",
    "#     if a == 1\n",
    "#         ax.text(-0.13, 1.08, \"(\" * letters[a] * \")\", ha=\"left\", va=\"top\", transform=ax.transAxes, fontsize=FONTSIZE)\n",
    "#     else\n",
    "#         ax.text(-0.1, 1.08, \"(\" * letters[a] * \")\", ha=\"left\", va=\"top\", transform=ax.transAxes, fontsize=FONTSIZE)\n",
    "#     end\n",
    "#     ax.legend(sorted_handles, sorted_labels, loc=\"lower center\", ncol=1, fontsize=FONTSIZE*0.72,\n",
    "#         bbox_to_anchor=(0.772, 0.71), frameon=\"True\", framealpha=1)\n",
    "#        # bbox_to_anchor=(0.768, 0.76), frameon=\"True\", framealpha=1)\n",
    "# end\n",
    "\n",
    "# mkpath(dirname(output_file_name))\n",
    "# fig.savefig(output_file_name; bbox_inches=\"tight\", dpi=300) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f656f272-ef30-4aef-910f-14e6a13c0c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "################################################################################\n",
    "################################################################################\n",
    "\n",
    "# SLR SENSITIVITY PLOTS\n",
    "\n",
    "################################################################################\n",
    "################################################################################\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cd4c4ac7-679f-4048-a72a-e8c8eddef515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- inputs you already have ---\n",
    "path_to_posteriors = \"Data/Posterior_Data_New_All\"\n",
    "future_obs_directory = \"./IntermediateData/emulator_pred/0.8244943887658679-data\"\n",
    "output_file_name   = \"Plots/Sensitivity_Plots/SLR_sensitivity_wrt_parameters.pdf\"\n",
    "path_to_projections = \"Data/Projection_Data\"\n",
    "\n",
    "chosen_year =  2300\n",
    "row_idx = yrs_dict[chosen_year]\n",
    "\n",
    "# Realization numbers\n",
    "realizations = [string(i) for i in 1:100];\n",
    "\n",
    "# --- collect widths for all realizations ---\n",
    "widths = Array{Float64}(undef, length(realizations))\n",
    "θ_mat  = Array{Float64}(undef, length(realizations), 6)\n",
    "\n",
    "for (i, r) in enumerate(realizations)\n",
    "    vaf_sample = JLD2.load(joinpath(path_to_projections, \"R_$(r)\", \"$(r)-year$(chosen_year)pred_VAF.jld2\"),\n",
    "                           \"sample_post_mm_ssp5\")\n",
    "    # no trailing comma\n",
    "    μ, lower, upper = calculate_quantiles_mean(vaf_sample, row_idx)\n",
    "\n",
    "    widths_all_years = upper .- lower          # elementwise\n",
    "    widths[i] = widths_all_years[end]          # last year’s width (or use row_idx if that’s per-year already)\n",
    "\n",
    "    θ = JLD2.load(joinpath(future_obs_directory, \"$(r)_emulator_data.jld2\"), \"θ\")\n",
    "    θ_mat[i, :] = unscale_params(θ)            # ensure this returns a 6-vector\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "657cd703-4957-4317-aaba-5e5fa6afa8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- plotting: 2×3 grid, one subplot per parameter ---\n",
    "# fig, ax = PyPlot.subplots(nrows=2, ncols=3, figsize=(18, 11), dpi=300,\n",
    "#     gridspec_kw=Dict(\"height_ratios\"=>[1,1], \"width_ratios\"=>[1,1,1], \"wspace\"=>0.175, \"hspace\"=>0.25))\n",
    "\n",
    "# FONTSIZE=20.5\n",
    "# # fig.suptitle(\"Sea-level Contributions 90% Credible Interval Widths at $(chosen_year)\"; fontsize=30, fontweight=\"bold\", y=0.98)\n",
    "\n",
    "# title_dict = Dict(1=>L\"\\sigma_{max}\", 2=>L\"q\", 3=>L\"C_{\\mu}\", 4=>L\"C_{\\phi}\", 5=>L\"\\log(\\gamma_0)\", 6=>L\"\\overline{m}\")\n",
    "# tick_dict  = Dict(1=>[1.1e5,1.2e5,1.3e5,1.4e5],\n",
    "#                   2=>[0.15,0.2,0.25,0.3],\n",
    "#                   3=>[0.8,0.9,1,1.1],\n",
    "#                   4=>[0.82,0.88,0.94,1,1.06],\n",
    "#                   5=>[9.17,10,11,12],\n",
    "#                   6=>[12,20,30,40,50,58])\n",
    "\n",
    "# xlim_dict = Dict([1 => [1.02e5,1.485e5], \n",
    "#                   2 => [0.108,0.333], \n",
    "#                   3 => [0.78,1.148],\n",
    "#                   4 => [0.81,1.095], \n",
    "#                   5 => [9.05,12.6], \n",
    "#                   6 => [10,60]])\n",
    "\n",
    "# for j in 1:6\n",
    "#     rI = (j-1) ÷ 3 + 1\n",
    "#     cI = (j-1) % 3 + 1\n",
    "#     axi = ax[rI, cI]\n",
    "\n",
    "#     if j == 5\n",
    "#         var = np.log(θ_mat[:, j])\n",
    "#     else\n",
    "#         var = θ_mat[:, j]\n",
    "#     end\n",
    "\n",
    "#     seaborn.regplot(x=var, y=widths, lowess=true,\n",
    "#               scatter_kws=Dict(\"alpha\"=>0.85, \"s\"=> SIZE*2, \"color\"=>DOTCOLOR, \n",
    "#                                 \"edgecolor\"=>EDGECOLOR, \"linewidths\"=>0.5, \n",
    "#                                 \"plotnonfinite\"=>false, \"zorder\"=>2), \n",
    "#               line_kws=Dict(\"color\" => \"red\", \"lw\" => 1, \"alpha\" => 0.8), ax=axi)\n",
    "\n",
    "    \n",
    "#     axi.set_title(string(title_dict[j]), fontsize=1.2*FONTSIZE, pad=10)\n",
    "#     axi.ticklabel_format(style=\"sci\", scilimits=(-2,2), useMathText=true)\n",
    "#     axi.tick_params(axis=\"both\", which=\"major\", labelsize=FONTSIZE*0.8)\n",
    "#     axi.xaxis.offsetText.set_fontsize(FONTSIZE*0.8)\n",
    "#     axi.yaxis.offsetText.set_fontsize(FONTSIZE*0.8)\n",
    "#     axi.set_xticks(tick_dict[j])\n",
    "#     axi.set_xlim(xlim_dict[j])\n",
    "#     axi.set_ylim([8.51,22])\n",
    "#     axi.set_yticks([10,15,20])\n",
    "#     axi.locator_params(tight=true, nbins=6)\n",
    "#     axi.grid(true, alpha=0.5, zorder=1)\n",
    "# end\n",
    "\n",
    "# mkpath(dirname(output_file_name))\n",
    "# fig.savefig(output_file_name; bbox_inches=\"tight\", dpi=300)   # should now complete quickly\n",
    "# PyPlot.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "372537ff-b668-43ea-8717-b9d563c128ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assumptions you already have:\n",
    "# # - θ_mat :: Matrix{Float64}  (n_realizations × 6)   # parameters per realization\n",
    "# # - widths :: Vector{Float64}  (n_realizations)      # 90% CI width at chosen_year\n",
    "# # - FONTSIZE, SIZE, EDGECOLOR defined\n",
    "# # - title_dict, tick_dict like in your snippet (LaTeXStrings are fine)\n",
    "# cmap = mpl.cm.get_cmap(\"viridis\")\n",
    "\n",
    "# output_file_name   = \"Plots/Sensitivity_Plots/SLR_sensitivity_wrt_pairwise_parameters.pdf\"\n",
    "\n",
    "# # Choose a sequential cmap and robust color limits for widths (since widths ≥ 0)\n",
    "\n",
    "# vmin, vmax = quantile(widths, [0.05, 0.95])   # robust limits; change to [minimum(widths), maximum(widths)] if you prefer\n",
    "# norm_ = mpl.colors.Normalize(vmin=vmin, vmax=vmax)\n",
    "\n",
    "# # Build all 15 unique pairs (1..6 choose 2), row-major ordering\n",
    "# pairs = [(a,b) for a in 1:6 for b in a+1:6]  # length = 15\n",
    "\n",
    "# # Figure: 5 rows × 3 cols\n",
    "# fig, ax = PyPlot.subplots(nrows=5, ncols=3, figsize=(22, 29), width_ratios=[1,1,1], height_ratios=[1,1,1,1,1])\n",
    "# # fig.suptitle(\"Sea-level Contributions 90% Credible Interval Widths at $(chosen_year)\"; fontsize=30, fontweight=\"bold\", y=1.008)\n",
    "\n",
    "# # If ax is a Matrix{PyObject}, indexing is ax[row, col]\n",
    "# for (idx, (xk, yk)) in enumerate(pairs)\n",
    "#     rI = 1 + (idx-1) ÷ 3\n",
    "#     cI = 1 + (idx-1) % 3\n",
    "#     axi = ax[rI, cI]\n",
    "\n",
    "#     # Scatter: x = param xk, y = param yk, color = widths\n",
    "#     x_var = (xk == 5) ? log.(θ_mat[:, xk]) : θ_mat[:, xk]\n",
    "#     y_var = (yk == 5) ? log.(θ_mat[:, yk]) : θ_mat[:, yk]\n",
    "\n",
    "#     axi.set_rasterization_zorder(0)\n",
    "#     sc = axi.scatter(x_var, y_var;\n",
    "#                      s=SIZE*5, c=widths, cmap=cmap, \n",
    "#                      edgecolor=EDGECOLOR, linewidth=0.5,\n",
    "#                      rasterized=true)\n",
    "\n",
    "#     # Labels/ticks/limits\n",
    "#     axi.set_xlabel(string(title_dict[xk]), fontsize=FONTSIZE, labelpad=10)\n",
    "#     axi.set_ylabel(string(title_dict[yk]), fontsize=FONTSIZE, labelpad=10)\n",
    "#     axi.ticklabel_format(style=\"sci\", scilimits=(-3,3), useMathText=true)\n",
    "#     axi.tick_params(axis=\"both\", which=\"major\", labelsize=FONTSIZE*0.8)\n",
    "#     axi.xaxis.offsetText.set_fontsize(FONTSIZE*0.8)\n",
    "#     axi.yaxis.offsetText.set_fontsize(FONTSIZE*0.8)\n",
    "#     axi.locator_params(tight=true, nbins=6)\n",
    "#     axi.grid(true, alpha=0.5, zorder=1)\n",
    "#     axi.set_xticks(tick_dict[xk])\n",
    "#     axi.set_yticks(tick_dict[yk])\n",
    "#     axi.set_xlim(xlim_dict[xk])\n",
    "#     axi.set_ylim(xlim_dict[yk])\n",
    "# end\n",
    "\n",
    "# # Single shared colorbar on the right\n",
    "# plt.tight_layout(rect=[0.0, 0.0, 0.95, 1.0])  # leave room for colorbar\n",
    "# cax = fig.add_axes([0.98, 0.25, 0.02, 0.5])  # [left, bottom, width, height]\n",
    "# sm = mpl.cm.ScalarMappable(norm=norm_, cmap=cmap); sm.set_array([])\n",
    "# cbar = fig.colorbar(sm, cax=cax)\n",
    "# cbar.ax.set_title(\"90% \\ncredible \\ninterval \\nwidth\", fontsize=FONTSIZE, pad=30)\n",
    "# cbar.ax.tick_params(axis=\"both\", which=\"major\", labelsize=FONTSIZE*0.8)\n",
    "# cbar.mappable.set_clim(8.5, 22)\n",
    "\n",
    "# mkpath(dirname(output_file_name))\n",
    "# fig.savefig(output_file_name; bbox_inches=\"tight\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "874bf7d9-7b64-44eb-8bfe-d3b1b2d900c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "################################################################################\n",
    "################################################################################\n",
    "\n",
    "# NATHAN PAPER PLOTS\n",
    "\n",
    "################################################################################\n",
    "################################################################################\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "adede873-8318-43a8-99af-aaff2a294542",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_post_mm_ssp5_2015 = np.load(\"Amery_PCA_GP_Emulator_posterior_pushed-SSP-5-8.5.npy\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "968b30b0-d19e-41f2-a1a1-ffd902dcf6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function plot_param_means_of_trajectory(real, posterior_dict, axis, title_dict, tick_dict, ylim_dict, color, fill_color, FONTSIZE_PARAM)\n",
    "\n",
    "#     # Years at which recalibration occurred\n",
    "#     cal_years = collect(range(2015, step=15, length=19))\n",
    "#     means = Dict(j => Vector{Float64}() for j in 1:6)\n",
    "#     uppers = Dict(j => Vector{Float64}() for j in 1:6)\n",
    "#     lowers = Dict(j => Vector{Float64}() for j in 1:6)\n",
    "\n",
    "#     for j in 1:6\n",
    "#         current_post = θ_posterior_2015\n",
    "#         var = (j == 5) ? log.(current_post[:, j]) : current_post[:, j]\n",
    "#         push!(means[j], mean(var))\n",
    "#         push!(uppers[j], quantile(var, 0.95))\n",
    "#         push!(lowers[j], quantile(var, 0.05))\n",
    "#     end\n",
    "\n",
    "#     for yr in cal_years[2:end]\n",
    "#         current_post = posterior_dict[yr]\n",
    "#         for j in 1:6\n",
    "#             var = (j == 5) ? log.(current_post[:, j]) : current_post[:, j]\n",
    "#             push!(means[j], mean(var))\n",
    "#             push!(uppers[j], quantile(var, 0.95))\n",
    "#             push!(lowers[j], quantile(var, 0.05))\n",
    "#         end\n",
    "#     end\n",
    "\n",
    "#     for j in 1:6\n",
    "#         rI = (j-1) ÷ 2 + 1\n",
    "#         cI = (j-1) % 2 + 1\n",
    "#         ax = axis[rI, cI]\n",
    "#         # ax = axis[j]\n",
    "#         ax.spines[\"top\"].set_visible(false)\n",
    "#         ax.spines[\"right\"].set_visible(false)\n",
    "#         ax.tick_params(which=\"both\", top=false, right=false, labeltop=false, labelright=false)\n",
    "#         ax.plot(cal_years,means[j],label=\"Parameter posterior distribution mean\",zorder=20, color=color, lw=3)\n",
    "#         ax.fill_between(cal_years, uppers[j],lowers[j],alpha = 0.5,label=\"90% credible interval\", color=fill_color)\n",
    "#         ax.ticklabel_format(style=\"sci\", scilimits=(-2,4), useMathText=true)\n",
    "#         ax.tick_params(axis=\"both\", which=\"major\", labelsize=FONTSIZE_PARAM*0.8)\n",
    "#         ax.xaxis.offsetText.set_fontsize(FONTSIZE_PARAM*0.8)\n",
    "#         ax.yaxis.offsetText.set_fontsize(FONTSIZE_PARAM*0.8)\n",
    "#         if rI == 3\n",
    "#             ax.set_xlabel(\"Analysis year\", fontsize=FONTSIZE_PARAM, labelpad=10)\n",
    "#         end\n",
    "#         ax.set_ylabel(title_dict[j], fontsize=FONTSIZE_PARAM, labelpad=10)\n",
    "#         ax.set_yticks(tick_dict[j])\n",
    "#         ax.set_ylim(ylim_dict[j])\n",
    "#         ax.set_xlim(2015,2305)\n",
    "#         xticks = rI == 3 ? [2015,2050,2100,2150,2200,2250,2300] : []\n",
    "#         ax.set_xticks(xticks)\n",
    "#         # ax.locator_params(tight=true, nbins=6)\n",
    "#         ax.grid(true, alpha=0.25, zorder=1)\n",
    "\n",
    "#         y_true = (j == 5) ? log.(θ_mat[real, j]) : θ_mat[real, j]\n",
    "#         dx = 5        # small nudge to the right\n",
    "#         ax.scatter([cal_years[end]+dx], [y_true];\n",
    "#            marker=\"D\", s=64, c=color, edgecolors=\"k\", linewidths=0.8, zorder=21, clip_on=false)\n",
    "#     end  \n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0342c12d-0d22-43cc-b701-13f9bf6c1345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_years_no_gap = collect(range(2016, step=1, length=285))\n",
    "# yrs_gapped = collect(range(2030, step=15, length=19));\n",
    "\n",
    "# yrs_dict = Dict{Int64, Int64}()\n",
    "# for (idx,yr) in enumerate(all_years_no_gap)\n",
    "#         yrs_dict[yr] = idx\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d22b841a-4a66-45b9-8f04-6e287b6dd178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function plot_slr_means_of_trajectory(path_to_proj, axis, r, pred_year, color, fill_color, FONTSIZE_SLR)\n",
    "    \n",
    "#     # Years at which recalibration occurred\n",
    "#     cal_years = collect(range(2015, step=15, length=20))\n",
    "#     # @show cal_years\n",
    "#     # Maximum number of calibration years that occurred before year projected\n",
    "#     n_cal_years = fld(pred_year-2015,15) + 1\n",
    "    \n",
    "#     means = Vector{Float64}()\n",
    "#     uppers = Vector{Float64}()\n",
    "#     lowers = Vector{Float64}()\n",
    "    \n",
    "#     # Index of the matrix containing the specified years projections\n",
    "#     pred_idx = yrs_dict[pred_year]\n",
    "\n",
    "#     push!(means, mean(sample_post_mm_ssp5_2015[pred_idx,:] ))\n",
    "#     push!(uppers, quantile(sample_post_mm_ssp5_2015[pred_idx,:], 0.95))\n",
    "#     push!(lowers, quantile(sample_post_mm_ssp5_2015[pred_idx,:], 0.05))\n",
    "    \n",
    "#     for yr in cal_years[2:n_cal_years]\n",
    "#         current_projections = JLD2.load(\"$(path_to_proj)/$(r)-year$(yr)pred_VAF.jld2\",\"sample_post_mm_ssp5\" )\n",
    "#         # Calculate the means and quantiles of that row \n",
    "#         push!(means, mean( current_projections[pred_idx,:] ))\n",
    "#         push!(uppers, quantile(current_projections[pred_idx,:], 0.95))\n",
    "#         push!(lowers, quantile(current_projections[pred_idx,:], 0.05))\n",
    "\n",
    "#     end\n",
    "#     # Plot against year calibrated\n",
    "#     axis.plot(cal_years[1:n_cal_years], means, label=\"Projection distribution mean\", zorder=20, color=color, lw=3)\n",
    "#     axis.fill_between(cal_years[1:n_cal_years], uppers, lowers,alpha=0.5, label=\"90% credible interval\", color=fill_color)\n",
    "#     axis.set_xlim(2015,cal_years[n_cal_years])\n",
    "#     xticks = (pred_year == 2300) ? [2015,2050,2100,2150,2200,2250,2300] : cal_years[1:1+floor(Int,pred_idx/100):n_cal_years]\n",
    "#     axis.set_xticks(xticks)\n",
    "#     axis.tick_params(axis=\"both\", which=\"major\", labelsize=FONTSIZE_SLR*0.85)\n",
    "#     axis.grid(true, alpha=0.25, zorder=1)\n",
    "#     axis.set_xlabel(\"Analysis year\", fontsize=FONTSIZE_SLR, labelpad=10)\n",
    "#     axis.set_ylabel(\"Sea-level contribution at $(pred_year) (mm)\", fontsize=FONTSIZE_SLR, labelpad=10)\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cfc18e42-3193-426a-845c-9932314194e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Realization numbers\n",
    "Realizations = [string(i) for i in 1:100];\n",
    "\n",
    "Random.seed!(7);\n",
    "# Only selecting 3 trajectories because the graph gets to messy with more.\n",
    "selections = [14,24,49,77]\n",
    "println(selections)\n",
    "\n",
    "path_to_posteriors = \"Data/Posterior_Data_New_All\"\n",
    "path_to_slr_projections = \"Data/Projection_Data\"\n",
    "\n",
    "\n",
    "title_dict = Dict([\n",
    "            1 => L\"\\sigma_{max}\", 2 => L\"q\" , 3 => L\"C_{\\mu}\" ,\n",
    "            4 => L\"C_{\\phi}\", 5 => L\"\\log(\\gamma_0)\", 6 => L\"\\overline{m}\" ])\n",
    "\n",
    "tick_dict  = Dict(1=>[100000,120000,140000],\n",
    "                  2=>[0.15,0.20,0.25,0.30],\n",
    "                  3=>[0.8,0.9,1,1.1],\n",
    "                  4=>[0.8,0.9,1],\n",
    "                  5=>[9.17,10,11,12],\n",
    "                  6=>[20,30,40,50])\n",
    "\n",
    "ylim_dict = Dict([1 => [0.98e5,1.5e5], \n",
    "                  2 => [0.093,0.34], \n",
    "                  3 => [0.79,1.14],\n",
    "                  4 => [0.79,1.08], \n",
    "                  5 => [9.05,12.2], \n",
    "                  6 => [11.5,58.5]])\n",
    "\n",
    "color_dict = Dict(\n",
    "                1 => \"red\", 2=> \"green\", 3=>\"purple\", 4=>\"blue\"\n",
    ")\n",
    "\n",
    "fill_color_dict = Dict(\n",
    "                1 => \"lightcoral\", 2=> \"palegreen\", 3=>\"plum\", 4=>\"lightblue\"\n",
    ")\n",
    "\n",
    "# Generic handles and labels for the figures\n",
    "gray_patch = matplotlib.patches.Patch(color=\"gray\", label=\"90% credible interval\",alpha=0.5)\n",
    "black_line_param = matplotlib.lines.Line2D([], [], lw=3, color=\"black\", label=\"Parameter posterior distribution mean\")\n",
    "black_line_slr = matplotlib.lines.Line2D([], [], lw=3, color=\"black\", label=\"Projection distribution mean\")\n",
    "\n",
    "# Define the figure subplots for parametric analysis\n",
    "fig_params, ax_params = PyPlot.subplots(nrows=3, ncols=2, figsize=(28, 15), dpi=300,\n",
    "                     gridspec_kw=Dict(\"height_ratios\"=> [1, 1, 1], \"width_ratios\"=> [1, 1], \"hspace\"=> 0.15, \"wspace\"=> 0.1))\n",
    "FONTSIZE_PARAM = 26\n",
    "# Loop to call the parametric plotting function \n",
    "for (i,r) in enumerate(selections)\n",
    "    posterior_dict = JLD2.load(\"$(path_to_posteriors)/R_$(r)_Posterior_Dict.jld2\", \"post_data\")\n",
    "    plot_param_means_of_trajectory(r, posterior_dict, ax_params, title_dict, tick_dict, ylim_dict, \n",
    "                                    color_dict[i], fill_color_dict[i], FONTSIZE_PARAM)\n",
    "end\n",
    "\n",
    "#Figure labels and legends\n",
    "ax_params[end].set_xlabel(\"Analysis year\", fontsize=FONTSIZE_PARAM, labelpad=10)\n",
    "# fig_params.supylabel(\"Parameter value\", fontsize=FONTSIZE_PARAM)\n",
    "fig_params.legend(handles=[black_line_param, gray_patch],loc=\"upper center\", ncol=6, fontsize=0.9*FONTSIZE_PARAM,\n",
    "           bbox_to_anchor=(0.5, 0.962), bbox_transform=PyPlot.gcf().transFigure,\n",
    "           frameon=\"True\", framealpha=1)\n",
    "param_plot_saveout_path = \"Plots/Nathan_Figure_Plots/param_posterior_against_analysis_year.pdf\"\n",
    "mkpath(dirname(param_plot_saveout_path))\n",
    "fig_params.savefig(param_plot_saveout_path; dpi=300)\n",
    "plt.close()\n",
    "\n",
    "fig_slr, axes = subplots(nrows=1, ncols=3, figsize=(33, 6))\n",
    "fig_slr.subplots_adjust(wspace=0.2, hspace=0.0)\n",
    "slr_plot_saveout_path = \"Plots/Nathan_Figure_Plots/projected_slr_against_analysis_year.pdf\"\n",
    "FONTSIZE_SLR = 22\n",
    "# Loop to call the SLR plotting function for projections for three future years\n",
    "letters = [\"a\", \"b\", \"c\"]\n",
    "for (a, chosen_year) in enumerate([2100, 2200, 2300])\n",
    "    ax_slr = axes[a]\n",
    "    for (i,r) in enumerate(selections)\n",
    "        plot_slr_means_of_trajectory(\"$(path_to_slr_projections)/R_$(r)\", ax_slr, r, chosen_year, color_dict[i], \n",
    "                                                                            fill_color_dict[i], FONTSIZE_SLR)\n",
    "    end\n",
    "    if a == 1\n",
    "        ax_slr.set_ylim([-3.97,4.75])\n",
    "    end\n",
    "    if a == 3\n",
    "        ax_slr.text(-0.157, 1.09, \"(\" * letters[a] * \")\", ha=\"left\", va=\"top\", transform=ax_slr.transAxes, fontsize=FONTSIZE_SLR*0.92)\n",
    "    elseif a == 2\n",
    "        ax_slr.text(-0.145, 1.09, \"(\" * letters[a] * \")\", ha=\"left\", va=\"top\", transform=ax_slr.transAxes, fontsize=FONTSIZE_SLR*0.92)\n",
    "    else\n",
    "        ax_slr.text(-0.149, 1.09, \"(\" * letters[a] * \")\", ha=\"left\", va=\"top\", transform=ax_slr.transAxes, fontsize=FONTSIZE_SLR*0.92)\n",
    "    end\n",
    "    ax_slr.legend(handles=[black_line_slr, gray_patch],loc=\"upper center\", ncol=1, fontsize=FONTSIZE_SLR*0.72,\n",
    "           bbox_to_anchor=(0.754, 1.013),frameon=\"True\", framealpha=1)\n",
    "end\n",
    "mkpath(dirname(slr_plot_saveout_path))\n",
    "fig_slr.savefig(slr_plot_saveout_path; bbox_inches=\"tight\", dpi=300)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac301286-00a3-423c-ad74-d37b43636317",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.5",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
